QID,QUESTION,CORRECT ANSWER,A,B,C,D,E,F,EXPLANATION/NOTES,Snowflake Documentation,Image URL,Topic(s)
1,Will data cached in a warehouse be lost when the warehouse is resized?,A,"Possibly, if the warehouse is resized to a smaller size and the cache no longer fits.",Yes. because the compute resource is replaced in its entirety with a new compute resource.,No. because the size of the cache is independent from the warehouse size,Yes. became the new compute resource will no longer have access to the cache encryption key,,,"Unlike Metadata cache or Query Result cache, Warehouse cache is usable through the specific VWH only\n
VWH cache gets cleared when VWH is suspended\n
If cache-size is too small, least-recently-used data is emptied first",https://docs.snowflake.com/en/user-guide/warehouses-considerations#scaling-up-vs-scaling-out,,Performance Concepts
2,What are ways to create and manage data shares in Snowflake? (Choose two.),"A,C",Through the Snowflake web interface (UI),Through the DATA_SHARE=TRUE parameter,Through SQL commands,Through the enable_share=true parameter,Using the CREATE SHARE AS SELECT * TABLE command,,,https://docs.snowflake.com/en/user-guide/data-sharing-provider,,Data Protection and Data Sharing
3,What is the purpose of an External Function?,A,To call code that executes outside of Snowflake,To run a function in another Snowflake database,To share data in Snowflake with external parties,To ingest data from on-premises data sources,,,"External functions are a type of User-Defined-Function (UDF)\n
• Snowflake supports scalar external functions; the remote service must return exactly one row for each row received\n
• Snowflake stores security-related external function information in an API integration",https://docs.snowflake.com/en/sql-reference/external-functions-introduction,,Data Transformations
4,Which is the MINIMUM required Snowflake edition that a user must have if they want to use AWS/Azure Privatelink or Google Cloud Private Service Connect?,D,Standard,Premium,Enterprise,Business Critical,,,**Concept included in test from Sept 2024,"https://docs.snowflake.com/en/user-guide/intro-editions, https://docs.snowflake.com/en/user-guide/admin-security-privatelink",,"Snowflake AI Data Cloud Features and Architecture, Account Access and Security"
5,What happens when a virtual warehouse is resized?,B,When increasing the size of an active warehouse the compute resource for all running and queued queries on the warehouse are affected,When reducing the size of a warehouse the compute resources are removed only when they are no longer being used to execute any current statements.,The warehouse will be suspended while the new compute resource is provisioned and will resume automatically once provisioning is complete.,Users who are trying to use the warehouse will receive an error message until the resizing is complete,,,,https://docs.snowflake.com/en/user-guide/warehouses-tasks,,Performance Concepts
6,What features does Snowflake Time Travel enable?,B,Querying data-related objects that were created within the past 365 days,Restoring data-related objects that have been deleted within the past 90 days,Conducting point-in-time analysis for BI reporting,Analyzing data usage/manipulation over all periods of time,,,"Snowflake Time Travel enables accessing historical data (i.e. data that has been changed or deleted) at any point within a defined period. It serves as a powerful tool for performing the following tasks:\n
-Restoring data-related objects (tables, schemas, and databases) that might have been accidentally or intentionally deleted.\n
-Duplicating and backing up data from key points in the past.\n
-Analyzing data usage/manipulation over specified periods of time.",https://docs.snowflake.com/en/user-guide/data-time-travel,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
7,A virtual warehouse's auto-suspend and auto-resume settings apply to which of the following?,B,The primary cluster in the virtual warehouse,The entire virtual warehouse,The database in which the virtual warehouse resides,The Queries currently being run on the virtual warehouse,,,,https://docs.snowflake.com/en/user-guide/warehouses-overview,,Performance Concepts
8,What are value types that a VARIANT column can store? (Choose two.),"B,D",STRUCT,OBJECT,BINARY,ARRAY,CLOB,,**Concept included in test from Sept 2024,https://docs.snowflake.com/en/sql-reference/data-types-semistructured,,Data Transformations
9,"True or False: 
It is possible for a user to run a query against the query result cache without requiring an active warehouse?",A,TRUE,FALSE,,,,,,https://community.snowflake.com/s/article/Understanding-Result-Caching,,"Data Transformations, Performance Concepts"
10,Which of the following indicates that it may be appropriate to use a clustering key for a table? (Choose two.),"D,E",The table contains a column that has very low cardinality,DML statements that are being issued against the table are blocked,The table has a small number of micro-partitions,Queries on the table are running slower than expected,The clustering depth for the table is large,,"Queries on the table are running slower than expected or have noticeably degraded over time.\n

The clustering depth for the table is large.\n

**Concept included in test from Sept 2024",https://docs.snowflake.com/en/user-guide/tables-clustering-keys#label-considerations-for-choosing-clustering,,Performance Concepts
11,Which of the following can be executed/called with Snowpipe?,C,A User Defined Function (UDF),A stored procedure,A single copy_into statement,A single insert__into statement,,,,"https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro, https://docs.snowflake.com/en/sql-reference/sql/create-pipe",,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture, Data Transformations"
12,Query compilation occurs in which architecture layer of the Snowflake Cloud Data Platform?,D,Compute layer,Storage layer,Cloud infrastructure layer,Cloud services layer,,,"Cloud Service Layer:\n
-Authentication\n
-Infrastructure management\n
-Metadata management\n
-Query parsing and optimization\n
-Access control\n
Query execution is different from Query processing. Query execution is performed in the processing layer. While The services layer for Snowflake authenticates user sessions, provides management, enforces security functions, performs query compilation and optimization, results cache and coordinates all transactions",https://docs.snowflake.com/en/user-guide/intro-key-concepts,,Snowflake AI Data Cloud Features and Architecture
13,In which scenarios would a user have to pay Cloud Services costs? (Choose two.),"A,E",Compute Credits = 50 Credits Cloud Services = 10,Compute Credits = 80 Credits Cloud Services = 5,Compute Credits = 100 Credits Cloud Services = 9,Compute Credits = 120 Credits Cloud Services = 10,Compute Credits = 200 Credits Cloud Services = 26,,Cloud services are charged once > 10% of the compute credits,https://docs.snowflake.com/en/user-guide/cost-exploring-compute,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
14,Which Snowflake partner specializes in data catalog solutions?,A,Alation,DataRobot,dbt,Tableau,,,,https://docs.snowflake.com/en/user-guide/ecosystem-all,,Snowflake AI Data Cloud Features and Architecture
15,Which Snowflake technique can be used to improve the performance of a query?,A,Clustering,Indexing,Fragmenting,Using INDEX HINTS,,,,https://docs.snowflake.com/en/user-guide/tables-clustering-keys,,Performance Concepts
16,Which of the following objects can be shared through secure data sharing?,D,Masking policy,Stored procedure,Task,External table,,,"Following objects can be shared:\n
-Database\n
-Tables\n
-External tables\n
-Secure Views\n
-Secure Materialized Views\n
-Secure UDFs\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/user-guide/data-sharing-intro,,Data Protection and Data Sharing
17,Which semi-structured file formats are supported when unloading data from a table? (Choose two.),"D,E",ORC,XML,Avro,Parquet,JSON,,"Loading Supported File Formats:\n
-CSV/TSV (structured)\n
-JSON\n
-Avro\n
-Parquet\n
-ORC\n
-XML\n
Unloading Supported File Formats:\n
-CSV/TSV (structured)\n
-JSON\n
-Parquet","https://docs.snowflake.com/en/user-guide/intro-summary-unloading, https://docs.snowflake.com/en/user-guide/data-unload-prepare",,Data Loading and Unloading
18,Which account usage views are used to evaluate the details of dynamic data masking? (Choose two.),"B,C",ROLES,POLICY_REFERENCES,QUERY_HISTORY,RESOURCE_MONITORS,ACCESS_HISTORY,,,https://docs.snowflake.com/en/user-guide/security-column-ddm-intro,,Data Protection and Data Sharing
19,"True or False: A 4X-Large Warehouse may, at times, take longer to provision than a X-Small Warehouse.",A,TRUE,FALSE,,,,,"4XL contains more servers, which might - sometimes - take longer to get provisioned",https://docs.snowflake.com/en/user-guide/warehouses-tasks,,Performance Concepts
20,What happens to the underlying table data when a CLUSTER BY clause is added to a Snowflake table?,D,Data is hashed by the cluster key to facilitate fast searches for common data values,Larger micro-partitions are created for common data values to reduce the number of partitions that must be scanned,Smaller micro-partitions are created for common data values to allow for more parallelism,Data may be colocated by the cluster key within the micro-partitions to improve pruning performance),,,,https://docs.snowflake.com/en/user-guide/tables-clustering-keys,,Performance Concepts
21,What is a limitation of a Materialized View?,D,A Materialized View cannot support any aggregate functions,A Materialized View can only reference up to two tables,A Materialized View cannot be joined with other tables,A Materialized View cannot be defined with a JOIN,,,"Materialized View limitations:\n
-functions must be deterministic (eg. CURRENT_TIME or CURRENT_TIMESTAMP not allowed)\n
-Cannot be created using TIME TRAVEL\n
-Can query only a single table\n
-Joins, including self-joins, are not supported.\n
-A materialized view cannot query any view\n
-A materialized view cannot query a UDTF\n
A materialized view cannot include:\n
-UDFs (this limitation applies to all types of user-defined functions, including external functions).\n
-Window functions.\n
-HAVING clauses.\n
-ORDER BY clause.\n
-LIMIT clause.\n
-GROUP BY keys that are not within the SELECT list Nesting of subqueries within a materialized view\n
Materialized view can be joined with other tables. But you cannot include JOIN in a materialized view definition",https://docs.snowflake.com/en/user-guide/views-materialized#limitations-on-creating-materialized-views,,Performance Concepts
22,What can be used to view warehouse usage over time? (Choose two.),"D,E",The load HISTORY view,The Query history view,The show warehouses command,The WAREHOUSE_METERING_HISTORY View,The billing and usage tab in the Snowflake web Ul,,"This Account Usage view can be used to return the hourly credit usage for a single warehouse (or all the warehouses in your account) within the last 365 days (1 year). \n

Snowsight can be used to view compute cost. ","https://docs.snowflake.com/en/sql-reference/account-usage/warehouse_metering_history, https://docs.snowflake.com/en/user-guide/cost-exploring-compute",,"Data Transformations, Performance Concepts, Snowflake AI Data Cloud Features and Architecture"
23,What are the default Time Travel and Fail-safe retention periods for transient tables?,C,Time Travel - 1 day. Fail-safe - 1 day,Time Travel - 0 days. Fail-safe - 1 day,Time Travel - 1 day. Fail-safe - 0 days,Transient tables are retained in neither Fail-safe nor Time Travel,,,"Transient tables can have a Time Travel retention period of either 0 or 1 day.\n
Temporary tables can also have a Time Travel retention period of 0 or 1 day; however, this retention period ends as soon as the table is dropped or the session in which the table was created ends.\n
Transient and temporary tables have no Fail-safe period.\n
**Concept included in test from Sept 2024","https://docs.snowflake.com/en/user-guide/data-availability, https://docs.snowflake.com/en/user-guide/tables-temp-transient#comparison-of-table-types",,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
24,Which of the following is a valid source for an external stage when the Snowflake account is located on Microsoft Azure?,C,An FTP server with TLS encryption,An HTTPS server with WebDAV,A Google Cloud storage bucket,A Windows server file share on Azure,,,"Data source can be AWS, Azure or GCP cloud storage, regardless of where the Snowflake account is hosted","https://docs.snowflake.com/en/user-guide/data-load-local-file-system-stage-ui, https://docs.snowflake.com/en/user-guide/data-load-overview#external-stages",,Data Loading and Unloading
25,Which of the following describes how multiple Snowflake accounts in a single organization relate to various cloud providers?,A,Each Snowflake account can be hosted in a different cloud vendor and region.,Each Snowflake account must be hosted in a different cloud vendor and region,All Snowflake accounts must be hosted in the same cloud vendor and region,"Each Snowflake account can be hosted in a different cloud vendor, but must be in the same region.",,,"The cloud platform you choose for each Snowflake account is completely independent from your other Snowflake accounts. In fact, you can choose to host each Snowflake account on a different platform, although this may have some impact on data transfer billing when loading data.",https://docs.snowflake.com/en/user-guide/intro-cloud-platforms,,Snowflake AI Data Cloud Features and Architecture
26,"When reviewing a query profile, what is a symptom that a query is too large to fit into the memory?",D,A single join node uses more than 50% of the query time,Partitions scanned is equal to partitions total,An Aggregate Operator node is present,The query is spilling to remote storage,,,,"https://docs.snowflake.com/en/user-guide/performance-query-warehouse-memory, https://docs.snowflake.com/en/user-guide/ui-query-profile#queries-too-large-to-fit-in-memory",,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
27,"A user unloaded a Snowflake table called mytable to an internal stage called mystage. 

Which command can be used to view the list of files that has been uploaded to the staged?",D,list @mytable;,list @%mytable;,list@ %my.stage;,list @mystage;,,,,https://docs.snowflake.com/en/sql-reference/sql/list,,Data Transformations
28,Which Snowflake object enables loading data from files as soon as they are available in a cloud storage location?,A,Pipe,External stage,Task,Stream,,,"Snowpipe enables loading data from files as soon as they're available in a stage. This means you can load data from files in micro-batches, making it available to users within minutes, rather than manually executing COPY statements on a schedule to load larger batches.",https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro,,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture"
29,What SQL command would be used to view all roles that were granted to user. 1?,A,show grants to user USER1;,show grants of user USER1;,describe user USER1;,show grants on user USER1;,,,,https://docs.snowflake.com/en/sql-reference/sql/show-grants,,Data Transformations
30,What is a best practice after creating a custom role?,B,Create the custom role using the SYSADMIN role.,Assign the custom role to the SYSADMIN role,Assign the custom role to the PUBLIC role,Add_CUSTOM to all custom role names,,,"Custom roles (i.e. any roles other than the system-defined roles) can be created by the USERADMIN role (or a higher role) as well as by any role to which the CREATE ROLE privilege has been granted. By default, a newly-created role is not assigned to any user, nor granted to any other role.\n
When creating roles that will serve as the owners of securable objects in the system, Snowflake recommends creating a hierarchy of custom roles, with the top-most custom role assigned to the system role SYSADMIN.",https://docs.snowflake.com/en/user-guide/security-access-control-configure#label-security-custom-role,,Account Access and Security
31,"True or False: 
Loading data into Snowflake requires that source data files be no larger than 16MB.",B,TRUE,FALSE,,,,,"Default file size when UNLOADING is 16MB, but can be up to 5GB via MAX_FILE_SIZE parameter. For loading, Snowflake recommends a file size of 100-250MB compressed to make use of parallelization",https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare,,Data Loading and Unloading
32,Which command can be used to stage local files to the Snowflake interface?,A,SnowSQL,Snowflake classic web interface (Ul),Snowsight,NET driver,,,PUT command from SnowSQL command line interface tool,https://docs.snowflake.com/en/user-guide/data-load-local-file-system-stage,,Data Loading and Unloading
33,Which of the following conditions must be met in order to return results from the results cache? (Choose two.),"A,E",The user has the appropriate privileges on the objects associated with the query,Micro-partitions have been reclustered since the query was last run,The new query is run using the same virtual warehouse as the previous query,The query includes a User Defined Function (UDF),The query has been run within 24 hours of the previously-run query,,"If the same query is fired again in 24 hrs, it will not be COMPUTED, which means it will not be charged. and it is not affected by WH suspension.",https://docs.snowflake.com/en/user-guide/querying-persisted-results#retrieval-optimization,,Performance Concepts
34,When is the result set cache no longer available? (Choose two.),"C,E",When another warehouse is used to execute the query,When another user executes the query,When the underlying data has changed,When the warehouse used to execute the query is suspended,When it has been 24 hours since the last query,,,https://docs.snowflake.com/en/user-guide/querying-persisted-results,,Performance Concepts
35,"A developer is granted ownership of a table that has a masking policy. The developer's role is not able to see the masked data. 

Will the developer be able to modify the table to read the masked data?",D,"Yes, because a table owner has full control and can unset masking policies.","Yes, because masking policies only apply to cloned tables.","No, because masking policies must always reference specific access roles.","No, because ownership of a table does not include the ability to change masking policies",,,,https://docs.snowflake.com/en/user-guide/security-column-intro#what-are-masking-policies,,Data Protection and Data Sharing
36,Which of the following describes how clustering keys work in Snowflake?,B,"Clustering keys update the micro-partitions in place with a full sort, and impact the DML operations.","Clustering keys sort the designated columns over time, without blocking DML operations","Clustering keys create a distributed, parallel data structure of pointers to a table's rows and columns",Clustering keys establish a hashed key on each node of a virtual warehouse to optimize joins at run-time,,,,https://docs.snowflake.com/en/user-guide/tables-clustering-keys,,Performance Concepts
37,What feature can be used to reorganize a very large table on one or more columns?,B,Micro-partitions,Clustering keys,Key partitions,Clustered partitions,,,,https://docs.snowflake.com/en/user-guide/tables-clustering-keys,,Performance Concepts
38,How long is Snowpipe data load history retained?,D,As configured in the create pipe settings,Until the pipe is dropped,64 days,14 days,,,"Stored in the metadata of the pipe for 14 days. Must be requested from Snowflake via a REST endpoint, SQL table function, or ACCOUNT_USAGE view\n
Loading History:\n
-Snowpipe -> 14 days\n
-Copy Into > 64 days (stored in the Metadata of the target table)","https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro#load-history, https://docs.snowflake.com/en/sql-reference/functions/pipe_usage_history",,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture, Data Transformations"
39,"A user needs to create a materialized view in the schema MYDB.MYSCHEMA. 

Which statements will provide this access?",A,"GRANT ROLE MYROLE TO USER USER1;
GRANT CREATE MATERIALIZED VIEW ON SCHEMA MYDB.MYSCHEMA TO ROLE MYROLE;","GRANT ROLE MYROLE TO USER USER1;
GRANT CREATE MATERIALIZED VIEW ON SCHEMA MYDB.MYSCHEMA TO USER USER1;","GRANT ROLE MYROLE TO USER USER1;
GRANT CREATE MATERIALIZED VIEW ON SCHEMA MYDB.MYSCHEMA TO MYROLE;","GRANT ROLE MYROLE TO USER USER1;
GRANT CREATE MATERIALIZED VIEW ON SCHEMA MYDB.MYSCHEMA TO USER1;",,,Privileges can only be granted to users and role_name is a required parameter.,"https://docs.snowflake.com/en/user-guide/views-materialized#privileges-on-a-materialized-view-s-schema, https://docs.snowflake.com/en/sql-reference/sql/grant-privilege#examples",,"Performance Concepts, Data Transformations"
40,What Snowflake role must be granted for a user to create and manage accounts?,B,ACCOUNTADMIN,ORGADMIN,SECURITYADMIN,SYSADMIN,,,"ORGADMIN is NOT part of the role hierarchy\n
An account can be created by an ORGADMIN through the web interface or using SQL.\n
Additonal actions the ORGADMIN can do include creating and managing accounts data sharing (across regions / clouds), and data replication and failover","https://docs.snowflake.com/en/user-guide/organizations, https://docs.snowflake.com/en/user-guide/organizations-manage-accounts",,Snowflake AI Data Cloud Features and Architecture
41,What data is stored in the Snowflake storage layer? (Choose two.),"B,D",Snowflake parameters,Micro-partitions,Query history,Persisted query results,Standard and secure view results,,,https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture,,Snowflake AI Data Cloud Features and Architecture
42,"A company's security audit requires generating a report listing all Snowflake logins (e.g. date and user) within the last 90 days. 

Which of the following statements will return the required information?",D,"SELECT LAST_SUCCESS_LOGIN, LOGIN_NAME FROM ACCOUNT_USAGE.USERS;","SELECT EVENT_TIMESTAMP, USER_NAME FROM table(information_schema.login_history_by_user))","SELECT EVENT_TIMESTAMP, USER_NAME FROM ACCOUNT_USAGE ACCESS_HISTORY;","SELECT EVENT_TIMESTAMP, USER_NAME FROM ACCOUNT_USAGE.LOGIN_HISTORY;",,,,https://docs.snowflake.com/en/sql-reference/account-usage/login_history,,Data Transformations
43,How would you determine the size of the virtual warehouse used for a task?,C,"Root task may be executed concurrently (i.e. multiple instances, it is recommended to leave some margins in the execution window to avoid missing instances of execution","Querying (select) the size of the stream content would help determine the warehouse size. For example, if querying large stream content, use a larger warehouse size","If using the stored procedure to execute multiple SQL statements, it's best to test run the stored procedure separately to size the compute resource first","Since task infrastructure is based on running the task body on schedule, it's recommended to configure the virtual warehouse for automatic concurrency handling using Multi-cluster warehouse (MCW) to match the task schedule",,,,https://docs.snowflake.com/en/user-guide/warehouses-considerations#selecting-an-initial-warehouse-size,,"Performance Concepts, Data Loading and Unloading"
44,"In the query profiler view for a query, which components represent areas that can be used to help optimize query performance? (Choose two.)","C,D",Bytes scanned,Bytes sent over the network,Number of partitions scanned,Percentage scanned from cache,External bytes scanned,,"-The fewer partitions are scanned (compared to the total), the better pruning / clustering works and thus the better the performance\n
-Cache usage improves the performance\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/user-guide/ui-snowsight-activity#label-snowsight-query-profile-reference,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
45,User-level network policies can be created by which of the following roles? (Choose two.),"B,D",ROLEADMIN,ACCOUNTADMIN,SYSADMIN,SECURITYADMIN,USERADMIN,,,https://docs.snowflake.com/en/user-guide/network-policies#create-a-network-policy,,Account Access and Security
46,"A user has 10 files in a stage containing new customer data. The ingest operation completes with no errors, using the following command: 
    COPY INTO my__table FROM @my_stage; 

The next day the user adds 10 files to the stage so that now the stage contains a mixture of new customer data and updates to the previous data. The user did not remove the 10 original files. 

If the user runs the same copy into command what will happen?",D,All data from all of the files on the stage will be appended to the table,Only data about new customers from the new files will be appended to the table,The operation will fail with the error uncertain files in stage.,All data from only the newly-added files will be appended to the table.,,,"Load history is stored for 64 days in target table to avoid duplicating / loading data twice. Hence only new data will be loaded, already loaded data ignored. Also COPY command maintains historic load metadata with target table, so day 1 , 10 files will will not be loaded again.",https://docs.snowflake.com/en/user-guide/data-load-considerations-load#loading-older-files,,Data Loading and Unloading
47,What happens when a cloned table is replicated to a secondary database? (Choose two.),"C,D",A read-only copy of the cloned tables is stored.,The replication will not be successful.,The physical data is replicated,Additional costs for storage are charged to a secondary account,Metadata pointers to cloned tables are replicated,,,https://docs.snowflake.com/en/user-guide/account-replication-considerations#replication-and-cloning,,Data Protection and Data Sharing
48,Which feature is only available in the Enterprise or higher editions of Snowflake?,A,Column-level security,SOC 2 type Il certification,Multi-factor Authentication (MFA),Object-level access control,,,,https://docs.snowflake.com/en/user-guide/intro-editions#enterprise-edition,,Snowflake AI Data Cloud Features and Architecture
49,Which of the following Snowflake objects can be shared using a secure share? (Choose two.),"D,E",Materialized views,Sequences,Procedures,Tables,Secure User Defined Functions (UDFs),,"Following objects can be shared:\n
-Tables\n
-External Tables\n
-Secure Views\n
-Secure Materialized Views\n
-Secure UDFs\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/user-guide/data-sharing-intro,,Data Protection and Data Sharing
50,Which of the following are benefits of micro-partitioning? (Choose two.),"B,C",Micro-partitions cannot overlap in their range of values,Micro-partitions are immutable objects that support the use of Time Travel.,Micro-partitions can reduce the amount of 1/0 from object storage to virtual warehouses,Rows are automatically stored in sorted order within micro-partitions,Micro-partitions can be defined on a schema-by-schema basis,,"- In contrast to traditional static partitioning, Snowflake micro-partitions are derived automatically; they don’t need to be explicitly defined up-front or maintained by users.\n
- As the name suggests, micro-partitions are small in size (50 to 500 MB, before compression), which enables extremely efficient DML and fine-grained pruning for faster queries.\n
- Micro-partitions can overlap in their range of values, which, combined with their uniformly small size, helps prevent skew.\n
- Columns are stored independently within micro-partitions, often referred to as columnar storage. This enables efficient scanning of individual columns; only the columns referenced by a query are scanned.",https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#benefits-of-micro-partitioning,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
51,Which statement about billing applies to Snowflake credits?,D,Credits are billed per-minute with a 60-minute minimum,Credits are used to pay for cloud data storage usage,Credits are consumed based on the number of credits billed for each hour that a warehouse runs,Credits are consumed based on the warehouse size and the time the warehouse is running,,,"Based on T-Shirt size of virtual warehouse and the time the VWH is running; time in seconds.\n
Minimum: 60 seconds after VWH has been provisioned / resumed\n
A virtual warehouse is one or more clusters of compute resources that enable executing queries, loading data, and performing other DML operations.\n
Snowflake credits are used to pay for the processing time used by each virtual warehouse. Snowflake credits are charged based on the number of virtual warehouses you use, how long they run, and their size.",https://docs.snowflake.com/en/user-guide/cost-understanding-compute#virtual-warehouse-credit-usage,,Performance Concepts
52,Which COPY INTO command outputs the data into one file?,A,SINGLE= TRUE,MAX_FILE_NUMBER=1,FILE_NUMBER=1,MULTIPLE=FALSE,,,"Default: SINGLE = FALSE\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/sql-reference/sql/copy-into-location#copy-options-copyoptions,,Data Transformations
53,Which of the following compute resources or features are managed by Snowflake? (Choose two.),"C,D",Execute a COPY command,Updating data,Snowpipe,AUTOMATIC_ CLUSTERING,Scaling up a warehouse,,"Snowpipe uses Snowflake-supplied compute resources.\n
Automatic Clustering is the Snowflake service that seamlessly and continually manages all reclustering, as needed, of clustered tables.\n

Serverless features are for example:\n
-Snowpipe\n
-Automatic Clustering\n
-Materialized Views\n
-Search Optimization\n
-Query Acceleration Service\n
-Tasks (optional)",https://docs.snowflake.com/en/user-guide/cost-understanding-compute,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
54,"A user has unloaded data from Snowflake to a stage. 

Which SQL command should be used to validate which data was loaded into the stage?",A,list @file_stage,show @file_stage,view @file_stage,verify @file_stage,,,,https://docs.snowflake.com/en/sql-reference/sql/list,,Data Transformations
55,Which of the following are valid methods for authenticating users for access into Snowflake? (Select three.),"B,D,E",SCIM,Federated authentication,TLS 1.2,Key-pair authentication,OAuth,OCSP authentication,,https://docs.snowflake.com/en/user-guide/authentication-policies,,Account Access and Security
56,"Which Snowflake objects track DML changes made to tables, like inserts, updates, and deletes?",B,Pipes,Streams,Tasks,Procedures,,,**Concept included in test from Sept 2024,https://docs.snowflake.com/en/user-guide/streams-intro,,Data Loading and Unloading
57,What is the recommended file sizing for data loading using Snowpipe?,A,"A compressed file size greater than 100 MB, and up to 250 MB","A compressed file size greater than 100 GB, and up to 250 GB","A compressed file size greater than 10 MB, and up to 100 MB","A compressed file size greater than 1 GB, and up to 2 GB",,,Loading data files roughly 100-250 MB in size or larger reduces the overhead charge relative to the amount of total data loaded to the point where the overhead cost is immaterial.,https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare#continuous-data-loads-i-e-snowpipe-and-file-sizing,,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture"
59,Which data type can be used to store geospatial data in Snowflake?,D,Variant,Object,Geometry,Geography,,,,https://docs.snowflake.com/en/sql-reference/data-types-geospatial,,Data Transformations
60,Which of the following are best practice recommendations that should be considered when loading data into Snowflake? (Choose two.),"C,D",Load files that are approximately 25 MB or smaller.,Remove all dates and timestamps.,Load files that are approximately 100-250 MB (or larger),Avoid using embedded characters such as commas for numeric data types,Remove semi-structured data types,,,https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare#preparing-delimited-text-files,,Data Loading and Unloading
61,In which use cases does Snowflake apply egress charges?,C,Data sharing within a specific region,Query result retrieval,Database replication,Loading data into Snowflake,,,,https://docs.snowflake.com/en/user-guide/cost-understanding-data-transfer,,Performance Concepts
62,How often are encryption keys automatically rotated by Snowflake?,A,30 Days,60 Days,90 Days,365 Days,,,"Keys are automatically getting retired after 30 days. Old / retired keys are just being used for decryption from this point on.\n
Periodic rekeying after 365 days is an enterprise+ feature. In this case, retired keys older than a year are being destroyed and the data is re-encrypted with a new key.",https://docs.snowflake.com/en/user-guide/security-encryption-manage#encryption-key-rotation,,Data Protection and Data Sharing
63,What is a machine learning and data science partner within the Snowflake Partner Ecosystem?,D,Informatica,Power BI,Adobe,Data Robot,,,,https://docs.snowflake.com/en/user-guide/ecosystem-analytics,,Snowflake AI Data Cloud Features and Architecture
64,Which Snowflake feature is used for both querying and restoring data?,B,Cluster keys,Time Travel,Fail-safe,Cloning,,,,https://docs.snowflake.com/en/user-guide/data-time-travel,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
65,What is a key feature of Snowflake architecture?,C,Zero-copy cloning creates a mirror copy of a database that updates with the original,Software updates are automatically applied on a quarterly basis,Snowflake eliminates resource contention with its virtual warehouse implementation,Multi-cluster warehouses allow users to run a query that spans across multiple clusters,Snowflake automatically sorts DATE columns during ingest for fast retrieval by date,,,https://docs.snowflake.com/en/user-guide/intro-key-concepts,,Snowflake AI Data Cloud Features and Architecture
66,Which services does the Snowflake Cloud Services layer manage? (Choose two.),"C,E",Compute resources,Query execution,Authentication,Data storage,Metadata,,,https://docs.snowflake.com/en/user-guide/intro-key-concepts,,Snowflake AI Data Cloud Features and Architecture
67,What happens when an external or an internal stage is dropped? (Choose two.),"A,D","When dropping an external stage, the files are not removed and only the stage is dropped","When dropping an external stage, both the stage and the files within the stage are removed","When dropping an internal stage, the files are deleted with the stage and the files are recoverable","When dropping an internal stage, the files are deleted with the stage and the files are not recoverable","When dropping an internal stage, only selected files are deleted with the stage and are not recoverable",,"For an internal stage, all of the files in the stage are purged from Snowflake, regardless of their load status. This prevents the files from continuing to using storage and, consequently, accruing storage charges. However, this also means that the staged files cannot be recovered after a stage is dropped. For an external stage, only the stage itself is dropped; any data files in the referenced external location (Amazon S3, Google Cloud Storage, or Microsoft Azure) are not removed.",https://docs.snowflake.com/en/sql-reference/sql/drop-stage,,Data Transformations
68,What is the default File Format used in the COPY command if one is not specified?,A,CSV,JSON,Parquet,XML,,,,https://docs.snowflake.com/en/sql-reference/sql/copy-into-location,,Data Transformations
69,"When unloading to a stage, which of the following is a recommended practice or approach?",D,Set SINGLE: = true for larger files,Use OBJECT_CONSTRUCT (* ) when using Parquet,Avoid the use of the CAST function,Define an individual file format,,,"Data Unloading Considerations:\n
Defining a File Format: File format defines the type of data to be unloaded into the stage or S3. It is best practice to define an individual file format when regularly used to unload a certain type of data based on the characteristics of the file needed.","https://docs.snowflake.com/en/user-guide/data-unload-considerations, https://community.snowflake.com/s/article/Best-Practices-for-Data-Unloading",,Data Loading and Unloading
70,Where would a Snowflake user find information about query activity from 90 days ago?,A,account_ usage. query history view,account_ usage.query_history_archive View,information_schema. cruery_history view,information_ schema - query history_by_session view,,,**Concept included in test from Sept 2024,https://docs.snowflake.com/en/sql-reference/account-usage/query_history,,Data Transformations
71,Which of the following Snowflake capabilities are available in all Snowflake editions? (Choose two.),"B,D",Customer-managed encryption keys through Tri-Secret Secure,Automatic encryption of all data,Up to 90 days of data recovery through Time Travel,Object-level access control,Column-level security to apply data masking policies to tables and views,,"Customer-managed encryption keys through Tri-Secret Secure = Business Critical+ editions\n
Automatic encryption of all data = All editions\n
Up to 90 days of data recovery through Time Travel = Enterprise+ editions\n
Object-level access control = All editions\n
Column-level security to apply data masking policies to tables and views = Enterprise+ editions\n
**Concept included in test from Sept 2024","https://docs.snowflake.com/en/user-guide/intro-editions, https://docs.snowflake.com/en/user-guide/intro-editions#security-governance-data-protection",,"Snowflake AI Data Cloud Features and Architecture, Data Protection and Data Sharing"
72,What is the minimum Snowflake edition required to create a materialized view?,B,Standard Edition,Enterprise Edition,Business Critical Edition,Virtual Private Snowflake Edition,,,**Concept included in test from Sept 2024,https://docs.snowflake.com/en/user-guide/intro-editions,,Snowflake AI Data Cloud Features and Architecture
73,The Information Schema and Account Usage Share provide storage information for which of the following objects? (Choose three.),"B,C,D",Users,Tables,Databases,Internal Stages,,,**Concept included in test from Sept 2024,"https://docs.snowflake.com/en/sql-reference/info-schema, https://docs.snowflake.com/en/sql-reference/account-usage",,Data Transformations
74,Which stage type can be altered and dropped?,B,Database stage,External stage,Table stage,User stage,,,User and Table stages are created automatically for each User/Table and cannot be altered or dropped; only named stages (internal or external) can be dropped.,"https://docs.snowflake.com/en/sql-reference/sql/drop-stage, https://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage",,"Data Transformations, Data Loading and Unloading"
75,"A user is loading JSON documents composed of a huge array containing multiple records into Snowflake. The user enables the strip_outer _array file format option. 

What does the STRIP_OUTER_ARRAY file format do?",B,It removes the last element of the outer array.,"It removes the outer array structure and loads the records into separate table rows,",It removes the trailing spaces in the last element of the outer array and loads the records into separate table columns,It removes the NULL elements from the JSON object eliminating invalid data and enables the ability to load the records,,,,https://docs.snowflake.com/en/user-guide/semistructured-considerations,,Data Loading and Unloading
76,Which of the following Snowflake features provide continuous data protection automatically? (Choose two.),"C,E",Internal stages,Incremental backups,Time Travel,Zero-copy clones,Fail-safe,,**Concept included in test from Sept 2024,"https://docs.snowflake.com/en/user-guide/data-availability, https://docs.snowflake.com/en/user-guide/data-cdp",,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
77,During periods of warehouse contention which parameter controls the maximum length of time a warehouse will hold a query for processing?,B,STATEMENT_TIMEOUT_IN_SECONDS,STATEMENT_QUEUED_TIMEOUT_IN_SECONDS,MAX_CONCURRENCY_LEVEL,QUERY_TIMEOUT_IN_SECONDS,,,"Parameter setting is In seconds\n
Default is 0 (= no queueing timeout)\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/user-guide/performance-query-warehouse-max-concurrency,,Performance Concepts
78,"True or False: 
Fail-safe can be disabled within a Snowflake account.",B,TRUE,FALSE,,,,,"Regular tables: 7 days failsafe\n
External- + Temporary- + Transient-Tables: 0 days (0 no failsafe!)\n
Not possible to make any changes to failsafe settings",https://docs.snowflake.com/en/user-guide/data-failsafe,,Data Protection and Data Sharing
79,Which of the following describes external functions in Snowflake?,A,They are a type of User-defined Function (UDF).,They contain their own SQL code.,They call code that is stored inside of Snowflake.,They can return multiple rows for each row received,,,"External functions must be scalar functions. A scalar external function returns a single value for each input row.\n
External functions call code that is stored and executed outside Snowflake\n
Snowflake stores security-related external function information in an API integration\n
An external function is a type of UDF. Unlike other UDFs, an external function does not contain its own code; instead, the external function calls code that is stored and executed outside Snowflake",https://docs.snowflake.com/en/sql-reference/external-functions-introduction,,Data Transformations
80,Which data types does Snowflake support when querying semi-structured data? (Choose two.),"A,B",VARIANT,ARRAY,VARCHAR,XML,BLOB,,Variant - Array - Object,"https://docs.snowflake.com/en/user-guide/querying-semistructured, https://docs.snowflake.com/en/sql-reference/data-types-semistructured",,"Performance Concepts, Data Transformations"
81,What is the default character set used when loading CSV files into Snowflake?,A,UTF-8,UTF-16,ISO S859-1,ANSI_X3.A,,,"For delimited files (CSV, TSV, etc.), the default character set is UTF-8.","https://docs.snowflake.com/en/sql-reference/sql/copy-into-table, https://docs.snowflake.com/en/user-guide/intro-summary-loading",,"Data Transformations, Data Loading and Unloading"
82,What are two ways to create and manage Data Shares in Snowflake? (Choose two.),"A,C",Via the Snowflake Web Interface (UI),Via the data_share=true parameter,Via SQL commands,Via Virtual Warehouses,,,,https://docs.snowflake.com/en/user-guide/data-sharing-provider#creating-a-share,,Data Protection and Data Sharing
83,A marketing co-worker has requested the ability to change a warehouse size on their medium virtual warehouse called MKTG_WH. Which of the following statements will accommodate this request?,C,ALLOW RESIZE ON WAREHOUSE MKTG_WH TO USER MKTG_LEAD;,GRANT MODIFY ON WAREHOUSE MKTG_WH TO USER MKTG_LEAD;,GRANT MODIFY ON WAREHOUSE MKTG_WH TO ROLE MARKETING;,GRANT OPERATE ON WAREHOUSE MKTG_WH TO ROLE MARKET;,,,"Virtual Warehouse privileges:\n
-USAGE - user can run queries on VWH\n
-MONITOR - stats about the VWH can be viewed\n
-MODIFY - Size of VWH can be changed\n
-OPERATE - VWH can be suspended or resumed\n
-OWNERSHIP - All\n
-ALL - All privileges, except Ownership","https://docs.snowflake.com/en/sql-reference/sql/grant-privilege, https://docs.snowflake.com/en/user-guide/security-access-control-privileges#virtual-warehouse-privileges",,"Data Transformations, Account Access and Security"
84,"True or False: 
A Virtual Warehouse can be resized while suspended.",A,TRUE,FALSE,,,,,,https://docs.snowflake.com/en/user-guide/warehouses-tasks#resizing-a-warehouse,,Performance Concepts
85,"When reviewing the load for a warehouse using the load monitoring chart, the chart indicates that a high volume of Queries are always queuing in the warehouse. 

According to recommended best practice, what should be done to reduce the Queue volume? (Choose two.)","A,D",Use multi-clustered warehousing to scale out warehouse capacity.,Scale up the warehouse size to allow Queries to execute faster.,Stop and start the warehouse to clear the queued queries,Migrate some queries to a new warehouse to reduce load,Limit user access to the warehouse so fewer queries are run against it.,,"Scale Out for concurrency (use of multi-cluster Warehouses) - reduce queueing\n
Split workload over different, independent warehouses to reduce queueing",https://docs.snowflake.com/en/user-guide/performance-query-warehouse-queue#options-for-reducing-queues,,Performance Concepts
86,"A user has an application that writes a new file to a cloud storage location every 5 minutes. 

What would be the MOST efficient way to get the files into Snowflake?",D,Create a task that runs a copy into operation from an external stage every 5 minutes,Create a task that puts the files in an internal stage and automate the data loading wizard,Create a task that runs a GET operation to intermittently check for new files,Set up cloud provider notifications on the file location and use Snowpipe with auto-ingest,,,"Pipes are highly scalable and cost-effective since they only incur charges when data is ingested, unlike other options like copying data at regular intervals or using external tables.",https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro,,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture"
87,A company strongly encourages all Snowflake users to self-enroll in Snowflake's default Multi-Factor Authentication (MFA) service to provide increased login security for users connecting to Snowflake. Which application will the Snowflake users need to install on their devices in order to connect with MFA?,B,Okta Verify,Duo Mobile,Microsoft Authenticator,Google Authenticator,,,"Snowflake integrates with the Duo Mobile app to provide multi-factor authentication (MFA) for users connecting to Snowflake. This means that in order to use MFA, Snowflake users need to have the Duo Mobile app installed on their devices and enroll in Snowflake's MFA service.\n

Okta Verify, Microsoft Authenticator, and Google Authenticator are alternative MFA apps, but they are not directly integrated with Snowflake and may not be supported for use with Snowflake's MFA service.",https://docs.snowflake.com/en/user-guide/security-mfa,,Account Access and Security
88,The fail-safe retention period is how many days?,B,1 day,7 days,45 days,90 days,,,,https://docs.snowflake.com/en/user-guide/data-failsafe,,Data Protection and Data Sharing
89,"True or False: 
Reader Accounts are able to extract data from shared data objects for use outside of Snowflake.",A,TRUE,FALSE,,,,,,https://docs.snowflake.com/en/user-guide/data-sharing-reader-create,,Data Protection and Data Sharing
90,What is the MOST performant file format for loading data in Snowflake?,C,CSV (Unzipped),Parquet,CSV (Gzipped),ORC,,,"Compressed structured data has best performance\n
Loading from Gzipped CSV is several times faster than loading from ORC and Parquet at an impressive 15 TB/Hour. While 5-6 TB/hour is decent if your data is originally in ORC or Parquet, don't go out of your way to CREATE ORC or Parquet files from CSV in the hope that it will load Snowflake faster.\n
Loading data into fully structured (columnarized) schema is ~10-20% faster than landing it into a VARIANT.","https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare, https://community.snowflake.com/s/article/How-to-Load-Terabytes-Into-Snowflake-Speeds-Feeds-and-Techniques",,"Data Loading and Unloading, Performance Concepts, Data Loading and Unloading"
91,Which cache type is used to cache data output from SQL queries?,B,Metadata cache,Result cache,Remote cache,Local file cache,,,"Result Cache: Which holds the results of every query executed in the past 24 hours. These are available across virtual warehouses, so query results returned to one user is available to any other user on the system who executes the same query, provided the underlying data has not changed.\n

Local Disk Cache: Which is used to cache data used by SQL queries. Whenever data is needed for a given query it's retrieved from the Remote Disk storage, and cached in SSD and memory.",https://docs.snowflake.com/en/user-guide/querying-persisted-results,,Performance Concepts
92,"True or False: 
When you create a custom role, it is a best practice to immediately grant that role to ACCOUNTADMIN.",B,TRUE,FALSE,,,,,Grant the Role to SYSADMIN,https://docs.snowflake.com/en/user-guide/security-access-control-overview#custom-roles,,Account Access and Security
93,What tasks can be completed using the copy command? (Choose two.),"C,D",Columns can be aggregated,Columns can be joined with an existing table,Columns can be reordered,Columns can be omitted,Data can be loaded without the need to spin up a virtual warehouse,,"Column actions:\n
-Reorder\n
-Omit\n
-Truncate\n
-Cast (change data type)",https://docs.snowflake.com/en/user-guide/data-load-transform,,"Data Transformations, Data Loading and Unloading"
94,Which of the following commands cannot be used within a reader account?,A,CREATE SHARE,ALTER WAREHOUSE,DROP ROLE,SHOW SCHEMAS,DESCRIBE TABLE,,"A reader account is a special type of user account that has read-only access to data in Snowflake. This means that reader accounts can only perform actions that are related to querying data, such as running SELECT statements and viewing metadata.\n

As a result, reader accounts cannot perform actions that modify the data or metadata stored in Snowflake, such as creating new objects, modifying existing objects, or dropping objects. This includes the CREATE SHARE command, which is used to create a new share and make it available to other users.",https://docs.snowflake.com/en/user-guide/data-sharing-reader-create,,Data Protection and Data Sharing
95,"A sales table FCT_SALES has 100 million records. The following Query was executed: 
    SELECT COUNT (1) FROM FCT_SALES; 

How did Snowflake fulfill this query?",D,Query against the result set cache,Query against a virtual warehouse cache,Query against the most-recently created micro-partition,Query against the metadata excite,,,"Metadata of Micro-Partitions:\n
-Max & Min of each column (=range)\n
-Count of distinct values for each column (SELECT COUNT(*).. / SELECT COUNT(1)..)\n
other information to assist in query optimization.",https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions,,Performance Concepts
96,Which command is used to unload data from a Snowflake table into a file in a stage?,A,COPY INTO,GET,WRITE,EXTRACT INTO,,,"In Snowflake, the ""COPY INTO"" command is used to unload data from a Snowflake table into a file in a stage. The stage acts as an intermediate storage location for the unloaded data, and the data can then be transferred to an external storage location such as Amazon S3 or Microsoft Azure Blob Storage.\n

Unload from TABLE into STAGE with COPY INTO, then use GET command to download locally or cloud provider tools (in case of External Stage) into (external) cloud storage\n

**Concept included in test from Sept 2024",https://docs.snowflake.com/en/user-guide/data-unload-snowflake,,Data Loading and Unloading
97,Which command can be used to load data into an internal stage?,D,LOAD,COPY,GET,PUT,,,"Use PUT command to upload data from local machine or On-Premise system into an internal stage\n
**Concept included in test from Sept 2024","https://docs.snowflake.com/en/sql-reference/sql/put, https://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage#types-of-internal-stages",,"Data Transformations, Data Loading and Unloading"
98,What Snowflake features allow virtual warehouses to handle high concurrency workloads? (Choose two.),"B,D",The ability to scale up warehouses,The use of warehouse auto scaling,The ability to resize warehouses,Use of multi-clustered warehouses,The use of warehouse indexing,,**Concept included in test from Sept 2024,https://docs.snowflake.com/en/user-guide/warehouses-considerations#multi-cluster-warehouses-improve-concurrency,,Performance Concepts
99,What transformations are supported in a CREATE PIPE .. AS COPY .. FROM (..)statement? (Choose two.),"C,D",Data can be filtered by an optional where clause,Incoming data can be joined with other tables,Columns can be reordered,Columns can be omitted,Row level access can be defined,,,https://docs.snowflake.com/en/sql-reference/sql/create-pipe#examples,,Data Transformations
100,What types of data listings are available in the Snowflake Data Marketplace? (Choose two.),"D,E",Reader,Consumer,Vendor,Standard,Personalized,,,https://docs.snowflake.com/en/user-guide/data-exchange-using#browse-data-listings,,Data Protection and Data Sharing
101,"Which Snowflake feature allows a user to substitute a randomly generated identifier for sensitive data, in order to prevent unauthorized users access to the data, before loading it into Snowflake?",A,External Tokenization,External Tables,Materialized Views,User-Defined Table Functions (UDTF),,,"-External Tokenization makes use of masking policies with external functions\n
-Enterprise feature\n
-Column-level security\n
-Data is pre-loaded into SF in an unreadable way\n
-Data can only be un-masked by use of an external token (increased security)","https://docs.snowflake.com/en/user-guide/security-column-ext-token-intro, https://docs.snowflake.com/en/sql-reference/external-functions",,"Data Protection and Data Sharing, Data Transformations"
102,Which Snowflake architectural layer is responsible for a query execution plan?,C,Compute,Data storage,Cloud services,Cloud provider,,,"The cloud services layer is a collection of services that coordinate activities across Snowflake. These services tie together all of the different components of Snowflake in order to process user requests, from login to query dispatch. The cloud services layer also runs on compute instances provisioned by Snowflake from the cloud provider.\n

Services managed in this layer include:\n
-Authentication\n
-Infrastructure management\n
-Metadata management\n
-Query parsing and optimization\n
-Access control",https://docs.snowflake.com/en/user-guide/intro-key-concepts,,Snowflake AI Data Cloud Features and Architecture
103,What file formats does Snowflake support for loading semi-structured data? (Choose three.),"B,D,E",TSV,JSON,PDF,Avro,Parquet,JPEG,"TSV = structured\n
JSON = semi-structured\n
PDF = unstructured\n
Avro = semi-structured\n
Parquet = semi-structured\n
JPEG = unstructured\n

Snowflake can import semi-structured data from JSON, Avro, ORC, Parquet, and XML formats and store it in Snowflake data types designed specifically to support semi-structured data.","https://docs.snowflake.com/en/user-guide/data-load-prepare#supported-file-formats, https://docs.snowflake.com/en/user-guide/semistructured-intro",,Data Loading and Unloading
104,How often are the Account and Table master keys automatically rotated by Snowflake?,A,30 Days,60 Days,90 Days,365 Days,,,All Snowflake-managed keys are automatically rotated by Snowflake when they are more than 30 days old.,https://docs.snowflake.com/en/user-guide/security-encryption-manage#encryption-key-rotation,,Data Protection and Data Sharing
105,"lf a Snowflake user decides a table should be clustered, what should be used as the cluster key?",D,The columns that are queried in the select clause.,The columns with very high cardinality.,The columns with many different values.,The columns most actively used in the select filters.,,,**Concept included in test from Sept 2024,https://docs.snowflake.com/en/user-guide/tables-clustering-keys#strategies-for-selecting-clustering-keys,,Performance Concepts
106,Which of the following objects can be directly restored using the UNDROP command? (Choose two.),"A,D",Schema,View,Internal stage,Table,User,Role,"Account Objects:\n
-UNDROP DATABASE\n

Database Objects:\n
-UNDROP SCHEMA\n
-UNDROP TABLE\n
-UNDROP TAG\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/sql-reference/sql/undrop,,Data Transformations
107,Which Snowflake layer is always leveraged when accessing a query from the result cache?,D,Metadata,Data Storage,Compute,Cloud Services,,,,https://community.snowflake.com/s/article/Caching-in-the-Snowflake-Cloud-Data-Platform,,"Performance Concepts, Snowflake AI Data Cloud Features and Architecture"
108,Which of the following are best practices for loading data into Snowflake? (Choose three.),"A,C,D","Aim to produce data files that are between 100 MB and 250 MB in size, compressed.","Load data from files in a cloud storage service in a different region or cloud platform from the service or region containing the Snowflake account, to save on cost.",Enclose fields that contain delimiter characters in single or double quotes.,Split large files into a greater number of smaller files to distribute the load among the compute resources in an active warehouse.,"When planning which warehouses to use for data loading, start with the largest warehouse possible.","Partition the staged data into large folders with random paths, allowing Snowflake to determine the best way to load each file.","To optimize the number of parallel operations for a load, we recommend aiming to produce data files roughly 100-250 MB (or larger) in size compressed.\n

Fields that contain delimiter characters should be enclosed in quotes (single or double). If the data contains single or double quotes, then those quotes must be escaped.\n

Split larger files into a greater number of smaller files to distribute the load among the compute resources in an active warehouse.",https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare,,Data Loading and Unloading
109,How can a user change which columns are referenced in a view?,C,Modify the columns in the underlying table,Use the ALTER VIEW command to update the view,Recreate the view with the required changes,Materialize the view to perform the changes,,,"Only limited actions are possible via ALTER VIEW command:\n
-Renaming a view.\n
-Converting to (or reverting from a secure view.\n
-Adding, overwriting, removing a comment for a view.\n
The definition of a view can NOT be changed via ALTER VIEW..\n
Note that you cannot use this command to change the definition for a view. To change the view definition, you must drop the view and then recreate it. ","https://docs.snowflake.com/en/user-guide/views-introduction#label-views-introduction-limitations, https://docs.snowflake.com/en/sql-reference/sql/alter-view#alter-view",,"Performance Concepts, Data Transformations"
110,Which of the following features are available with the Snowflake Enterprise edition? (Choose two.),"D,E",Database replication and failover,Automated index management,Customer managed keys (Tri-secret secure),Extended time travel,Native support for geospatial data,,"Replication failover = Business Critical+\n
Automated index management = Does not exist in Snowflake\n
Tri-secret = Business Critical+\n
Extended time travel = Enterprise+\n
Geospatial = Standard+\n",https://docs.snowflake.com/en/user-guide/intro-editions,,Snowflake AI Data Cloud Features and Architecture
111,Network policies can be applied to which of the following Snowflake objects? (Choose two.),"D,E",Roles,Databases,Warehouses,Users,Accounts,,**Concept included in test from Sept 2024,https://docs.snowflake.com/en/user-guide/network-policies#label-associating-network-policies,,Account Access and Security
112,"When cloning a database containing stored procedures and regular views, that have fully qualified table references, which of the following will occur?",D,The cloned views and the stored procedures will reference the cloned tables in the cloned database.,"An error will occur, as views with qualified references cannot be cloned.","An error will occur, as stored objects cannot be cloned.",The stored procedures and views will refer to tables in the source database.,,,,"https://docs.snowflake.com/en/user-guide/object-clone, https://docs.snowflake.com/en/sql-reference/sql/create-clone",,"Performance Concepts, Data Transformations"
113,Which formats does Snowflake store unstructured data in? (Choose two.),"B,D",GeoJSON,Array,XML,Object,BLOB,,**Concept included in test from Sept 2024,https://docs.snowflake.com/en/user-guide/unstructured-intro,,Data Loading and Unloading
114,Snowflake supports the use of external stages with which cloud platforms? (Choose three.),"A,D,E",Amazon Web Services,Docker,IBM Cloud,Microsoft Azure Cloud,Google Cloud Platform,Oracle Cloud,,https://docs.snowflake.com/en/user-guide/data-load-overview#label-data-load-overview-external-stages,,Data Loading and Unloading
115,What is the MINIMUM Snowflake edition required to use the periodic rekeying of micro-partitions?,A,Enterprise,Business Critical,Standard,Virtual Private Snowflake,,,Periodic rekeying requires Enterprise Edition (or higher).,"https://docs.snowflake.com/en/user-guide/intro-editions, https://docs.snowflake.com/en/user-guide/security-encryption-manage#label-periodic-rekeying",,"Snowflake AI Data Cloud Features and Architecture, Data Protection and Data Sharing"
116,When loading data into Snowflake via Snowpipe what is the compressed file size recommendation?,B,10-50 MB,100-250 MB,300-500 MB,1000-1500 MB,,,"We recommend files at least above 10 MB on average, with files in the 100 to 250 MB range offering the best cost-to-performance ratio.","https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare#continuous-data-loads-i-e-snowpipe-and-file-sizing, https://www.snowflake.com/blog/best-practices-for-data-ingestion",,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture"
117,What are best practice recommendations for using the ACCOUNTADMIN system-defined role in Snowflake? (Choose two.),"A,D",Ensure all ACCOUNTADMIN roles use Multi-factor Authentication (MFA).,All users granted ACCOUNTADMIN role must be owned by the ACCOUNTADMIN role.,The ACCOUNTADMIN role must be granted to only one user.,"Assign the ACCOUNTADMIN role to at least two users, but as few as possible.",All users granted ACCOUNTADMIN role must also be granted SECURITYADMIN role.,,,https://docs.snowflake.com/en/user-guide/security-access-control-considerations#control-the-assignment-of-the-accountadmin-role-to-users,,Account Access and Security
118,The Snowflake Cloud Data Platform is described as having which of the following architectures?,C,Shared-disk,Shared-nothing,Multi-cluster shared data,Serverless query engine,,,Snowflake's architecture is a hybrid of traditional shared-disk and shared-nothing database architectures.,"https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture, https://www.snowflake.com/product/architecture/",,Snowflake AI Data Cloud Features and Architecture
119,What features that are part of the Continuous Data Protection (CDP) feature set in Snowflake do not require additional configuration? (Choose two.),"C,D",Row level access policies,Data masking policies,Data encryption,Time Travel,External tokenization,,Time Travel and Data encryption are enabled by default. Default time travel setting: 1 Day,https://docs.snowflake.com/en/user-guide/data-cdp,,Data Protection and Data Sharing
120,"Which command should be used to load data from a file, located in an external stage, into a table in Snowflake?",D,INSERT,PUT,GET,COPY,,,"-From local machine or On-Premise into internal stage: PUT\n
-From Cloud storage into External stage: Cloud-Provider tools\n
-From External Stage into table: COPY INTO\n
-From Internal Stage into table: COPY INTO\n

**Concept included in test from Sept 2024",https://docs.snowflake.com/en/sql-reference/sql/copy-into-table,,Data Transformations
121,A user is preparing to load data from an external stage. Which practice will provide the MOST efficient loading performance?,A,Organize files into logical paths,Store the files on the external stage to ensure caching is maintained,Use pattern matching for regular expression execution,Load the data in one large file,,,"When staging regular data sets, we recommend partitioning the data into logical paths that include identifying details such as geographical location or other source identifiers, along with the date when the data was written.\n

Organizing your data files by path lets you copy any fraction of the partitioned data into Snowflake with a single command. This allows you to execute concurrent COPY statements that match a subset of files, taking advantage of parallel operations.\n

**Concept included in test from Sept 2024",https://docs.snowflake.com/en/user-guide/data-load-considerations-stage#label-organizing-data-by-path,,Data Loading and Unloading
122,What versions of Snowflake should be used to manage compliance with Personal Identifiable Information (PII) requirements? (Choose two.),"B,C",Custom Edition,Virtual Private Snowflake,Business Critical Edition,Standard Edition,Enterprise Edition,,,https://docs.snowflake.com/en/user-guide/intro-editions#business-critical-edition,,Snowflake AI Data Cloud Features and Architecture
123,Which of the following are characteristics of Snowflake virtual warehouses? (Choose two.),"C,E",Auto-resume applies only to the last warehouse that was started in a multi-cluster warehouse.,The ability to auto-suspend a warehouse is only available in the Enterprise edition or above.,SnowSQL supports both a configuration file and a command line option for specifying a default warehouse.,A user cannot specify a default warehouse when using the ODBC driver.,The default virtual warehouse size can be changed at any time.,,,https://docs.snowflake.com/en/user-guide/warehouses-overview#default-warehouse-for-client-utilities-drivers-connectors,,Performance Concepts
124,What internal stages are available in Snowflake? (Choose three.),"B,C,E",Schema stage,Named stage,User stage,Stream stage,Table stage,Database stage,,https://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage,,Data Loading and Unloading
125,Which of the following are handled by the cloud services layer of the Snowflake architecture? (Choose two.),"D,E",Query execution,Data loading,Time Travel data,Security,Authentication and access control,,"The cloud services layer is a collection of services that coordinate activities across Snowflake. These services tie together all of the different components of Snowflake in order to process user requests, from login to query dispatch. The cloud services layer also runs on compute instances provisioned by Snowflake from the cloud provider. Services managed in this layer include:\n
-Authentication\n
-Infrastructure management\n
-Metadata management\n
-Query parsing and optimization\n
-Access control",https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture,,Snowflake AI Data Cloud Features and Architecture
126,What are supported file formats for unloading data from Snowflake? (Choose three.),"B,C,F",XML,JSON,Parquet,ORC,AVRO,CSV,"XML, ORC, and AVRO are supported file types for loading data but not supporting for unloading","https://docs.snowflake.com/en/user-guide/data-unload-prepare, https://docs.snowflake.com/en/user-guide/data-load-prepare, https://docs.snowflake.com/en/user-guide/intro-summary-unloading",,Data Loading and Unloading
127,"A Snowflake Administrator needs to ensure that sensitive corporate data in Snowflake tables is not visible to end users, but is partially visible to functional managers. 

How can this requirement be met?",B,Use data encryption.,Use dynamic data masking.,Use secure materialized views.,Revoke all roles for functional managers and end users.,,,"Masking policy administrators can implement a masking policy such that analysts (i.e. users with the custom ANALYST role) can only view the last four digits of a phone number and none of the social security number, while customer support representatives (i.e. users with the custom SUPPORT role) can view the entire phone number and social security number for customer verification use cases.\n

Column-Level security\n
Enterprise+",https://docs.snowflake.com/en/user-guide/security-column-intro#what-are-masking-policies,,Data Protection and Data Sharing
128,Which of the following accurately describes shares?,A,"Tables, secure views, and secure UDFs can be shared",Shares can be shared,Data consumers can clone a new table from a share,Access to a share cannot be revoked once granted,,,"Tables\n
External Tables\n
Secure Views\n
Secure Materialized Views\n
Secure UDFs","https://docs.snowflake.com/en/user-guide/data-sharing-provider#preparing-to-create-a-share, https://docs.snowflake.com/en/user-guide/data-sharing-intro",,Data Protection and Data Sharing
129,"A company needs to allow some users to see Personally Identifiable Information (PII) while limiting other users from seeing the full value of the PlI. 

Which Snowflake feature will support this?",B,Row access policies,Data masking policies,Data encryption,Role based access control,,,,https://docs.snowflake.com/en/user-guide/security-column-ddm-intro,,Data Protection and Data Sharing
130,Which of the following are characteristics of security in Snowflake?,C,Account and user authentication is only available with the Snowflake Business Critical edition.,Support for HIPAA and GDPR compliance is available for Ul Snowflake editions.,Periodic rekeying of encrypted data is available with the Snowflake Enterprise edition and higher,Private communication to internal stages is allowed in the Snowflake Enterprise edition and higher.,,,"Authentication available to all account\n
HIPAA and GDPR available for all\n
Private communication to internal stages available to all","https://docs.snowflake.com/en/user-guide/security-encryption-manage, https://docs.snowflake.com/en/user-guide/intro-editions",,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
131,What are the correct parameters for time travel and fail-safe in the Snowflake Enterprise Edition?,D,Default Time Travel Retention is set to 0 days / Maximum Time Travel Retention is 30 days / Fail Safe retention time is 1 day.,Default Time Travel Retention is set to 1 day / Maximum Time Travel Retention is 365 days / Fail Safe retention time is 7 days.,Default Time Travel Retention is set to 0 days / Maximum Time Travel Retention is 90 days / Fail Safe retention time is 7 days.,Default Time Travel Retention is set to 1 day / Maximum Time Travel Retention is 90 days / Fail Safe retention time is 7 days.,Default Time Travel Retention is set to 7 days / Maximum Time Travel Retention is 1 day / Fail Safe retention time is 90 days.,Default Time Travel Retention is set to 90 days / Maximum Time Travel Retention is 7 days / Fail Safe retention time is 356 days.,,"https://docs.snowflake.com/en/user-guide/data-time-travel#enabling-and-deactivating-time-travel, https://docs.snowflake.com/en/user-guide/data-failsafe",,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
132,Which minimum Snowflake edition allows for a dedicated metadata store?,D,Standard,Enterprise,Business Critical,Virtual Private Snowflake,,,Dedicated metadata store and pool of compute resources (used in virtual warehouses) is offered through VPS,https://docs.snowflake.com/en/user-guide/intro-editions#security-governance-and-data-protection,,"Snowflake AI Data Cloud Features and Architecture, Data Protection and Data Sharing"
133,What type of query benefits the MOST from search optimization?,C,"A query that uses only disjunction (i.e., OR) predicates",A query that includes analytical expressions,A query that uses equality predicates or predicates that use IN,A query that filters on semi-structured data types,,,**Concept included in test from Sept 2024,"https://docs.snowflake.com/en/user-guide/search-optimization/queries-that-benefit, https://docs.snowflake.com/en/user-guide/search-optimization-service#understanding-the-search-optimization-service, https://community.snowflake.com/s/article/Search-Optimization-When-How-To-Use",,"Performance Concepts, Snowflake AI Data Cloud Features and Architecture"
134,"A user created a transient table and made several changes to it over the course of several days. Three days after the table was created, the user would like to go back to the first version of the table. 

How can this be accomplished?",B,"Use Time Travel, as long as DATA_RETENTION_TIME_IN_DAYS was set to at least 3 days.",The transient table version cannot be retrieved after 24 hours.,Contact Snowflake Support to have the data retrieved from Fail-safe storage.,Use the FAIL_SAFE parameter for Time Travel to retrieve the data from Fail-safe storage.,,,"Temporary and Transient tables:\n
-Time Travel: Max. 1 day\n
-Failsafe: 0 (none)",https://docs.snowflake.com/en/user-guide/tables-temp-transient#transient-tables,,Performance Concepts
135,Users are responsible for data storage costs until what occurs?,B,Data expires from Time Travel,Data expires from Fail-safe,Data is deleted from a table,Data is truncated from a table,,,"Storage is calculated and charged for data regardless of whether it is in the Active, Time Travel, or Fail-safe state. Because these life-cycle states are sequential, updated/deleted data protected by CDP will continue to incur storage costs until the data leaves the Fail-safe state.","https://docs.snowflake.com/en/user-guide/data-cdp-storage-costs, https://docs.snowflake.com/en/user-guide/tables-storage-considerations",,"Data Protection and Data Sharing, Performance Concepts"
136,What is the minimum Snowflake edition required for row level security?,B,Standard,Enterprise,Business Critical,Virtual Private Snowflake,,,,https://docs.snowflake.com/en/user-guide/intro-editions#security-governance-and-data-protection,,"Snowflake AI Data Cloud Features and Architecture, Data Protection and Data Sharing"
137,"A single user of a virtual warehouse has set the warehouse to auto-resume and auto-suspend after 10 minutes. The warehouse is currently suspended and the user performs the following actions: 
1. Runs a query that takes 3 minutes to complete 
2. Leaves for 15 minutes 
3. Returns and runs a query that takes 10 seconds to complete 
4. Manually suspends the warehouse as soon as the last query was completed 

When the user returns, how much billable compute time will have been consumed?",C,4 minutes,10 minutes,14 minutes,24 minutes,,,"3 Min\n
10 Min (after 10 Min VWH gets auto-suspended)\n
1 Min (after resuming minimum charge is 60 seconds, even when suspended earlier than that)",https://docs.snowflake.com/en/user-guide/cost-understanding-compute#label-virtual-warehouse-credit-usage,,Performance Concepts
138,"Which of the following features, associated with Continuous Data Protection (CDP), require additional Snowflake-provided data storage? (Choose two.)","B,C",Tri-Secret Secure,Time Travel,Fail-safe,Data encryption,External stages,,"Both Time Travel and Fail-safe require additional data storage, which has associated fees .","https://docs.snowflake.com/en/user-guide/data-availability, https://docs.snowflake.com/en/user-guide/data-cdp",,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
139,How would a user execute a series of SQL statements using a task?,C,Include the SQL statements in the body of the task CREATE TASK mytask . AS INSERT INTO target SELECT . FROM stream_s1 WHERE.. INSERT INTO target2 SELECT .. FROM stream_s1 WHERE .,A stored procedure can have only one DML statement per stored procedure invocation and therefore the user should sequence stored procedure calls in the task definition CREATE TASK mytask .. AS call stored_proc1); call stored_proc2);,Use a stored procedure executing multiple SQL statements and invoke the stored procedure from the task. CREATE TASK mytask .. AS call stored_proc_multiple_statements_inside);,"Create a task for each SQL statement (e.g. resulting in task1, task2, etc.) and string the series of SQL statements by having a control task calling task1, task2, etc. sequentially.",,,"A task can just submit a single SQL statement, unless it is calling a stored procedure with multiple statements in it","https://docs.snowflake.com/en/user-guide/tasks-intro, https://docs.snowflake.com/en/developer-guide/stored-procedure/stored-procedures-overview, https://docs.snowflake.com/en/sql-reference/stored-procedures-overview#what-is-a-stored-procedure",,"Performance Concepts, Data Transformations"
140,When publishing a Snowflake Data Marketplace listing into a remote region what should be taken into consideration? (Choose two.),"B,C","There is no need to have a Snowflake account in the target region, a share will be created for each user.","The listing is replicated into all selected regions automatically, the data is not.",The user must have the ORGADMIN role available in at least one account to link accounts for replication.,Shares attached to listings in remote regions can be viewed from any account in an organization.,For a standard listing the user can wait until the first customer requests the data before replicating it to the target region.,,**Concept included in test from Sept 2024,https://docs.snowflake.com/en/user-guide/data-exchange-managing-data-listings,,Data Protection and Data Sharing
141,Which file formats are supported for unloading data from Snowflake? (Choose two.),"B,E",Avro,JSON,ORC,XML,"Delimited (CSV, TSV, etc.)",,"Delimited (CSV,TSV, etc. = structured)\n
JSON, PARQUET (semi structured)",https://docs.snowflake.com/en/user-guide/intro-summary-unloading,,Data Loading and Unloading
142,What is a responsibility of Snowflake's virtual warehouses?,C,Infrastructure management,Metadata management,Query execution,Query parsing and optimization,Permanent storage of micro-partitions,,"-Infrastructure, Management, Metadata Management, and Query Parsing and Optimization = Cloud Services Layer\n
-Query Execution = Compute Layer (Virtual Warehouses)\n
-Storage of micro-partitions = Storage Layer","https://docs.snowflake.com/en/user-guide/intro-key-concepts, https://docs.snowflake.com/en/user-guide/warehouses-overview",,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
143,The Snowflake cloud services layer is responsible for which tasks? (Choose two.),"B,C",Local disk caching,Authentication and access control,Metadata management,Query processing,Database storage,,"Local disk caching and Query processing = Compute Layer\n
Database storage = Storage Layer",https://docs.snowflake.com/en/user-guide/intro-key-concepts,,Snowflake AI Data Cloud Features and Architecture
144,Which of the following statements apply to Snowflake in terms of security? (Choose two.),"A,C",Snowflake leverages a Role-Based Access Control (RBAC) model.,Snowflake requires a user to configure an IAM user to connect to the database.,All data in Snowflake is encrypted.,Snowflake can run within a user's own Virtual Private Cloud (VPC).,All data in Snowflake is compressed.,,"Snowflake is a native 100% public cloud solution, you cannot host it on your OWN VPC. All data micro partitions are encrypted.","https://docs.snowflake.com/en/guides-overview-secure, https://docs.snowflake.com/en/user-guide/data-cdp",,"Data Protection and Data Sharing, Account Access and Security"
145,"True or False: 
Snowpipe via REST API can only reference External Stages as source.",B,TRUE,FALSE,,,,,"There are two mechanisms for detecting if staged files are available:\n
-Automating Snowpipe using cloud messaging (auto_ingest = TRUE) - For External Stages only as it uses Cloud Notification Services\n
-Calling Snowpipe REST endpoints → For External or Internal Stages","https://docs.snowflake.com/en/user-guide/data-load-snowpipe-rest-load, https://docs.snowflake.com/en/user-guide/data-load-snowpipe-auto-s3",,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture"
146,A materialized view should be created when which of the following occurs? (Choose two.),"B,E",There is minimal cost associated with running the query.,The query consumes many compute resources every time it runs.,The base table gets updated frequently.,The query is highly optimized and does not consume many compute resources.,The results of the query do not change often and are used frequently.,,"Materialized views pre-compute resource intensive queries.\n
This safes resources, but the results shouldn't change too often as this would increase maintenance costs\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/user-guide/views-materialized#deciding-when-to-create-a-materialized-view,,Performance Concepts
147,"A company needs to read multiple terabytes of data for an initial load as part of a Snowflake migration. The company can control the number and size of CSV extract files. 

How does Snowflake recommend maximizing the load performance?",C,Use auto-ingest Snowpipes to load large files in a serverless model.,"Produce the largest files possible, reducing the overall number of files to process.",Produce a larger number of smaller files and process the ingestion with size Small virtual warehouses.,Use an external tool to issue batched row-by-row inserts within BEGIN TRANSACTION and COMMIT commands.,,,Make use of parallelization when loading,https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare,,Data Loading and Unloading
148,What is cached during a query on a virtual warehouse?,D,All columns in a micro-partition,Any columns accessed during the query,The columns in the result set of the query,All rows accessed during the query,,,Local VWH cache. Gets cleared when Warehouse is suspended,https://docs.snowflake.com/en/user-guide/performance-query-warehouse-cache,,Performance Concepts
149,Which snowflake objects will incur both storage and cloud compute charges? (Choose two.),"A,E",Materialized view,Sequence,Secure view,Transient table,Clustered table,,"Serverless compute charges because data changes need to be reflected / maintained\n

Clustered table needs to undergo clustering as the data changes and Materialized view also undergoes changes every time the underlying data changes or when the view is set to refresh.\n

**Concept included in test from Sept 2024","https://docs.snowflake.com/en/user-guide/cost-understanding-compute, https://docs.snowflake.com/en/user-guide/cost-understanding-data-storage",,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
150,What actions will prevent leveraging of the ResultSet cache? (Choose two.),"A,C",Removing a column from the query SELECT list,Stopping the virtual warehouse that the query is running against,Clustering of the data used by the query,Executing the RESULTS_SCAN() table function,Changing a column that is not in the cached query,,"-The new query syntactically matches the previously-executed query.\n
-The query does not include functions that must be evaluated at execution time (e.g. CURRENT TIMESTAMP and UUID STRING()\n
-Exception: CURRENT DATE function\n
-The query does not include user-defined functions (UDFs) or external functions.\n
-The table data contributing to the query result has not changed.\n
-The persisted result for the previous query is still available.\n
-The role accessing the cached results has the required privileges.\n
-Any configuration options that affect how the result was produced have not changed.\n
-The table's micro-partitions have not changed (e.g. been reclustered or consolidated)

","https://docs.snowflake.com/en/sql-reference/functions/current_timestamp, https://docs.snowflake.com/en/sql-reference/functions/uuid_string, https://docs.snowflake.com/en/sql-reference/functions/current_date, https://docs.snowflake.com/en/sql-reference/udf-overview, https://docs.snowflake.com/en/sql-reference/external-functions",,Data Transformations
151,Which columns are part of the result set of the Snowflake LATERAL FLATTEN command? (Choose two.),"B,D",CONTENT,PATH,BYTE_SIZE,INDEX,DATATYPE,,"Flatten output:\n
| SEQ |  KEY | PATH | INDEX | VALUE | THIS |\n

In the exam 25-MAR-2023\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/sql-reference/functions/flatten#output,,Data Transformations
152,Which URL type allows users to access unstructured data without authenticating into Snowflake or passing an authorization token?,A,Pre-signed URL,Scoped URL,Signed URL,File URL,,,"Pre-signed URLs are used to download or access files, via a web browser for example, without authenticating into Snowflake or passing an authorization token. These URLs are ideal for business intelligence applications or reporting tools that need to display the unstructured file contents.\n

Pre-Signed URL:\n
-GET_PRESIGNED_URL\n
-HTTPS URL\n
-Usage: BI Tools + Reporting\n
-Pre-signed access token (configurable)\n
-File support REST API: No\n
-Access files WITHOUT Authentication\n
-EXPIRATION_TIME argument (in seconds)\n
-Default: 3600 Seconds = 60 Minutes)\n

In the exam 25-MAR-2023\n
**Concept included in test from Sept 2024","https://docs.snowflake.com/en/user-guide/unstructured-intro#types-of-urls-available-to-access-files, https://docs.snowflake.com/en/sql-reference/functions/get_presigned_url",,"Data Loading and Unloading, Data Transformations"
153,What is the minimum Snowflake edition required to use Dynamic Data Masking?,B,Standard,Enterprise,Business Critical,Virtual Private Snowflake (VPC),,,"Dynamic data masking require Enterprise edition or higher edition.\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/user-guide/intro-editions#security-governance-data-protection,,"Snowflake AI Data Cloud Features and Architecture, Data Protection and Data Sharing"
154,Which stages are used with the Snowflake PUT command to upload files from a local file system? (Choose three.),"B,D,F",Schema Stage,User Stage,Database Stage,Table Stage,External Named Stage,Internal Named Stage,"PUT works with internal stages only\n
Use to upload data from local / on-prem system\n
External stages relate to data in the Cloud. Use Cloud provider tools to upload in this case\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/sql-reference/sql/put,,Data Transformations
155,Which of the following practices are recommended when creating a user in Snowflake? (Choose two.),"B,C",Configure the user to be initially disabled.,Force an immediate password change.,Set a default role for the user.,Set the number of minutes to unlock to 15 minutes.,Set the user's access to expire within a specified timeframe.,,,"https://docs.snowflake.com/en/sql-reference/sql/create-user#examples, https://docs.snowflake.com/en/user-guide/admin-user-management#creating-users",,"Data Transformations, Account Access and Security"
156,Which of the following statements describes a schema in Snowflake?,A,A logical grouping of objects that belongs to a single database,A logical grouping of objects that belongs to multiple databases,A named Snowflake object that includes all the information required to share a database,A uniquely identified Snowflake account within a business entity,,,A database can have multiple schemas but not the other way round,https://docs.snowflake.com/en/sql-reference/ddl-database,,Data Transformations
157,Which data types are supported by Snowflake when using semi-structured data? (Choose two.),"A,D",VARIANT,VARRAY,STRUCT,ARRAY,QUEUE,,"VARIANT, ARRAY, OBJECT\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/sql-reference/data-types-semistructured,,Data Transformations
158,Which Snowflake tool would be BEST to troubleshoot network connectivity?,D,SnowCLI,SnowUl,SnowSQL,SnowCD,,,SnowCD (i.e. Snowflake Connectivity Diagnostic Tool) helps users to diagnose and troubleshoot their network connection to Snowflake.,https://docs.snowflake.com/en/user-guide/snowcd,,"Snowflake AI Data Cloud Features and Architecture, Account Access and Security"
159,How does Snowflake allow a data provider with an Azure account in central Canada to share data with a data consumer on AWS in Australia?,D,"The data provider in Azure Central Canada can create a direct share to AWS Asia Pacific, if they are both in the same organization.",The data consumer and data provider can form a Data Exchange within the same organization to create a share from Azure Central Canada to AWS Asia Pacific.,The data provider uses the GET DATA workflow in the Snowflake Data Marketplace to create a share between Azure Central Canada and AWS Asia Pacific.,The data provider must replicate the database to a secondary account in AWS Asia Pacific within the same organization then create a share to the data consumer's account.,,,Database replication required for cross-region sharing,https://docs.snowflake.com/en/user-guide/secure-data-sharing-across-regions-platforms,,Data Protection and Data Sharing
160,"Which Snowflake function will interpret an input string as a JSON document, and produce a VARIANT value?",A,parse _json(),json_extract_path_text(),object_construct),flatten,,,"Interprets an input string as a JSON document, producing a VARIANT value.\n

Syntax PARSE_JSON( <expr> )\n

**Concept included in test from Sept 2024",https://docs.snowflake.com/en/sql-reference/functions/parse_json,,Data Transformations
161,Which command sets the Virtual Warehouse for a session?,C,COPY WAREHOUSE FROM «config file>>;,SET WAREHOUSE = <<warehouse name>>;,USE WAREHOUSE <<warehouse name»>;,USE VIRTUAL_WAREHOUSE <<warehouse name>>;,,,,https://docs.snowflake.com/en/sql-reference/sql/use-warehouse,,Data Transformations
162,What is the recommended compressed file size range for continuous data loads using Snowpipe?,D,8-16 MB,16-24 MB,10-99 MB,100-250 MB,,,"Snowpipe is typically used to load data that is arriving continuously. File sizing plays an important role in Snowpipe's performance. The recommended file size for data loading is 100-250MB compressed, however, if data is arriving continuously, then try to stage the data within one-minute intervals.",https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare#continuous-data-loads-i-e-snowpipe-and-file-sizing,,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture"
163,"A table needs to be loaded. The input data is in JSON format and is a concatenation of multiple JSON documents. The file size is 3 GB. A warehouse size small is being used. The following COPY INTO command was executed: 

COPY INTO SAMPLE FROM @~/SAMPLE.JSON (TYPE=JSON) 

The load failed with this error: Max LOB size (16777216) exceeded, actual size of parsed column is 17894470. 

How can this issue be resolved?",D,Compress the file and load the compressed file.,Split the file into multiple files in the recommended size range (100 MB - 250 MB).,Use a larger-sized warehouse.,Set STRIP_OUTER_ARRAY=TRUE in the COPY INTO command.,,,"Max. Variant file size is 16MB and the file is too large here.\n
STRIP_OUTER_ARRAY helps to split the file into multiple (smaller) rows to make the load possible.\n",https://docs.snowflake.com/en/user-guide/semistructured-considerations#data-size-limitations,,Data Loading and Unloading
164,What happens to historical data when the retention period for an object ends?,B,The data is cloned into a historical object.,The data moves to Fail-safe,Time Travel on the historical data is dropped.,The object containing the historical data is dropped.,,,"When the retention period ends for an object, the historical data is moved into Snowflake Fail-safe.\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/user-guide/data-time-travel#data-retention-period,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
165,"Which of the following is an example of an operation that can be completed without requiring compute, assuming no queries have been executed previously?",C,SELECT SUM (ORDER_AMT) FROM SALES;,SELECT AVG(ORDER_QTY) FROM SALES;,SELECT MIN(ORDER_AMT) FROM SALES;,SELECT ORDER_AMT * ORDER_QTY FROM SALES;,,,"""assuming that no query has been executed before"" means that options that could take advantage of the cache and not require computation are wrong\n

Snowflake stores the MIN and MAX-values of each column of each micro-partition in it's Cloud Services Layer and also the COUNT DISTINCT.\n

Snowflake stores metadata about all rows stored in a micro-partition, including:\n
-The range of values for each of the columns in the micro-partition.\n
-The number of distinct values.\n
-Additional properties used for both optimization and efficient query processing.",https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#what-are-micro-partitions,,Performance Concepts
166,Where can a user find and review the failed logins of a specific user for the past 30 days?,B,The USERS view in ACCOUNT_USAGE,The LOGIN_HISTORY view in ACCOUNT_USAGE,The ACCESS_HISTORY view in ACCOUNT_USAGE,The SESSIONS view in ACCOUNT_USAGE,,,**Concept included in test from Sept 2024,https://docs.snowflake.com/en/sql-reference/account-usage/login_history,,Data Transformations
167,"A virtual warehouse is created using the following command: 

Create warehouse my_WH with 
warehouse_size = MEDIUM 
min_cluster_count = 1 
max_cluster_count = 1 
auto_suspend = 60 
auto_resume = true; 

The image below is a graphical representation of the warehouse utilization across two days. 

What action should be taken to address this situation?",C,Increase the warehouse size from Medium to 2XL.,Increase the value for the parameter MAX_CONCURRENCY_LEVEL.,Configure the warehouse to a multi-cluster warehouse.,Lower the value of the parameter STATEMENT_QUEUED_TIMEOUT_IN_SECONDS,,,"Multi-Cluster Warehouses = scaling out for concurrency / to reduce queueing\n

Multi-cluster is the solution for concurrency. Default MAX_CONCURRENCY_LEVEL is 8. Therefore, concurrency is not an issue. We need multi-cluster warehouses for scale-out.","https://docs.snowflake.com/en/user-guide/performance-query-warehouse-queue#options-for-reducing-queues, https://docs.snowflake.com/en/sql-reference/parameters#max-concurrency-level",https://i.imgur.com/dELZwcZ.jpeg,"Performance Concepts, Data Transformations"
168,"In a Snowflake role hierarchy, what is the top-level role?",C,SYSADMIN,ORGADMIN,ACCOUNTADMIN,SECURITYADMIN,,,ORGADMIN is a separate role and not part of the role hierarchy,https://docs.snowflake.com/en/user-guide/security-access-control-overview#label-role-hierarchy-and-privilege-inheritance,,Account Access and Security
169,"Assume there is a table consisting of five micro-partitions with values ranging from A to Z. 

Which diagram indicates a well-clustered table?",A,Option A,Option B,Option C,Option D,,,"When there is no overlap in the range of values across all micro-partitions, the micro-partitions are considered to be in a constant state (i.e. they cannot be improved by clustering).\n

A) Clustering Depth is ideal (=1)\n
In the exam 25-MAR-2023",https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#clustering-depth,https://i.imgur.com/MaMZsMA.jpeg,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
170,What is the minimum Fail-safe retention time period for transient tables?,D,1 day,7 days,12 hours,0 days,,,"Failsafe for Permanent tables = 7 days, for Temporary, Transient and External tables = 0 days (no failsafe)\n
**Concept included in test from Sept 2024","https://docs.snowflake.com/en/user-guide/data-failsafe, https://docs.snowflake.com/en/user-guide/tables-temp-transient",,"Data Protection and Data Sharing, Performance Concepts"
171,Which command can be used to load data files into a Snowflake stage?,C,JOIN,COPY INTO,PUT,GET,,,"From Local / on-prem into internal stage → PUT\n
From stage into table → COPY INTO\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/sql-reference/sql/put,,Data Transformations
172,The bulk data load history that is available upon completion of the COPY statement is stored where and for how long?,C,In the metadata of the target table for 14 days,In the metadata of the pipe for 14 days,In the metadata of the target table for 64 days,In the metadata of the pipe for 64 days,,,"Pipe load history → 14 days\n
Bulk data load. Stored in the metadata of the target table for 64 days. Available upon completion of the COPY statement as the statement output.","https://docs.snowflake.com/en/user-guide/data-load-considerations-load#load-metadata, https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro#load-history",,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture"
173,Which of the following objects are contained within a schema? (Choose two.),"B,D",Role,Stream,Warehouse,External table,User,Share,"External table, Stream = Schema level objects\n
Role, Warehouse, User = Account level objects\n
Share = Database level object","https://docs.snowflake.com/en/sql-reference/identifiers, https://docs.snowflake.com/en/sql-reference/ddl-database, https://docs.snowflake.com/en/user-guide/security-access-control-overview#securable-objects",,"Data Transformations, Account Access and Security"
174,"Which SQL commands, when committed, will consume a stream and advance the stream offset? (Choose two.)","A,C",UPDATE TABLE FROM STREAM,SELECT FROM STREAM,INSERT INTO TABLE SELECT FROM STREAM,ALTER TABLE AS SELECT FROM STREAM,BEGIN COMMIT,,,https://docs.snowflake.com/en/user-guide/streams-intro,,Data Loading and Unloading
175,"A running virtual warehouse is suspended. 

What is the MINIMUM amount of time that the warehouse will incur charges for when it is restarted?",B,1 second,60 seconds,5 minutes,60 minutes,,,"Warehouse credits are calculated based on Warehouse size and runtime in seconds. However, when a VWH is started / resumed, the minimum charge is for 1 minute (past this minute in seconds)",https://docs.snowflake.com/en/user-guide/warehouses-considerations,,Performance Concepts
176,What effect does WAIT_FOR_COMPLETION = TRUE have when running an ALTER WAREHOUSE command and changing the warehouse size?,D,The warehouse size does not change until all queries currently running in the warehouse have completed.,The warehouse size does not change until all queries currently in the warehouse queue have completed.,The warehouse size does not change until the warehouse is suspended and restarted.,It does not return from the command until the warehouse has finished changing its size.,,,"This is making sure that the next submitted command in this session will use the resized Warehouse\n

WAIT_FOR_COMPLETION = FALSE | TRUE When resizing a warehouse, you can use this parameter to block the return of the ALTER WAREHOUSE command until the resize has finished provisioning all its compute resources. Blocking the return of the command when resizing to a larger warehouse serves to notify you that your compute resources have been fully provisioned and the warehouse is now ready to execute queries using all the new resources.",https://docs.snowflake.com/en/sql-reference/sql/alter-warehouse,,Data Transformations
177,What impacts the credit consumption of maintaining a materialized view? (Choose two.),"C,D",Whether or not it is also a secure view,How often the underlying base table is queried,How often the base table changes,Whether the materialized view has a cluster key defined,How often the materialized view is queried,,"When a base table changes, all materialized views defined on the table are updated by a background service that uses compute resources provided by Snowflake.\n

Maintaining clustering (of either a table or a materialized view) adds costs.","https://docs.snowflake.com/en/user-guide/views-materialized#estimating-and-controlling-costs, https://docs.snowflake.com/en/user-guide/views-materialized#effects-of-changes-to-base-tables-on-materialized-views",,Performance Concepts
178,"The first user assigned to a new account, ACCOUNTADMIN, should create at least one additional user with which administrative privilege?",A,USERADMIN,PUBLIC,ORGADMIN,SYSADMIN,,,"By default, when your account is provisioned, the first user is assigned the ACCOUNTADMIN role. This user should then create one or more additional users who are assigned the USERADMIN role. All remaining users should be created by the user(s) with the USERADMIN role or another role that is granted the global CREATE USER privilege.",https://docs.snowflake.com/en/user-guide/security-access-control-considerations#using-the-accountadmin-role,,Account Access and Security
179,Which Snowflake feature will allow small volumes of data to continuously load into Snowflake and will incrementally make the data available for analysis?,B,COPY INTO,CREATE PIPE,INSERT INTO,TABLE STREAM,,,"The keyword "" continuously"". We will need to use Snowpipe. Use COPY INTO for Bulk loading","https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro#load-order-of-data-files, https://docs.snowflake.com/en/sql-reference/sql/create-pipe",,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture, Data Transformations"
180,Which database objects can be shared with the Snowflake secure data sharing feature? (Choose two.),"B,C",Files,External tables,Secure User-Defined Functions (UDFs),Sequences,Streams,,"Secure Data Sharing lets you share selected objects in a database in your account with other Snowflake accounts. You can share the following Snowflake database objects:\n
-Tables\n
-External tables\n
-Secure views\n
-Secure materialized views\n
-Secure UDFs\n",https://docs.snowflake.com/en/user-guide/data-sharing-intro,,Data Protection and Data Sharing
181,What is an advantage of using an explain plan instead of the query profiler to evaluate the performance of a query?,B,The explain plan output is available graphically.,An explain plan can be used to conduct performance analysis without executing a query.,An explain plan will handle queries with temporary tables and the query profiler will not.,An explain plan's output will display automatic data skew optimization information.,,,"No credits need to be used.\n

EXPLAIN compiles the SQL statement, but does not execute it, so EXPLAIN does not require a running warehouse.\n

Although EXPLAIN does not consume any compute credits, the compilation of the query does consume Cloud Service credits, just as other metadata operations do.\n

**Concept included in test from Sept 2024",https://docs.snowflake.com/en/sql-reference/sql/explain#usage-notes,,Data Transformations
182,"The following JSON is stored in a VARIANT column called sc of the CAR_SALES table: 

A user needs to extract the dealership information from the JSON. 

How can this be accomplished?",A,select src: dealership from car_sales;,select src.dealership from car_sales;,select src: Dealership from car_sales;,select dealership from car_sales;,,,"column name is src (case insensitive)\n
Keys in brackets are case sensitive (""dealership"", ""date"", etc.)\n

Insert a colon : between the VARIANT column name and any first-level element: <column>:<level1_element>.\n

**Concept included in test from Sept 2024",https://docs.snowflake.com/en/user-guide/querying-semistructured,https://i.imgur.com/jf2FM6F.jpeg,Performance Concepts
183,Which Snowflake objects can be shared with other Snowflake accounts? (Choose three.),"C,E,F",Schemas,Roles,Secure Views,Stored Procedures,Tables,Secure User-Defined Functions (UDFs),,https://docs.snowflake.com/en/user-guide/data-sharing-intro,,Data Protection and Data Sharing
184,What is the SNOWFLAKE ACCOUNT_USAGE view that contains information about which objects were read by queries within the last 365 days (1 year)?,C,VIEWS_HISTORY,OBJECT_HISTORY,ACCESS_HISTORY,LOGIN_HISTORY,,,**Concept included in test from Sept 2024,"https://docs.snowflake.com/en/user-guide/access-history, https://docs.snowflake.com/en/sql-reference/account-usage/access_history",,"Account Access and Security, Data Transformations"
185,Which privilege is required for a role to be able to resume a suspended warehouse if auto-resume is not enabled?,B,USAGE,OPERATE,MONITOR,MODIFY,,,"USAGE → use Warehouse, eg. run queries on it\n
OPERATE → suspend / resume\n
MONITOR → review stats and usage\n
MODIFY → change size\n

OPERATE: Enables changing the state of a warehouse (stop, start, suspend, resume). In addition, enables viewing current and past queries executed on a warehouse and aborting any executing queries.\n

**Concept included in test from Sept 2024",https://docs.snowflake.com/en/user-guide/security-access-control-privileges#virtual-warehouse-privileges,,Account Access and Security
186,Which statement is true about running tasks in Snowflake?,B,A task can be called using a CALL statement to run a set of predefined SQL commands.,A task allows a user to execute a single SQL statement/command using a predefined schedule.,A task allows a user to execute a set of SQL commands on a predefined schedule.,A task can be executed using a SELECT statement to run a predefined SQL command.,,,"A task executes a single SQL statement / command. It can not be called, but it can call a stored procedure (which in turn might include and run multiple SQL statements)\n

A task can execute any one of the following types of SQL code:\n
-Single SQL statement\n
-Call to a stored procedure\n
-Procedural logic using Snowflake Scripting Developer Guide",https://docs.snowflake.com/en/user-guide/tasks-intro,,Performance Concepts
187,"A user created a new worksheet within the Snowsight Ul and wants to share this with teammates. 

How can this worksheet be shared?",C,Create a zero-copy clone of the worksheet and grant permissions to teammates,Create a private Data Exchange so that any teammate can use the worksheet,Share the worksheet with teammates within Snowsight,Create a database and grant all permissions to teammates,,,https://www.awesomescreenshot.com/video/16252655?key=2158cb91f2d67c71b92c91da3e08f596,https://docs.snowflake.com/en/user-guide/ui-snowsight-worksheets#label-sharing-worksheets-and-folders,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
188,"What is the following SQL command used for? 

Select * from table(validate(t1, job_id => '_last*));",D,To validate external table files in table t1 across all sessions,To validate task SQL statements against table t1 in the last 14 days,To validate a file for errors before it gets executed using a COPY command,To return errors from the last executed COPY command into table t1 in the current session,,,"-Validate returns errors from a previously executed COPY command\n
-COPY INTO with VALIDATION_MODE parameter checks for errors previous to actually loading the data\n
-VALIDATION_MODE = RETURN_n_ROWS | RETURN_ERRORS | RETURN_ALL_ERROR\n",https://docs.snowflake.com/en/sql-reference/functions/validate,,Data Transformations
189,Which command should be used to download files from a Snowflake stage to a local folder on a client's machine?,B,PUT,GET,COPY,SELECT,,,**Concept included in test from Sept 2024,https://docs.snowflake.com/en/sql-reference/sql/get,,Data Transformations
190,Which of the following activities consume virtual warehouse credits in the Snowflake environment? (Choose two.),"D,E",Caching query results,Running EXPLAIN and SHOW commands,Cloning a database,Running a custom query,Running COPY commands,,"Caching query results = Query Result Cache\n
EXPLAIN/SHOW, Cloning = Metadata operations\n

A warehouse provides the required resources, such as CPU, memory, and temporary storage, to perform the following operations in a Snowflake session:\n
-Executing SQL SELECT statements that require compute resources (e.g. retrieving rows from tables and views).\n
-Performing DML operations, such as: Updating rows in tables (DELETE , INSERT , UPDATE).\n
-Loading data into tables (COPY INTO <table>).\n
-Unloading data from tables (COPY INTO <location>).\n

Note: To perform these operations, a warehouse must be running and in use for the session. While a warehouse is running, it consumes Snowflake credits.",https://docs.snowflake.com/en/user-guide/warehouses-considerations,,Performance Concepts
191,Data storage for individual tables can be monitored using which commands and/or objects? (Choose two.),"B,E",SHOW STORAGE BY TABLE;,SHOW TABLES;,Information Schema -> TABLE_HISTORY,Information Schema -> TABLE_FUNCTION,Information Schema -> TABLE_STORAGE_METRICS,,These two options will show bytes stored.,"https://docs.snowflake.com/en/user-guide/tables-storage-considerations#individual-table-storage, https://docs.snowflake.com/en/sql-reference/sql/show-tables, https://docs.snowflake.com/en/sql-reference/sql/show-tables",,"Performance Concepts, Data Transformations"
192,How should a virtual warehouse be configured if a user wants to ensure that additional multi-clusters are resumed with no delay?,C,Configure the warehouse to a size larger than generally required,Set the minimum and maximum clusters to autoscale,Use the standard warehouse scaling policy,Use the economy warehouse scaling policy,,,,https://docs.snowflake.com/en/user-guide/warehouses-multicluster#setting-the-scaling-policy-for-a-multi-cluster-warehouse,,Performance Concepts
193,What is the maximum total Continuous Data Protection (CDP) charges incurred for a temporary table?,D,30 days,7 days,48 hours,24 hours,,,"Temporary and Transient tables:\n
Time travel → 1 day = 24h\n
Failsafe → 0 (none)\n

The maximum total CDP charges incurred for a temporary table are 1 day (or less if the table is explicitly dropped or dropped as a result of terminating the session). During this period, Time Travel can be performed on the table.","https://docs.snowflake.com/en/user-guide/data-time-travel#data-retention-period, https://docs.snowflake.com/en/user-guide/data-cdp-storage-costs#temporary-and-transient-tables, https://docs.snowflake.com/en/user-guide/tables-storage-considerations",,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
194,How can a row access policy be applied to a table or a view? (Choose two.),"B,E",Within the policy DDL,Within the create table or create view DDL,By future APPLY for all objects in a schema,Within a control table,Using the command ALTER < object> ADD ROW ACCESS POLICY <policy>;,,,https://docs.snowflake.com/en/user-guide/security-row-intro,,Data Protection and Data Sharing
195,How does Snowflake Fail-safe protect data in a permanent table?,C,"Fail-safe makes data available up to 1 day, recoverable by user operations.","Fail-safe makes data available for 7 days, recoverable by user operations.","Fail-safe makes data available for 7 days, recoverable only by Snowflake Support.","Fail-safe makes data available up to 1 day, recoverable only by Snowflake Support.",,,Fail-safe provides a (non-configurable) 7-day period during which historical data may be recoverable by Snowflake. This period starts immediately after the Time Travel retention period ends.,https://docs.snowflake.com/en/user-guide/data-failsafe#what-is-fail-safe,,Data Protection and Data Sharing
196,Which statement describes how Snowflake supports reader accounts?,D,A reader account can consume data from the provider account that created it and combine it with its own data.,A consumer needs to become a licensed Snowflake customer as data sharing is only supported between Snowflake accounts.,The users in a reader account can query data that has been shared with the reader account and can perform DML tasks.,The SHOW MANAGED ACCOUNTS command will view all the reader accounts that have been created for an account.,,,"SHOW MANAGED ACCOUNTS: Lists the managed accounts created for your account. Currently used by data providers to create reader accounts for their consumers.\n
To view all the reader accounts that have been created for your account, use the SHOW MANAGED ACCOUNTS command.\n
About option : A reader account can consume data from the provider account that created it and combine it with its own data.\n
Reader accounts (formerly known as “read-only accounts”) enable providers to share data with consumers who are not already Snowflake customers, without requiring the consumers to become Snowflake customers.\n
A reader account is intended primarily for querying data shared by the provider of the account. You can work with data, for example, by creating materialized views.\n
Set a data metric function on objects in the reader account.\n
Upload new data.\n
Modify existing data.\n
Unload data using a storage integration. However, you can use the COPY INTO <location> command with your connection credentials to unload data into a cloud storage location.\n

**Concept included in test from Sept 2024","https://docs.snowflake.com/en/user-guide/data-sharing-reader-create, https://docs.snowflake.com/en/sql-reference/sql/show-managed-accounts, https://docs.snowflake.com/en/user-guide/data-sharing-reader-create#viewing-reader-accounts",,"Data Protection and Data Sharing, Data Transformations"
197,"What happens to the shared objects for users in a consumer account from a share, once a database has been created in that account?",C,The shared objects are transferred.,The shared objects are copied.,The shared objects become accessible.,The shared objects can be re-shared,,,"Once a database is created (in a consumer account) from a share, all the shared objects are accessible to users in the consumer account.",https://docs.snowflake.com/en/user-guide/data-sharing-provider,,Data Protection and Data Sharing
198,What privilege should a user be granted to change permissions for new objects in a managed access schema?,A,Grant the OWNERSHIP privilege on the schema.,Grant the OWNERSHIP privilege on the database.,Grant the MANAGE GRANTS global privilege.,Grant ALL privileges on the schema.,,,,https://docs.snowflake.com/en/sql-reference/sql/grant-privilege#access-control-requirements,,Data Transformations
199,Which data type can store more than one type of data structure?,D,JSON,BINARY,VARCHAR,VARIANT,,,,https://docs.snowflake.com/en/sql-reference/data-types-semistructured#variant,,Data Transformations
200,What is true about sharing data in Snowflake? (Choose two.),"C,E",The Data Consumer pays for data storage as well as for data computing.,"The shared data is copied into the Data Consumer account, so the Consumer can modify it without impacting the base data of the Provider.",A Snowflake account can both provide and consume shared data.,The Provider is charged for compute resources used by the Data Consumer to query the shared data.,The Data Consumer pays only for compute resources to query the shared data.,,"With Secure Data Sharing, no actual data is copied or transferred between accounts. The only charges to consumers are for the compute resources (i.e. virtual warehouses) used to query the shared data.\n

Any full Snowflake account can both provide and consume shared data.",https://docs.snowflake.com/en/user-guide/data-sharing-intro#how-does-secure-data-sharing-work,,Data Protection and Data Sharing
201,What is the minimum Snowflake edition needed for database failover and failback between Snowflake accounts for business continuity and disaster recovery?,C,Standard,Enterprise,Business Critical,Virtual Private Snowflake,,,,https://docs.snowflake.com/en/user-guide/intro-editions#business-critical-edition,,Snowflake AI Data Cloud Features and Architecture
202,Credit charges for Snowflake virtual warehouses are calculated based on which of the following considerations? (Choose two.),"C,D",The number of queries executed,The number of active users assigned to the warehouse,The size of the virtual warehouse,The length of time the warehouse is running,The duration of the queries that are executed,,"Snowflake credits are charged based on the number of virtual warehouses you use, how long they run, and their size.",https://docs.snowflake.com/en/user-guide/warehouses-considerations#how-are-credits-charged-for-warehouses,,Performance Concepts
203,Which statement MOST accurately describes clustering in Snowflake?,B,The database ACCOUNTADMIN must define the clustering methodology for each Snowflake table.,Clustering is the way data is grouped together and stored within Snowflake micro-partitions.,The clustering key must be included in the COPY command when loading data into Snowflake.,Clustering can be disabled within a Snowflake account.,,,,https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions,,Performance Concepts
204,What is the maximum Time Travel retention period for a temporary Snowflake table?,B,90 days,1 day,7 days,45 days,,,**Concept included in test from Sept 2024,https://docs.snowflake.com/en/user-guide/data-time-travel#data-retention-period,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
205,Which methods can be used to delete staged files from a Snowflake stage? (Choose two.),"C,D",Use the DROP <file> command after the load completes.,Specify the TEMPORARY option when creating the file format.,Specify the PURGE copy option in the COPY INTO <table> command.,Use the REMOVE command after the load completes.,Use the DELETE LOAD HISTORY command after the load completes.,,,"https://docs.snowflake.com/en/user-guide/data-load-local-file-system-copy#managing-data-files, https://docs.snowflake.com/en/sql-reference/sql/remove, https://docs.snowflake.com/en/sql-reference/sql/copy-into-table#purging-files-after-loading,",,"Data Loading and Unloading, Data Transformations"
206,"In the Snowflake access control model, which entity owns an object by default?",D,The user who created the object,The SYSADMIN role,Ownership depends on the type of object,The role used to create the object,,,"To own an object means that a role has the OWNERSHIP privilege on the object. Each securable object is owned by a single role, which by default is the role used to create the object.",https://docs.snowflake.com/en/user-guide/security-access-control-overview#securable-objects,,Account Access and Security
207,Which Snowflake SQL statement would be used to determine which users and roles have access to a role called MY ROLE?,A,SHOW GRANTS OF ROLE MY_ROLE,SHOW GRANTS TO ROLE MY_ROLE,SHOW GRANTS FOR ROLE MY_ROLE,SHOW GRANTS ON ROLE MY_ROLE,,,"OF = Lists all users and roles to which the role has been granted.\n
TO = Lists all privileges and roles granted to the role. If the role has a grant on a temporary object, then the grant only exists in the session that the temporary object was created.\n
ON = Lists all privileges that have been granted on the object.\n
FOR = Not a SHOW GRANT variant",https://docs.snowflake.com/en/sql-reference/sql/show-grants,,Data Transformations
208,How many resource monitors can be assigned at the account level?,A,1,2,3,4,,,A single monitor can be set at the account level to control credit usage for all warehouses in your account. Additional resource monitors might be assigned on the Warehouse level (to a single or a group of Warehouses),"https://docs.snowflake.com/en/user-guide/resource-monitors#assignment-of-resource-monitors, https://docs.snowflake.com/en/user-guide/resource-monitors#monitor-level",,Performance Concepts
209,What affects whether the query results cache can be used?,C,If the query contains a deterministic function,If the virtual warehouse has been suspended,If the referenced data in the table has changed,If multiple users are using the same virtual warehouse,,,"Result Cache: Which holds the results of every query executed in the past 24 hours. These are available across virtual warehouses, so query results returned to one user is available to any other user on the system who executes the same query, provided the underlying data has not changed.",https://docs.snowflake.com/en/user-guide/querying-persisted-results,,Performance Concepts
210,Where is Snowflake metadata stored?,C,Within the data files,In the virtual warehouse layer,In the cloud services layer,In the remote storage layer,,,,https://docs.snowflake.com/en/user-guide/intro-key-concepts,,Snowflake AI Data Cloud Features and Architecture
211,Which of the following describes the Snowflake Cloud Services layer?,A,Coordinates activities in the Snowflake account,Executes queries submitted by the Snowflake account users,Manages quotas on the Snowflake account storage,Manages the virtual warehouse cache to speed up queries,,,,https://docs.snowflake.com/en/user-guide/intro-key-concepts#cloud-services,,Snowflake AI Data Cloud Features and Architecture
212,Which TABLE function helps to convert semi-structured data to a relational representation?,C,CHECK_JSON,TO_JSON,FLATTEN,PARSE_JSON,,,**Concept included in test from Sept 2024,https://docs.snowflake.com/en/sql-reference/functions/flatten,,Data Transformations
213,Which privilege must be granted to a share to allow secure views the ability to reference data in multiple databases?,D,CREATE_SHARE on the account,SHARE on databases and schemas,SELECT on tables used by the secure view,REFERENCE_USAGE on databases,,,,"https://docs.snowflake.com/en/sql-reference/sql/grant-privilege-share#usage-notes, https://docs.snowflake.com/en/user-guide/data-sharing-mutiple-db",,"Data Transformations, Data Protection and Data Sharing"
214,Network policies can be set at which Snowflake levels? (Choose two.),"C,E",Role,Schema,User,Database,Account,Tables,**Concept included in test from Sept 2024,https://docs.snowflake.com/en/user-guide/network-policies#activating-a-network-policy,,Account Access and Security
215,Which of the following describes a Snowflake stored procedure?,D,They can be created as secure and hide the underlying metadata from the user.,They can only access tables from a single database.,They can contain only a single SQL statement.,They can be created to run with a caller's rights or an owner's rights.,,,,https://docs.snowflake.com/en/developer-guide/stored-procedure/stored-procedures-overview#what-is-a-stored-procedure,,Data Transformations
216,"A user has a standard multi-cluster warehouse auto-scaling policy in place. 

Which condition will trigger a cluster to shut-down?",D,When after 2-3 consecutive checks the system determines that the load on the most-loaded cluster could be redistributed.,When after 5-6 consecutive checks the system determines that the load on the most-loaded cluster could be redistributed.,When after 5-6 consecutive checks the system determines that the load on the least-loaded cluster could be redistributed.,When after 2-3 consecutive checks the system determines that the load on the least-loaded cluster could be redistributed.,,,For an economy multi-cluster Warehouse it's 5-6 consecutive scans,https://docs.snowflake.com/en/user-guide/warehouses-multicluster#setting-the-scaling-policy-for-a-multi-cluster-warehouse,,Performance Concepts
217,Which of the following statements describe features of Snowflake data caching? (Choose two.),"B,E","When a virtual warehouse is suspended, the data cache is saved on the remote storage layer.","When the data cache is full, the least-recently used data will be cleared to make room.",A user can only access their own queries from the query result cache.,A user must set USE_METADATA_CACHE to TRUE to use the metadata cache in queries.,The RESULT_SCAN table function can access and filter the contents of the query result cache.,,"When the data cache is full, the least-recently used data will be cleared to make room is CORRECT because Snowflake automatically manages its data cache and evicts the least-recently used data when the cache becomes full.\n

The RESULT_SCAN table function can access and filter the contents of the query result cache is CORRECT because the RESULT_SCAN table function can be used to query and filter the data that has been cached in the query result cache.\n

When a virtual warehouse is suspended, the data cache is saved on the remote storage layer is INCORRECT because when a virtual warehouse is suspended, the data cache is not saved on the remote storage layer. The data cache is cleared when a virtual warehouse is suspended and any data that needs to be cached is reloaded from the remote storage layer when the virtual warehouse is resumed.\n

A user can only access their own queries from the query result cache is INCORRECT because the query result cache is a shared cache and all users can access the data that has been cached. There are no restrictions based on user access.\n

Option A user must set USE_METADATA_CACHE to TRUE to use the metadata cache in queries is INCORRECT because the metadata cache is used by default in queries and there is no need for a user to explicitly set USE_METADATA_CACHE to TRUE.","https://docs.snowflake.com/en/user-guide/warehouses-considerations#how-does-warehouse-caching-impact-queries, https://docs.snowflake.com/en/user-guide/querying-persisted-results, https://docs.snowflake.com/en/user-guide/performance-query-warehouse-cache",,Performance Concepts
218,Which parameter can be used to instruct a COPY command to verify data files instead of loading them into a specified table?,D,STRIP_NULL_VALUES,SKIP_BYTE_ORDER_MARK,REPLACE_INVALID_CHARACTERS,VALIDATION_ MODE,,,VALIDATION_MODE: This instructs the command to validate the data files instead of loading them into target tables and allows you to perform the dry run to ensure the fail-safe delivery of data.,https://docs.snowflake.com/en/sql-reference/sql/copy-into-table#optional-parameters,,Data Transformations
219,"By default, which Snowflake role is required to create a share?",D,ORGADMIN,SECURITYADMIN,SHAREADMIN,ACCOUNTADMIN,,,CREATE SHARE: Account :Only the ACCOUNTADMIN role has this privilege by default. The privilege can be granted to additional roles as needed.,https://docs.snowflake.com/en/sql-reference/sql/create-share#access-control-requirements,,"Data Transformations, Data Protection and Data Sharing"
220,Which query profile statistics help determine if efficient pruning is occurring? (Choose two.),"C,E",Bytes sent over network,Percentage scanned from cache,Partitions total,Bytes spilled to local storage,Partitions scanned,,"The fewer Partitions are scanned, compared to the total, the better the pruning\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/user-guide/ui-snowsight-activity#statistics,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
221,"If a size Small virtual warehouse is made up of two servers, how many servers make up a Large warehouse?",B,4,8,16,32,,,,https://docs.snowflake.com/en/user-guide/warehouses-overview#warehouse-size,,Performance Concepts
222,The Snowflake Search Optimization Services supports improved performance of which kind of query?,C,Queries against large tables where frequent DML occurs,Queries against tables larger than 1 TB,Selective point lookup queries,Queries against a subset of columns in a table,,,"SELECT.. FROM.. WHERE <cloumn_value> = .. (equality predicate)\n
SELECT.. FROM.. WHERE < column_value> IN (...) (in predicate)\n
Keyword ""selective""\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/user-guide/search-optimization-service,,"Performance Concepts, Snowflake AI Data Cloud Features and Architecture"
223,"A data provider wants to share data with a consumer who does not have a Snowflake account. The provider creates a reader account for the consumer following these steps: 
1. Created a user called ""CONSUMER""
2. Created a database to hold the share and an extra-small warehouse to query the data
3. Granted the role PUBLIC the following privileges: Usage on the warehouse, database, and schema, and SELECT on all the objects in the share 

Based on this configuration what is true of the reader account?",B,The reader account will automatically use the Standard edition of Snowflake.,The reader account compute will be billed to the provider account.,"The reader account can clone data the provider has shared, but cannot re-share it.",The reader account can create a copy of the shared data using CREATE TABLE AS..,,,"Compute and storage will be billed to the provider, as the reader account is not a Snowflake customer",https://docs.snowflake.com/en/user-guide/data-sharing-reader-create,,Data Protection and Data Sharing
224,Which commands should be used to grant the privilege allowing a role to select data from all current tables and any tables that will be created later in a schema? (Choose two.),"C,D",grant USAGE on all tables in schema DB1.SCHEMA to role MYROLE;,grant USAGE on future tables in schema DB1.SCHEMA to role MYROLE;,grant SELECT on all tables in schema DB1.SCHEMA to role MYROLE;,grant SELECT on future tables in schema DB1.SCHEMA to role MYROLE;,grant SELECT on all tables in database DB1 to role MYROLE;,grant SELECT on future tables in database DB1 to role MYROLE;,,https://docs.snowflake.com/en/sql-reference/sql/grant-privilege#roles,,Data Transformations
225,"A user has unloaded data from a Snowflake table to an external stage. 

Which command can be used to verify if data has been uploaded to the external stage named my _stage?",B,view @my_stage,list @my_stage,show @my_stage,display @my_stage,,,LIST or LS can be used to list the files in a stage,https://docs.snowflake.com/en/user-guide/data-unload-snowflake#unloading-data-to-the-named-stage,,Data Loading and Unloading
226,Which of the following is the Snowflake Account_Usage.Metering_History view used for?,A,Gathering the hourly credit usage for an account,Compiling an account's average cloud services cost over the previous month,Summarizing the throughput of Snowpipe costs for an account,Calculating the funds left on an account's contract,,,The METERING_HISTORY view in the ACCOUNT_USAGE schema can be used to return the hourly credit usage for an account within the last 365 days (1 year).,https://docs.snowflake.com/en/sql-reference/account-usage/metering_history,,Data Transformations
227,"User INQUISITIVE_PERSON has been granted the role DATA_SCIENCE. The role DATA_SCIENCE has privileges OWNERSHIP on the schema MARKETING of the database ANALYTICS_DW. 

Which command will show all privileges granted to that schema?",B,SHOW GRANTS ON ROLE DATA_SCIENCE,SHOW GRANTS ON SCHEMA ANALYTICS_DW.MARKETING,SHOW GRANTS TO USER INQUISITIVE_PERSON,SHOW GRANTS OF ROLE DATA_SCIENCE,,,,https://docs.snowflake.com/en/sql-reference/sql/show-grants#variants,,Data Transformations
228,When should a multi-cluster warehouse be used in auto-scaling mode?,A,When it is unknown how much compute power is needed,If the select statement contains a large number of temporary tables or Common Table Expressions (CTEs),If the runtime of the executed query is very slow,When a large number of concurrent queries are run on the same warehouse,,,"Scale Out for concurrency → Multi-Cluster Warehouses + auto-scaling\n
Scale UP for complexity → Increasing size of a Warehouse\n
If known consistent large number of concurrent queries, use Maximized\n
If unknown, auto-scale dynamically manages the load to support\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/user-guide/warehouses-multicluster#maximized-vs-auto-scale,,Performance Concepts
229,Which of the following are considerations when using a directory table when working with unstructured data? (Choose two.),"B,D",A directory table is a separate database object.,Directory tables store data file metadata.,A directory table will be automatically added to a stage.,Directory tables do not have their own grantable privileges.,Directory table data can not be refreshed manually.,,"Directory Table\n
-External & internal stages (= Named Stages)\n
-Stores catalog of files in the stage\n
-NOT a securable, separate object\n
-NOT on Table Stages & User Stages\n
-Directory = (enable = true)\n
-Columns: Relative_path / File_URL / Size / Last_Modified / MD5 / ETAG\n
-Auto-Refresh with Notification service of cloud provider auto_refresh = true\n
-Manual refresh Alter Stage @stage_name Refresh;\n
-0.06 credits per 1000 notifications (or overhead for manual refreshes)\n
-STAGE_DIRECTORY_FILE_REGISTRATION_HISTORY Metadata history\n

**Concept included in test from Sept 2024",https://docs.snowflake.com/en/user-guide/data-load-dirtables-manage,,Data Loading and Unloading
230,Which statements reflect key functionalities of a Snowflake Data Exchange? (Choose two.),"B,E","If an account is enrolled with a Data Exchange, it will lose its access to the Snowflake Marketplace.",A Data Exchange allows groups of accounts to share data privately among the accounts.,"A Data Exchange allows accounts to share data with third, non-Snowflake parties.",Data Exchange functionality is available by default in accounts using the Enterprise edition or higher.,The sharing of data in a Data Exchange is bidirectional. An account can be a provider for some datasets and a consumer for others.,,"Data Exchange is NOT enabled for all accounts; contacting support may be necessary\n
Snowflake Marketplace and Data Exchange can both be used; consumers can switch between the Snowflake Marketplace and the Data Exchange\n
All parties must be Snowflake accounts for Data Exchange\n
Data Exchange Admin can designate the other accounts as providers, consumers, or both\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/user-guide/data-exchange,,Data Protection and Data Sharing
231,What occurs when a pipe is recreated using the CREATE OR REPLACE PIPE command?,A,The Pipe load history is reset to empty.,The REFRESH command is executed.,The stage will be purged.,The destination table is truncated.,,,Might cause data to be loaded twice,https://docs.snowflake.com/en/user-guide/data-load-snowpipe-manage#label-snowpipe-management-recreate-pipes,,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture"
232,Which statement describes pruning?,A,The filtering or disregarding of micro-partitions that are not needed to return a query.,The return of micro-partitions values that overlap with each other to reduce a query's runtime.,A service that is handled by the Snowflake Cloud Services layer to optimize caching.,The ability to allow the result of a query to be accessed as if it were a table.,,,,https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#query-pruning,,Performance Concepts
233,Which statements are true concerning Snowflake's underlying cloud infrastructure? (Select three.),"D,E,F",Snowflake data and services are deployed in a single availability zone within a cloud provider's region.,"Snowflake data and services are available in a single cloud provider and a single region, the use of multiple cloud providers is not supported.",Snowflake can be deployed in a customer's private cloud using the customer's own compute and storage resources for Snowflake compute and storage,Snowflake uses the core compute and storage services of each cloud provider for its own compute and storage,"All three layers of Snowflake's architecture (storage, compute, and cloud services) are deployed and managed entirely on a selected cloud platform",Snowflake data and services are deployed in at least three availability zones within a cloud provider's region,"Each account is deployed in a specific region and a specific cloud provider (AWS/AZURE/GCP)\n
High availability is achieved by leveraging multiple availability zones (eg.data centers) within the chosen region",https://docs.snowflake.com/en/user-guide/intro-key-concepts,,Snowflake AI Data Cloud Features and Architecture
234,"A Snowflake user executed a query and received the results. Another user executed the same query 4 hours later. The data had not changed. 

What will occur?",A,"No virtual warehouse will be used, data will be read from the result cache.","No virtual warehouse will be used, data will be read from the local disk cache.",The default virtual warehouse will be used to read all data.,The virtual warehouse that is defined at the session level will be used to read all data.,,,"Same query, same data, less than 24h since last run → Query Result Cache",https://docs.snowflake.com/en/user-guide/querying-persisted-results#retrieval-optimization,,Performance Concepts
235,How long is the Fail-safe period for temporary and transient tables?,A,There is no Fail-safe period for these tables.,1 day,7 days,31 days,90 days,,,"https://docs.snowflake.com/user-guide/data-cdp-storage-costs#temporary-and-transient-tables, https://docs.snowflake.com/en/user-guide/tables-temp-transient",,"Performance Concepts, Data Protection and Data Sharing"
236,Using variables in Snowflake is denoted by using which SQL character?,C,@,&,$,#,,,"To distinguish variables from bind values and column names, all variables must be prefixed with a $ sign\n

Example:\n
SET (MIN, MAX)=(40, 70);\n
SELECT AVG(SALARY) FROM EMP WHERE AGE BETWEEN $MIN AND $MAX;",https://docs.snowflake.com/en/sql-reference/session-variables#using-variables-in-sql,,Data Transformations
237,Which of the following is a data tokenization integration partner?,A,Protegrity,Tableau,DBeaver,SAP,,,,https://docs.snowflake.com/en/user-guide/security-column-ext-token-use#external-tokenization-partner-integrations,,Data Protection and Data Sharing
238,How many days is load history for Snowpipe retained?,C,1 day,7 days,14 days,64 days,,,"COPY INTO - Stored in the metadata of the target table for 64 days\n

SNOWPIPE - Stored in the metadata of the pipe for 14 days",https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro#load-history,,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture"
239,"When loading data into Snowflake, how should the data be organized?",A,Into single files with 100-250 MB of compressed data per file,Into single files with 1-100 MB of compressed data per file,Into files of maximum size of 1 GB of compressed data per file,Into files of maximum size of 4 GB of compressed data per file,,,,https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare#general-file-sizing-recommendations,,Data Loading and Unloading
240,What is the default file size when unloading data from Snowflake using the COPY command?,C,5 MB,8 GB,16 MB,32 MB,,,"-File size can be set with parameter MAX_FILE_SIZE\n
-16 MB is default\n
-Max FIle size is 5 GB\n
-To unload data to a single output file (at the potential cost of decreased performance), specify the SINGLE = true copy option in the statement\n
\n
copy into @mystage/myfile.csv.gz from mytable\n
file_format = (type=csv compression='gzip')\n
single=true\n
max_file_size=4900000000;\n
\n
By default, COPY INTO location statements separate table data into a set of output files to take advantage of parallel operations. The maximum size for each file is set using the MAX_FILE_SIZE copy option. The default value is 16777216 (16 MB) but can be increased to accommodate larger files.",https://docs.snowflake.com/en/user-guide/data-unload-considerations#unloading-to-a-single-file,,Data Loading and Unloading
241,What are the responsibilities of Snowflake's Cloud Service layer? (Choose three.),"A,B,D",Authentication,Resource management,Virtual warehouse caching,Query parsing and optimization,Query execution,Physical storage of micro-partitions,"Virtual warehouse caching + Query execution = Compute Layer\n
Physical storage of micro-partitions = Storage Layer\n

The cloud services layer is a collection of services that coordinate activities across Snowflake. These services tie together all of the different components of Snowflake in order to process user requests, from login to query dispatch. The cloud services layer also runs on compute instances provisioned by Snowflake from the cloud provider.\n

Services managed in this layer include:\n
Authentication\n
Infrastructure management\n
Metadata management\n
Query parsing and optimization\n
Access control","https://docs.snowflake.com/en/user-guide/intro-key-concepts#cloud-services, https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture",,Snowflake AI Data Cloud Features and Architecture
242,Which of the following significantly improves the performance of selective point lookup queries on a table?,D,Clustering,Materialized Views,Zero-copy Cloning,Search Optimization Service,,,"Equality predicates\n
IN predicates\n
Enterprise+ feature\n
Serverless\n
Compute + Storage costs (Search Access Path)\n

The search optimization service aims to significantly improve the performance of certain types of queries on tables, including: Selective point lookup queries on tables.\n

A point lookup query returns only one or a small number of distinct rows.",https://docs.snowflake.com/en/user-guide/search-optimization-service#understanding-the-search-optimization-service,,"Performance Concepts, Snowflake AI Data Cloud Features and Architecture"
243,"Files have been uploaded to a Snowflake internal stage. The files now need to be deleted. 

Which SQL command should be used to delete the files?",C,PURGE,MODIFY,REMOVE,DELETE,,,"PURGE option is part of the copy command\n
REMOVE is used after the load has been completed\n
DELETE is table rows\n
**Concept included in test from Sept 2024",https://docs.snowflake.com/en/sql-reference/sql/remove,,Data Transformations
244,"For non-materialized views, what column in Information Schema and Account Usage identifies whether a view is secure or not?",B,CHECK_OPTION,IS_SECURE,IS_UPDATEABLE,TABLE_NAME,,,,https://docs.snowflake.com/en/user-guide/views-secure#determining-if-a-view-is-secure,,"Data Protection and Data Sharing, Performance Concepts"
245,What is the purpose of multi-cluster virtual warehouses?,C,To create separate data warehouses to increase query optimization,To allow users the ability to choose the type of compute nodes that make up a virtual warehouse cluster,To eliminate or reduce Queuing of concurrent queries,To allow the warehouse to resize automatically,,,"To enable fully automated scaling for concurrency, Snowflake recommends multi-cluster warehouses, which provide essentially the same benefits as creating additional warehouses and redirecting queries, but without requiring manual intervention.","https://docs.snowflake.com/en/user-guide/warehouses-multicluster, https://docs.snowflake.com/en/user-guide/warehouses-overview#query-processing-and-concurrency",,Performance Concepts
246,How would a user run a multi-cluster warehouse in maximized mode?,C,"Configure the maximum clusters setting to ""Maximum.""",Turn on the additional clusters manually after starting the warehouse.,Set the minimum Clusters and maximum Clusters settings to the same value.,Set the minimum clusters and maximum clusters settings to different values.,,,"If min=max, there is no room for increasing any clusters and min and max would be same. Hence same value for maximized mode.\n

There is no auto-scaling (scale out / scale in) in this case",https://docs.snowflake.com/en/user-guide/warehouses-multicluster#maximized-vs-auto-scale,,Performance Concepts
247,Why does Snowflake recommend file sizes of 100-250 MB compressed when loading data?,D,Optimizes the virtual warehouse size and multi-cluster setting to economy mode,Allows a user to import the files in a sequential order,Increases the latency staging and accuracy when loading the data,Allows optimization of parallel operations,,,,https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare#general-file-sizing-recommendations,,Data Loading and Unloading
248,"When cloning a database, what is cloned with the database? (Choose two.)","B,D",Privileges on the database,Existing child objects within the database,Future child objects within the database,Privileges on the schemas within the database,Only schemas and tables within the database,,"If the source object is a database or schema, the clone inherits all granted privileges on the clones of all child objects contained in the source object:\n
-For databases, contained objects include schemas, tables, views, etc.\n
-For schemas, contained objects include tables, views, etc.\n
The clone of the container itself (database or schema) does not inherit the privileges granted on the source container.\n
For tables or views the COPY GRANT option can be used in the CREATE command to copy over the grants to the clone",https://docs.snowflake.com/en/user-guide/object-clone#access-control-privileges-for-cloned-objects,,Performance Concepts
249,What is the MINIMUM edition of Snowflake that is required to use a SCIM security integration?,B,Business Critical Edition,Standard Edition,Virtual Private Snowflake (VPS),Enterprise Edition,,,SCIM is available for ALL editions.,"https://docs.snowflake.com/en/user-guide/scim-intro, https://docs.snowflake.com/en/user-guide/admin-security",,Account Access and Security
250,Who can create network policies within Snowflake? (Choose two.),"C,E",SYSADMIN only,ORGADMIN only,A role with the CREATE NETWORK POLICY privilege,A role with the CREATE SECURITY INTEGRATION privilege,SECURITYADMIN or higher roles,,"Create a network policy\n
Only security administrators (i.e. users with the SECURITYADMIN role) or higher or a role with the global CREATE NETWORK POLICY privilege can create network policies. Ownership of a network policy can be transferred to another role\n",https://docs.snowflake.com/en/user-guide/network-policies,,Account Access and Security
251,"What is common between AWS Quicksight, PowerBI, and Tableau?",C,They are Snowflake Security & Governance Partners.,They are Snowflake Machine Learning Partners.,They are Snowflake Business Intelligence Partners.,They are Snowflake Data Integration Partners.,,,"Business intelligence (BI) tools enable analyzing, discovering, and reporting on data to help make more informed business decisions. They use dashboards, charts, or other graphical tools to deliver data visualization. We can see the Snowflake ecosystem in the following image:",https://docs.snowflake.com/en/user-guide/ecosystem-bi,,Snowflake AI Data Cloud Features and Architecture
252,"Snowflake recommends, as a minimum, that all users with the following role(s) should be enrolled in Multi-Factor Authentication (MFA):",D,"SECURITYADMIN, ACCOUNTADMIN","SECURITYADMIN, ACCOUNTADMIN, PUBLIC, SYSADMIN","SECURITYADMIN, ACCOUNTADMIN, SYSADMIN",ACCOUNTADMIN,,,,https://docs.snowflake.com/en/user-guide/security-mfa,,Account Access and Security
253,"A deterministic query is run at 8am, takes 5 minutes, and the results are cached. Which of the following statements are true? (Choose two.)","D,E",The same exact query will return the precomputed results even if the underlying data has changed as long as the results were last accessed within the previous 24 hour period,Snowflake edition is Enterprise or higher,The exact query will ALWAYS return the precomputed result set for the RESULT_CACHE_ACTIVE = time period,The same exact query will return the precomputed results if the underlying data hasn't changed and the results were last accessed within previous 24 hour period,The 24 hours timer on the precomputed results gets renewed every time the exact query is executed,,,https://docs.snowflake.com/en/user-guide/querying-persisted-results,,Performance Concepts
254,What type of columns does Snowflake recommend to be used as clustering keys? (Choose two.),"D,E",A column with very low cardinality,A VARIANT column,A column with very high cardinality,A column that is most actively used in join predicates,A column that is most actively used in selective filters,,,https://docs.snowflake.com/en/user-guide/tables-clustering-keys,,Performance Concepts
255,How is table data compressed in Snowflake?,B,The micro-partitions are stored in compressed cloud storage and the cloud storage handles compression.,Each column is compressed as it is stored in a micro-partition.,Each micro-partition is compressed as it is written into cloud storage using GZIP.,The text data in a micro-partition is compressed with GZIP but other types are not compressed.,,,Snowflake automatically determines the most efficient compression algorithm for the columns in each micro-partition.,https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions,,Performance Concepts
256,What feature of Snowflake Continuous Data Protection can be used for maintenance of historical data?,C,Fail-safe,Network policies,Time Travel,Access control,,,Snowflake Time Travel enables accessing historical data that has been changed or deleted at any point within a defined period. It is a powerful CDP (Continuous Data Protection) feature which ensures the maintenance and availability of your historical data.,https://docs.snowflake.com/en/user-guide/data-cdp,,Data Protection and Data Sharing
257,"A company’s security audit requires generating a report listing all Snowflake logins (e.g., date and user) within the last 90 days.
Which of the following statements will return the required information?",B,"SELECT LAST_SUCCESS_LOGIN, LOGIN_NAME
FROM ACCOUNT_USAGE.USERS;","SELECT EVENT_TIMESTAMP, USER_NAME
FROM ACCOUNT_USAGE.LOGIN_HISTORY;","SELECT EVENT_TIMESTAMP, USER_NAME
FROM table(information_schema.login_history_by_user())","SELECT EVENT_TIMESTAMP, USER_NAME
FROM ACCOUNT_USAGE.ACCESS_HISTORY;",,,login_history_by_user function returns login activity within the last 7 days only.,https://docs.snowflake.com/en/sql-reference/account-usage/login_history,,Data Transformations
258,What are common issues found by using the Query Profile? (Choose two.),"C,E",Identifying logical issues with the queries,Locating queries that consume a high amount of credits,Identifying inefficient micro-partition pruning,Identifying queries that will likely run very slowly before executing them,Data spilling to a local or remote disk,,,https://docs.snowflake.com/en/user-guide/ui-query-profile#statistics,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
259,What is the advantage of using a reader account?,A,It can be used by a client that does not have a Snowflake account,It is read-only and prevents the shared data from being updated by the provider,It provides limited access to the data share and is therefore cheaper for the data provider,It can be connected to a Snowflake account in a different region,,,,https://docs.snowflake.com/en/user-guide/ui-snowsight-private-sharing-reader-accounts,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
260,In which layer of Snowflake architecture is all security-related information stored?,A,Cloud Services.,Compute.,All of the above.,Storage.,,,"The Cloud Services layer is a collection of services coordinating activities across Snowflake. It's in charge of Authentication, Infrastructure management, Metadata management, Query parsing and optimization, and Access control.",https://docs.snowflake.com/en/user-guide/intro-key-concepts#cloud-services,,Snowflake AI Data Cloud Features and Architecture
261,When can a Virtual Warehouse start running queries?,A,When its provisioning is complete,After replication,Only during administrator defined time slots,12am-5am,,,"Virtual warehouses can be configure to auto_resume=true/false, accordingly once it provision it start executing the queries.",https://docs.snowflake.com/en/user-guide/warehouses-overview,,Performance Concepts
262,Which pages are included in the Activity area of Snowsight? (Choose two.),"B,D",Automatic Clustering History,Query History,Contacts,Copy History,Sharing settings,,,"https://docs.snowflake.com/en/user-guide/ui-snowsight-activity, https://docs.snowflake.com/en/user-guide/ui-snowsight-quick-tour#monitor-activity-in-sf-web-interface",,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
263,What is the use of the OVERWRITE=TRUE option in the PUT command?,A,It specifies whether Snowflake overwrites an existing file with the same name during upload.,It is not possible to use OVERWRITE=TRUE option with PUT command.,It specified whether Snowflake overwrites the encryption key you used to upload the files.,It specified whether Snowflake should overwrite the gzip compress algorithm with another one that you provide.,,,"The OVERWRITE=TRUE option in the Snowflake PUT command is used to overwrite an existing file with the same name in the target location. Imagine you run the following command:\n
PUT file:///tmp/data/mydata.csv @my_int_stage;\n

If there is a file called ""mydata.csv"" in the stage, it won't load it. However, using the OVERWRITE option, it will load it:\n
PUT file:///tmp/data/mydata.csv @my_int_stage OVERWRITE=TRUE;",https://docs.snowflake.com/en/sql-reference/sql/put#optional-parameters,,Data Transformations
264,"A query executed a couple of hours ago, which spent more than 5 minutes to run, is executed again, and it returned the results in less than a second. What might have happened?",B,Snowflake used the persisted query results from the metadata cache.,Snowflake used the persisted query results from the query result cache.,"A new Snowflake version has been released in the last two hours, improving the speed of the service.",Snowflake used the persisted query results from the warehouse cache.,,,"The query result cache stores the results of our queries for 24 hours, so as long as we perform the same query and the data hasn’t changed in the storage layer, it will return the same result without using the warehouse and without consuming credits.",https://docs.snowflake.com/en/user-guide/querying-persisted-results,,Performance Concepts
265,How does Snowflake store a table's underlying data? (Choose two.),"C,E",Uncompressed,Text file format,Columnar file format,User-defined partitions,Micro-partitions,,"All data in Snowflake tables is automatically divided into micro-partitions, which are contiguous units of storage. Each micro-partition contains between 50 MB and 500 MB of uncompressed data (note that the actual size in Snowflake is smaller because data is always stored compressed). Groups of rows in tables are mapped into individual micro-partitions, organized in a columnar fashion.",https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions,,Performance Concepts
266,How can a Snowflake user configure a virtual warehouse to support over 100 users if their company has Enterprise Edition?,C,Add additional warehouses and configure them as a cluster.,Use a larger warehouse.,Use a multi-cluster warehouse.,Set the auto-scale to 100.,,,Multi-cluster warehouse is the solution for simultaneous querying.,https://docs.snowflake.com/en/user-guide/warehouses-considerations#multi-cluster-warehouses-improve-concurrency,,Performance Concepts
267,"If auto-suspend is enabled for a Virtual Warehouse, the Warehouse is automatically suspended when:",B,There are no users logged into Snowflake.,The Warehouse is inactive for a specified period of time.,The last query using the Warehouse completes.,All Snowflakes sessions using the Warehouse are terminated.,,,,https://docs.snowflake.com/en/user-guide/warehouses-overview,,Performance Concepts
268,What is used to denote a pre-computed data set derived from a SELECT query specification and stored for later use?,A,Materialized view,External table,Secure view,View,,,,https://docs.snowflake.com/en/user-guide/views-materialized,,Performance Concepts
269,Where can we see the amount of storage used by Snowflake's Fail-Safe functionality in the User Interface?,C,In the Account & Billing section.,In the Account & Sessions section.,In the Admin & Cost Management section.,In the Admin & Fail-Safe section.,,,"You can see the Fail-Safe usage in Snowsight by navigating to Admin > Cost Management > Consumption and filter the ""Usage Type"" by Storage",https://docs.snowflake.com/en/user-guide/data-failsafe#view-fail-safe-storage-for-your-account,,Data Protection and Data Sharing
270,Which of the following are options when creating a Virtual Warehouse? (Choose two.),"A,F",Auto-resume,Auto-disable,Auto-enable,Auto-resize,Auto-drop,Auto-suspend,,https://docs.snowflake.com/en/sql-reference/sql/create-warehouse,,Data Transformations
271,"Query results are stored in the Result Cache for how long after they are last accessed, assuming no data changes have occurred?",A,24 hours,12 hours,3 Hours,1 Hour,,,,https://community.snowflake.com/s/article/Caching-in-the-Snowflake-Cloud-Data-Platform,,"Performance Concepts, Snowflake AI Data Cloud Features and Architecture"
272,Which is true of Snowflake network policies? A Snowflake network policy: (Choose two.),"D,E",Is activated using an ALTER DATABASE command,Is only available to customers with Business Critical Edition,Only ACCOUNTADMIN role or a role with the global CREATE NETWORK POLICY privilege can create network policies,Is available to all Snowflake Editions,Restricts or enables access to specific IP addresses,,,https://docs.snowflake.com/en/user-guide/network-policies,,Account Access and Security
273,How does a scoped URL expire?,C,The encoded URL access is permanent.,The length of time is specified in the expiration_time argument.,When the persisted query result period ends.,When the data cache clears.,,,"Types of URLs Available to Access Files in cloud storage:\n

Scoped URL: Encoded URL that permits temporary access to a staged file without granting privileges to the stage. The URL expires when the persisted query result period ends (i.e. the results cache expires), which is currently 24 hours.\n

File URL: URL that identifies the database, schema, stage, and file path to a set of files. A role that has sufficient privileges on the stage can access the files.\n

Pre-signed URL: Simple HTTPS URL used to access a file via a web browser. A file is temporarily accessible to users via this URL using a pre-signed access token. The expiration time for the access token is configurable.",https://docs.snowflake.com/en/user-guide/unstructured-intro,,Data Loading and Unloading
274,What are key characteristics of virtual warehouses in Snowflake? (Choose two.),"D,E",Warehouses that are multi-cluster can have nodes of different sizes.,Warehouses can only be used for querying and cannot be used for data loading.,Warehouses are billed on a per-minute usage basis.,Warehouses can be started and stopped at any time.,"Warehouses can be resized at any time, even while running.",,"Warehouses can be started and stopped at any time. They can also be resized at any time, even while running, to accommodate the need for more or less compute resources, based on the type of operations being performed by the warehouse.\n

You can expect a lot of questions about Virtual Warehouses in the exam.",https://docs.snowflake.com/en/user-guide/warehouses-overview,,Performance Concepts
275,How are privileges inherited in a role hierarchy in Snowflake?,D,Privileges are only inherited by the direct parent role in the hierarchy.,Privileges are inherited by any roles at the same level in the hierarchy.,Privileges are only inherited by the direct child role in the hierarchy.,Privileges are inherited by any roles above that role in the hierarchy.,,,The privileges associated with a role are inherited by any roles above that role in the hierarchy.,https://docs.snowflake.com/en/user-guide/security-access-control-privilegeshttps://docs.snowflake.com/en/user-guide/security-access-control-overview,,Account Access and Security
276,What authentication method does the Kafka connector use within Snowflake?,B,Username and password,Key pair authentication,OAuth,Multi-Factor Authentication (MFA),,,,https://docs.snowflake.com/en/user-guide/kafka-connector-install#download-the-kafka-connector-files,,"Data Transformations, Performance Concepts"
277,"You have two virtual warehouses in your Snowflake account. If one of them updates the data in the storage layer, when will the other one see it?",B,After the sync process.,Immediately.,Once all the compute resources are provisioned for the second warehouse.,After an average time of 5 seconds.,,,"All the warehouses of your account share the storage layer, so if the data is updated, all the warehouses will be able to see it.",,,Performance Concepts
278,Snowflake will return an error when a user attempts to share which object?,D,Secure materialized views,Tables,Secure views,Standard views,,,"For data security and privacy reasons, only secure views are supported in shares at this time. If a standard view is added to a share, Snowflake returns an error.",https://docs.snowflake.com/en/user-guide/data-sharing-provider,,Data Protection and Data Sharing
279,Why would a customer size a Virtual Warehouse from an X-Small to a Medium?,A,To accommodate a more complex workload,To accommodate more queries,To accommodate more users,To accommodate fluctuations in workload,,,You scale up to accommodate complex queries and you scale out to accommodate concurrent queries.,https://docs.snowflake.com/en/user-guide/warehouses-considerations#warehouse-resizing-improves-performance,,Performance Concepts
280,Which item in the Data Warehouse migration process does not apply in Snowflake?,B,Build the Data Pipeline,Migrate Indexes,Migrate Schemas,Migrate Users,,,Snowflake does not use indexes.,,,Performance Concepts
281,Which loop type iterates until a condition is true?,D,FOR,LOOP,WHILE,REPEAT,,,"A REPEAT loop iterates until a condition is true. In a REPEAT loop, the condition is tested immediately after executing the body of the loop. As a result, the body of the loop always executes at least once.\n
A WHILE loop iterates while a condition is true. In a WHILE loop, the condition is tested immediately before executing the body of the loop. If the condition is false before the first iteration, then the body of the loop does not execute even once.",https://docs.snowflake.com/en/developer-guide/snowflake-scripting/loops,,Data Transformations
282,Which common query problems can the Query Profile help a user identify and troubleshoot? (Choose two.),"C,E",When window functions are used incorrectly,When the SELECT DISTINCT command returns too many values,When there is a UNION without ALL,When there are Common Table Expressions (CTEs) without a final SELECT statement,When there are exploding joins,,"Some of the common query problems identified by Query Profile, including:\n
-Exploding joins\n
-UNION without ALL\n
-Queries too large to fit in memory (most often evidenced by “spilling”)\n
-Inefficient pruning (most often evidenced by large table scans)",https://www.snowflake.com/blog/new-approaches-visualizing-snowflake-query-statistics/,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
283,What activities can a user with the ORGADMIN role perform? (Choose two.),"A,D",Create an account for an organization.,Delete the account data for an organization.,Select all the data in tables for all accounts in an organization.,View usage information for all accounts in an organization.,Edit the account data for an organization.,,"A user with the ORGADMIN role can perform the following actions:\n
-Creating an Account.\n
-View/show all accounts in the Organization.\n
-Viewing a List of Regions Available for an Organization.\n
-View usage information for all accounts in the organization.\n
-Enable database replication for an account in the organization.\n

Note: Once an account is created, ORGADMIN can view the account properties but does not have access to the account data.",https://docs.snowflake.com/en/user-guide/organizations#orgadmin-role,,Snowflake AI Data Cloud Features and Architecture
284,"A Snowflake user wants to optimize performance for a query that queries only a small number of rows in a table. The rows require significant processing. The data in the table does not change frequently.
What should the user do?",B,Enable the query acceleration service for the virtual warehouse.,Create a materialized view based on the query.,Add a clustering key to the table.,Add the search optimization service to the table.,,,"Materialized views are particularly useful when:\n
-Query results contain a small number of rows and/or columns relative to the base table (the table on which the view is defined).\n
-Query results contain results that require significant processing, including:\n
-Analysis of semi-structured data.\n
-Aggregates that take a long time to calculate.\n
-The query is on an external table (i.e. data sets stored in files in an external stage), which might have slower performance compared to querying native database tables.\n
-The view’s base table does not change frequently.",https://docs.snowflake.com/en/user-guide/views-materialized#deciding-when-to-create-a-materialized-view,,Performance Concepts
285,Which of the below APIs are NOT Snowpipe REST APIs? (Choose two.),"D,E",insertFiles,insertReport,loadHistoryScan,loadFiles,insertHistoryScan,,"You can make calls to REST endpoints to get information. For example, by calling the following insertReport endpoint, you can get a report of files submitted via insertFiles:\n
GET https://<account_id>.snowflakecomputing.com/v1/data/pipes/<pipeName>/insertReport",https://docs.snowflake.com/en/user-guide/data-load-snowpipe-rest-apis,,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture"
286,Which columns are available in the output of a Snowflake directory table? (Choose two.),"B,C",STAGE_NAME,RELATIVE_PATH,LAST_MODIFIED,FILE_NAME,CATALOG_NAME,,"The output of a Snowflake directory table includes the following columns:\n
-RELATIVE_PATH: The path of the file relative to the stage.\n
-SIZE: The size of the file in bytes.\n
-LAST_MODIFIED: The date and time the file was last modified.\n
-MD5: checksum for the file.\n
-ETag: header for the file.\n
-FILE_URL: The Snowflake-hosted file URL to the file. The other columns listed are not available in the output of a Snowflake directory table.",https://docs.snowflake.com/en/user-guide/data-load-dirtables-manage#output,,Data Loading and Unloading
287,What does the client redirect feature in Snowflake enable?,C,A redirect of client connections to Snowflake accounts in different regions for data replication.,A redirect of client connections to Snowflake accounts in the same regions for business continuity.,A redirect of client connections to Snowflake accounts in different regions for business continuity.,A redirect of client connections to Snowflake accounts in the same regions for data replication.,,,"Client Redirect enables redirecting your client connections to Snowflake accounts in different regions for business continuity and disaster recovery, or when migrating your account to another region or cloud platform.",https://docs.snowflake.com/en/user-guide/client-redirect,,"Account Access and Security, Data Protection and Data Sharing"
288,How can a user improve the performance of a single large complex query in Snowflake?,B,Enable standard warehouse scaling.,Scale up the virtual warehouse.,Enable economy warehouse scaling.,Scale out the virtual warehouse.,,,"Resizing a warehouse generally improves query performance, particularly for larger, more complex queries. For query complexity Scale Up , for concurrency and query load tuning scale out.",https://docs.snowflake.com/en/user-guide/warehouses-considerations,,Performance Concepts
289,Which file formats support unloading semi-structured data? (Choose two.),"A,B",Parquet,JSON,ORC,Avro,XML,,"The following file formats are supported: Semi-structured JSON, Parquet\n
Not all semi-structured formats supported for data upload are supported for data unload.",https://docs.snowflake.com/en/user-guide/data-unload-prepare,,Data Loading and Unloading
290,How should a virtual warehouse be configured if a user wants to ensure that additional multi-clusters are resumed with the shortest delay possible?,A,Use the standard warehouse scaling policy,Configure the warehouse to a size larger than generally required,Set the minimum and maximum clusters to autoscale,Use the economy warehouse scaling policy,,,"The economy policy doesn't start immediately.\n
Only if the system estimates there’s enough query load to keep the cluster busy for at least 6 minutes.",https://docs.snowflake.com/en/user-guide/warehouses-multicluster,,Performance Concepts
291,Which cloud provider is not supported by Snowflake?,C,Google Cloud Platform.,AWS.,IBM.,Azure.,,,"A Snowflake account can only be hosted on Amazon Web Services, Google Cloud Platforms, and Microsoft Azure for now.",https://docs.snowflake.com/en/user-guide/intro-cloud-platforms,,Snowflake AI Data Cloud Features and Architecture
292,Which statement best describes Snowflake tables?,A,Snowflake tables are logical representations of underlying physical data,Snowflake tables require that clustering keys be defined to perform optimally,Snowflake tables are owned by a user,Snowflake tables are the physical instantiation of data loaded into Snowflake,,,,https://docs.snowflake.com/en/user-guide/tables-micro-partitions,,Performance Concepts
293,What can the Snowflake SCIM API be used to manage? (Choose two.),"A,B",Roles,Users,Session policies,Network policies,Integrations,,"Snowflake is compatible with SCIM2.0, SCIM is an open standard for automating user provisioning. The SCIM API allows us to programmatically manage roles and users within the Snowflake platform, making it easier to automate identity and access management tasks.",https://docs.snowflake.com/en/user-guide/scim-intro,,Account Access and Security
294,A Virtual Warehouse's auto-suspend and auto-resume settings apply to:,C,The database the Virtual Warehouse resides in,The queries currently being run by the Virtual Warehouse,The entire Virtual Warehouse,The primary cluster in the Virtual Warehouse,,,,https://docs.snowflake.com/en/user-guide/warehouses-overview,,Performance Concepts
295,What information is included in the display in the Query Profile? (Choose two.),"C,E",Index hints used in query,Credit usage details,Details and statistics for the overall query,Clustering keys details,Graphical representation of the query processing plan,,,https://docs.snowflake.com/en/user-guide/ui-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
296,Which statement best describes 'clustering'?,B,The database administrator must define the clustering methodology for each Snowflake table,Clustering represents the way data is grouped together and stored within Snowflake's micro-partitions,The clustering key must be included on the COPY command when loading data into Snowflake,Clustering can be disabled within a Snowflake account,,,,https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions,,Performance Concepts
297,What is one of the benefits of using a multi-cluster virtual warehouse?,B,It will automatically increase the warehouse size as needed.,It will automatically start and stop additional clusters as needed.,It will speed up data loading.,It will reduce the cost of running the warehouse.,,,,https://docs.snowflake.com/en/user-guide/warehouses-multicluster,,Performance Concepts
298,When a Pipe is recreated using the CREATE OR REPLACE PIPE command:,B,The REFRESH parameter is set to TRUE,The Pipe load history is reset to empty,Previously loaded files will be purged,Previously loaded files will be ignored,,,"REFRESH is a parameter for ALTER PIPE. \n
It is NOT a parameter for CREATE [OR REPLACE] Pipe.\n
Further recreating a pipe resets history\n

The load history for Snowpipe operations is stored in the metadata of the pipe object. When a pipe is recreated, the load history is dropped. In general, this condition only affects users if they subsequently execute an ALTER PIPE … REFRESH statement on the pipe. Doing so could load duplicate data from staged files in the storage location for the pipe if the data was already loaded successfully and the files were not deleted subsequently.","https://docs.snowflake.com/en/sql-reference/sql/alter-pipe, https://docs.snowflake.com/en/sql-reference/sql/create-pipe, https://docs.snowflake.com/en/user-guide/data-load-snowpipe-manage#label-snowpipe-management-recreate-pipes",,"Data Transformations, Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture"
299,What is the minimum Snowflake edition that customers planning on storing sensitive and protected information in Snowflake should consider for regulatory compliance?,C,Enterprise,Standard,Business Critical Edition,Premier,,,PII and HIPAA compliance are only supported for Business Critical Edition or higher.,https://docs.snowflake.com/en/user-guide/intro-editions#security-governance-data-protection,,"Snowflake AI Data Cloud Features and Architecture, Data Protection and Data Sharing"
300,Which of the following statements is true of zero-copy cloning?,B,Zero-copy clones increase storage costs as cloning the table requires storing its data twice,"At the instance/instant a clone is created, all micro-partitions in the original table and the clone are fully shared",Zero-copy cloning is licensed as an additional Snowflake feature,All zero-copy clone objects inherit the privileges of their original objects,,,"Using Zero-Copy cloning, you can create a snapshot of any table, schema, or database. The cloned object is independent and can be modified without modifying the original. It does NOT duplicate data; it duplicates the metadata of the micro-partitions, making it not consume storage.",https://docs.snowflake.com/en/user-guide/tables-storage-considerations#cloning-tables-schemas-and-databases,,Performance Concepts
301,What is the default access of a securable object until other access is granted?,B,Write access,No access,Read access,Full access,,,"Securable object: An entity to which access can be granted. Unless allowed by a grant, access is denied.",https://docs.snowflake.com/en/user-guide/security-access-control-overview,,Account Access and Security
302,"Which Snowflake object stores a generated identity and access management (IAM) entity for your external cloud storage, along with an optional set of allowed or blocked storage locations (Amazon S3, Google Cloud Storage, or Microsoft Azure)?",B,Security Integration.,Storage Integration.,User Stage.,Storage Schema.,,,A storage integration is a Snowflake object that stores a generated identity and access management (IAM) entity for your external cloud storage. This option will enable users to avoid supplying credentials when creating stages or when loading or unloading data.,https://docs.snowflake.com/en/sql-reference/sql/create-storage-integration,,Data Transformations
303,What is the purpose of the Snowflake SPLIT_TO_TABLE function?,D,To split a string and flatten the results into columns,To count the number of characters in a string,To split a string into an array of substrings,To split a string and flatten the results into rows,,,"SPLIT_TO_TABLE\n
This table function splits a string (based on a specified delimiter) and flattens the results into rows.",https://docs.snowflake.com/en/sql-reference/functions/split_to_table,,Data Transformations
304,When should you consider disabling auto-suspend for a Virtual Warehouse? (Choose two.),"B,E",When users will be using compute at different times throughout a 24/7 period,When managing a steady workload,When you do not want to have to manually turn on the Warehouse each time a user needs it,When you want to avoid queuing and handle concurrency,When the compute must be available with no delay or lag time,,,https://docs.snowflake.com/en/user-guide/warehouses-considerations#automating-warehouse-suspension,,Performance Concepts
305,Which of the following terms best describes Snowflake's database architecture?,A,"Multi-cluster, shared data",Cloud-native shared memory,Columnar shared nothing,Shared disk,,,"Built from the ground up for the cloud, Snowflake’s unique multi-cluster shared data architecture delivers the performance, scale, elasticity, and concurrency today’s organizations require.",https://www.snowflake.com/product/architecture/,,Snowflake AI Data Cloud Features and Architecture
306,What technique does Snowflake use to limit the number of micro-partitions retrieved as part of a query?,B,Clustering.,Pruning.,Indexing.,Computing.,,,"Query pruning consists of analyzing the smallest number of micro-partitions to solve a query. This technique retrieves all the necessary data to give a solution without looking at all the micro-partitions, saving a lot of time to return for the result.",https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#query-pruning,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
307,What columns are returned when performing a FLATTEN command on semi-structured data? (Choose two.),"A,E",VALUE,LEVEL,NODE,ROOT,KEY,,,https://docs.snowflake.com/en/sql-reference/functions/flatten#output,,Data Transformations
308,Which view in SNOWFLAKE.ACCOUNT_USAGE shows from which IP address a user connected to Snowflake?,D,SESSIONS,ACCESS_HISTORY,QUERY_HISTORY,LOGIN_HISTORY,,,,https://docs.snowflake.com/en/sql-reference/functions/login_history,,Data Transformations
309,What is the purpose of collecting statistics on data in Snowflake?,A,To enable efficient pruning based on query filters,To optimize query performance by reading all data in a table,To identify data storage order correlations,To reduce the total number of micro-partitions in a table,,,Snowflake collects rich statistics on data allowing it not to read unnecessary parts of a table based on the query filters. (Pruning),https://docs.snowflake.com/en/user-guide/ui-query-profile#inefficient-pruning,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
310,Snowflake provides two mechanisms to reduce data storage costs for short-lived tables. These mechanisms are: (Choose two.),"C,D",Permanent Tables,Materialized views,Temporary Tables,Transient Tables,Provisional Tables,,,https://docs.snowflake.com/en/user-guide/tables-storage-considerations,,Performance Concepts
311,Which of the following roles are NOT System-Defined Roles in Snowflake? (Choose two.),"B,E",SYSADMIN,STORAGEADMIN,USERADMIN,SECURITYADMIN,VIEWER,,The PUBLIC role is also a System-Defined role.,https://docs.snowflake.com/en/user-guide/security-access-control-overview#label-access-control-overview-roles-system,,Account Access and Security
312,What property from the Resource Monitors lets you specify whether you want to control the credit usage of your entire account or a specific set of warehouses?,A,Monitor Level.,Credit Quota.,Notification.,Schedule.,,,The monitor level is a property that specifies whether the resource monitor is used to monitor the credit usage for your entire account or individual warehouses.,https://docs.snowflake.com/en/user-guide/resource-monitors#assignment-of-resource-monitors,,Performance Concepts
313,A Snowflake user runs a query for 36 seconds on a size 2XL virtual warehouse. What would be the credit consumption?,D,Snowflake will charge for 36 seconds at the rate of 64 credits per hour.,Snowflake will charge for 60 seconds at the rate of 64 credits per hour.,Snowflake will charge for 36 seconds at the rate of 32 credits per hour.,Snowflake will charge for 60 seconds at the rate of 32 credits per hour.,,,"Credits are billed per-second, with a 60-second (i.e. 1-minute) minimum.",https://docs.snowflake.com/en/user-guide/cost-understanding-compute,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
314,"A Snowflake user wants to share data using my_share with account xy12345.
Which command should be used?",B,grant select on share my_share to account xy12345;,alter share my_share add accounts = xy12345;,grant usage on share my_share to account xy12345;,alter account xy12345 add share my_share;,,,"ALTER SHARE [ IF EXISTS ] <name> { ADD | REMOVE } ACCOUNTS = <consumer_account> [ , <consumer_account> , .. ] [ SHARE_RESTRICTIONS = { TRUE | FALSE } ]\n
ALTER SHARE [ IF\n
ALTER SHARE [ IF EXISTS ] <name> SET { [ ACCOUNTS = <consumer_account> [ , <consumer_account> .. ] ]",https://docs.snowflake.com/en/sql-reference/sql/alter-share,,"Data Transformations, Data Protection and Data Sharing"
315,A Snowflake user needs to import a JSON file larger than 16 MB. What file format option could be used?,D,compression = auto,strip_outer_array = false,trim_space = true,strip_outer_array = true,,,strip_outer_array = true will remove the outer array structure and copy the file into multiple table rows instead of row. (the limitation for table rows is max 16MB) with this solution it will be fine.,https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare#semi-structured-data-size-limitations,,Data Loading and Unloading
316,Which system-defined Snowflake role has permission to rename an account and specify whether the original URL can be used to access the renamed account?,D,ACCOUNTADMIN,SYSADMIN,SECURITYADMIN,ORGADMIN,,,"An organization administrator (i.e. a user granted the ORGADMIN role) can rename an account.\n
When an account is renamed, Snowflake creates a new account URL that is used to access the account. During the renaming, the administrator can accept the default to save the original account URL so users can continue to use it, or they can delete the original URL to force users to use the new URL.",https://docs.snowflake.com/en/user-guide/organizations-manage-accounts-rename,,Snowflake AI Data Cloud Features and Architecture
317,How often does Snowpipe load the data?,B,When we manually execute the COPY procedure.,As soon as they are available in a stage.,Once every 1 minute.,Once every 5 minutes.,,,Snowpipe enables loading data when the files are available in any (internal/external) stage. We use it when we have a small volume of frequent data and want to load it continuously (micro-batches). Snowpipe enables loading data when the files are available in any (internal/external) stage. We use it when we have a small volume of frequent data and want to load it continuously (micro-batches).,https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro,,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture"
318,Which of the following objects is not covered by Time Travel?,D,Databases,Schemas,Tables,Stages,,,,https://docs.snowflake.com/en/user-guide/data-time-travel,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
319,Increasing the maximum number of clusters in a Multi-Cluster Warehouse is an example of:,D,Scaling rhythmically,Scaling max,Scaling up,Scaling out,,,,https://docs.snowflake.com/en/user-guide/warehouses-considerations,,Performance Concepts
320,How can network and private connectivity security be managed in Snowflake?,A,By setting up network policies with IPv4 IP addresses,By manually setting up an Intrusion Prevention System (IPS) on each account,By manually setting up vulnerability patch management policies,By putting the Snowflake URL on the allowed list for get method responses,,,"Network policies provide options for managing network configurations to the Snowflake service.\n
Network policies allow restricting access to your account based on user IP address. Effectively, a network policy enables you to create an IP allowed list, as well as an IP blocked list, if desired.\n
Using network policies is one of the best practices related to network security.",https://docs.snowflake.com/en/user-guide/network-policies,,Account Access and Security
321,"A Snowflake user wants to temporarily bypass a network policy by configuring the user object property MINS_TO_BYPASS_NETWORK_POLICY.
What should they do?",D,Use the SECURITYADMIN role.,Use the SYSADMIN role.,Use the USERADMIN role.,Contact Snowflake Support.,,,"It is possible to temporarily bypass a network policy for a set number of minutes by configuring the user object property MINS_TO_BYPASS_NETWORK_POLICY, which can be viewed by executing DESCRIBE USER. Only Snowflake can set the value for this object property. Please contact Snowflake Support to set a value for this property.","https://docs.snowflake.com/en/user-guide/network-policies#bypassing-a-network-policy, https://docs.snowflake.com/en/sql-reference/sql/desc-user, https://community.snowflake.com/s/article/How-To-Submit-a-Support-Case-in-Snowflake-Lodge",,"Account Access and Security, Data Transformations, Snowflake AI Data Cloud Features and Architecture"
322,Which file format will keep floating-point numbers from being truncated when data is unloaded?,C,JSON,ORC,Parquet,CSV,,,"The data types such as FLOAT/DOUBLE/REAL (underlying using DOUBLE ), all are approximate values, they are all stored as DOUBLE which has a precision/scale of 15/9. When we are unloading floats/doubles, columns are unloaded to CSV or JSON files, Snowflake truncates the values to approximately (15,9). Precision is always not accurate. Snowflake can’t precisely represent any arbitrary value with double precision, it's as per industry standard. \n

When floating-point number columns are unloaded to CSV or JSON files, Snowflake truncates the values to approximately (15,9).\n

The values are not truncated when unloading floating-point number columns to Parquet files.","https://docs.snowflake.com/en/user-guide/data-unload-considerations#floating-point-numbers-truncated, https://community.snowflake.com/s/article/Floating-point-data-types-in-Snowflake",,"Data Loading and Unloading, Data Transformations"
323,What is a feature of column-level security in Snowflake?,A,External tokenization,Role access policies,Network policies,Internal tokenization,,,"Currently, Column-level Security includes two features:\n
-Dynamic Data Masking\n
-External Tokenization",https://docs.snowflake.com/user-guide/security-column-intro#what-is-column-level-security,,Data Protection and Data Sharing
324,What is the maximum row size in Snowflake?,B,50MB,16MB,500MB,8KB,,,16MB per row captured in the VARIANT field. Same for VARCHAR datatype.,https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare#semi-structured-data-size-limitations,,Data Loading and Unloading
325,A role is created and owns 2 tables. This role is then dropped. Who will now own the two tables?,A,The assumed role that dropped the role,The tables are now orphaned,SYSADMIN,The user that deleted the role,,,,https://docs.snowflake.com/en/sql-reference/sql/drop-role,,Data Transformations
326,"Which command is used to generate a zero-copy ""snapshot"" of any table, schema, or database?",B,COPY INTO,CREATE .. CLONE,CREATE REPLICATION GROUP,ALTER,,,,https://docs.snowflake.com/en/sql-reference/sql/create-clone,,Data Transformations
327,What are the available Snowflake scaling modes for configuring multi-cluster virtual warehouses? (Choose two.),"B,C",Scale-Out,Auto-Scale,Maximized,Economy,Standard,,"Note, that there are Scaling Policies called ""Economy"" and ""Standard"" in ""Auto-Scale"" mode.",https://docs.snowflake.com/en/user-guide/warehouses-multicluster#maximized-vs-auto-scale,,Performance Concepts
328,Which of the following sentences is an example of scaling up for a Snowflake virtual Warehouse?,C,Change from Economy Scaling Policy to Standard.,Request more data storage to our Cloud Provider.,Changing the size of a warehouse from L to XL.,Adding a new virtual warehouse of the same size.,,,Scaling up adds more compute power to a warehouse by improving the components. There will be a moment where scaling up is impossible as you cannot enhance the components more. Scaling out adds more warehouses to work in parallel. You can see it in the following image:,https://docs.snowflake.com/en/user-guide/warehouses-considerations#scaling-up-vs-scaling-out,,Performance Concepts
329,Which Snowflake object can be created to be temporary?,B,Storage integration,Stage,User,Role,,,,https://docs.snowflake.com/en/sql-reference/sql/create-stage,,Data Transformations
330,What strategies can be used to optimize the performance of a virtual warehouse? (Choose two.),"A,D",Increase the warehouse size.,Increase the MAX_CONCURRENCY_LEVEL parameter.,Suspend the warehouse frequently.,Reduce queuing.,Allow memory spillage.,,"Optimizing Warehouses for Performance:\n
-Reduce queues (if WH is not multi cluster make it multi cluster else add another WH)\n
-Resolve memory spillage ( scale up or convert it to Snowpark-optimized WH)\n
-Increase warehouse size (Scale up)\n
-Try Query Acceleration - set ENABLE_QUERY_ACCELERATION = true\n
-Optimizing the Warehouse Cache (by increasing Auto-suspension)\n
-Limiting Concurrently Running Queries (Decrease the MAX_CONCURRENCY_LEVEL)",https://docs.snowflake.com/en/user-guide/performance-query-warehouse,,Performance Concepts
331,"A developer is granted ownership of a table that has a masking policy. The developer’s role is not able to see the masked data.
Will the developer be able to modify the table to read the masked data?",D,"Yes, because a table owner has full control and can unset masking policies.","Yes, because masking policies only apply to cloned tables.","No, because masking policies must always reference specific access roles.","No, because ownership of a table does not include the ability to change masking policies.",,,"Object owners (i.e. the role that has the OWNERSHIP privilege on the object) do not have the privilege to unset masking policies.\n

Object owners cannot view column data in which a masking policy applies.",https://docs.snowflake.com/en/user-guide/security-column-intro#what-are-masking-policies,,Data Protection and Data Sharing
332,What is the recommended approach for unloading data to a cloud storage location from Snowflake?,B,"Unload the data to a local file system, then upload it to cloud storage.",Unload the data directly to the cloud storage location.,Use a third-party tool to unload the data to cloud storage.,"Unload the data to a user stage, then upload the data to cloud storage.",,,"The best approach is to use the COPY INTO <location> command to copy the data from the Snowflake database table into one or more files in a Snowflake or external stage.\n

After that you will be able to download the file from the stage to a local file system (not before)",https://docs.snowflake.com/en/user-guide/data-unload-overview#bulk-unloading-process,,Data Loading and Unloading
333,Which command can be used to list all the file formats for which a user has access privileges?,A,SHOW FILE FORMATS,LIST,DESCRIBE FILE FORMAT,ALTER FILE FORMAT,,,"SHOW FILE FORMATS: Lists the file formats for which you have access privileges. This command can be used to list the file formats for a specified database or schema (or the current database/schema for the session), or your entire account.",https://docs.snowflake.com/en/sql-reference/sql/show-file-formats,,Data Transformations
334,Which statistic displayed in a Query Profile is specific to external functions?,A,Total invocations,Partitions scanned,Bytes written,Bytes sent over the network,,,"Total invocations — number of times that an external function was called. (This can be different from the number of external function calls in the text of the SQL statement due to the number of batches that rows are divided into, the number of retries (if there are transient network problems), etc.)",https://docs.snowflake.com/en/user-guide/ui-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
335,Which Snowflake object can be used to record DML changes made to a table?,A,Stream,Stage,Snowpipe,Task,,,Streams are used for CDC purposes.,https://docs.snowflake.com/en/user-guide/streams,,Data Loading and Unloading
336,"To run a Multi-Cluster Warehouse in auto-scale mode, a user would:",D,Configure the Maximum Clusters setting to Auto-Scale,Set the Minimum Clusters and Maximum Clusters settings to the same value,Set the Warehouse type to Auto,Set the Minimum Clusters and Maximum Clusters settings to the different values,,,"If you set the minimum cluster count less than the maximum cluster count, then the warehouse runs in Auto-scale mode.",https://docs.snowflake.com/en/user-guide/warehouses-multicluster,,Performance Concepts
337,Which Snowflake features can be enabled by calling the SYSTEM$GLOBAL_ACCOUNT_SET_PARAMETER function by a user with the ORGADMIN role? (Choose two.),"B,D",Clustering,Client redirect,Fail-safe,Account and database replication,Search optimization service,,,https://docs.snowflake.com/en/sql-reference/functions/system_global_account_set_parameter,,Data Transformations
338,What type of function returns one value for each invocation?,D,Window,Aggregate,Table,Scalar,,,"A scalar function is a function that returns one value per invocation; in most cases, you can think of this as returning one value per row. This contrasts with Aggregate Functions, which return one value per group of rows.",https://docs.snowflake.com/en/sql-reference/functions,,Data Transformations
339,What are the key characteristics of ACСOUNT_USAGE views? (Choose two.),"A,E",Records for dropped objects are included in each view.,There is no data latency.,The historical data is not retained.,The historical data can be retained from 7 days to 6 months.,The data latency can vary from 45 minutes to 3 hours.,,,https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema,,Data Transformations
340,Which command can be used to delete staged files from a Snowflake stage when the files are no longer needed?,C,TRUNCATE TABLE,DELETE,REMOVE,DROP,,,REMOVE Removes files from either an external (external cloud storage) or internal (i.e. Snowflake) stage.,https://docs.snowflake.com/en/sql-reference/sql/remove,,Data Transformations
341,"Which Snowflake table type is only visible to the user who creates it, can have the same name as permanent tables in the same schema, and is dropped at the end of the session?",A,Temporary,User,Transient,Local,,,,https://docs.snowflake.com/en/user-guide/tables-temp-transient,,Performance Concepts
342,How many tasks can a tree of tasks have?,C,1000 without including the root task.,100,"1000, including the root task.",10,,,"Users can define a simple tree-like structure of tasks (refered to as a ""task graph"") that starts with a root task and is linked together by task dependencies. A tasks graph can have a maximum of 1000 tasks, including the root one. Also, each task can have a maximum of 100 children.",https://docs.snowflake.com/en/user-guide/tasks-graphs#create-a-task-graph,,Performance Concepts
343,Which function returns the name of the warehouse of the current session?,C,ACTIVE_WAREHOUSE(),RUNNING_WAREHOUSE(),CURRENT_WAREHOUSE(),WAREHOUSE(),,,"I'm not a big fan of learning commands by heart, and they are unlikely to appear on the exam, but this one may be useful. You have other commands to show the current database and schema, as you can see by executing the following command:\n
SELECT CURRENT_WAREHOUSE(), CURRENT_DATABASE(), CURRENT_SCHEMA();",https://docs.snowflake.com/en/sql-reference/functions/current_warehouse,,Data Transformations
344,Which of the following roles is recommended to be used to create and manage users and roles?,D,PUBLIC,SYSADMIN,ACCOUNTADMIN,SECURITYADMIN,,,,https://docs.snowflake.com/en/user-guide/security-access-control-configure,,Account Access and Security
345,Which Snowflake feature records changes made to a table so actions can be taken using that change data capture?,D,Pipe,Task,Materialized View,Stream,,,Note that a stream itself does not contain any table data. A stream only stores an offset for the source object and returns CDC records by leveraging the versioning history for the source object.,https://docs.snowflake.com/en/user-guide/streams-intro,,Data Loading and Unloading
346,Who can grant object privileges in a regular schema?,B,Database owner,Object owner,Schema owner,SYSADMIN,,,"In regular (i.e. non-managed) schemas, object owners (i.e. a role with the OWNERSHIP privilege on an object) can grant access on their objects to other roles, with the option to further grant those roles the ability to manage object grants\n

With managed access schemas, object owners lose the ability to make grant decisions. Only the schema owner (i.e. the role with the OWNERSHIP privilege on the schema) or a role with the MANAGE GRANTS privilege can grant privileges on objects in the schema, including future grants, centralizing privilege management.",https://docs.snowflake.com/en/user-guide/security-access-control-configure#label-managed-access-schemas,,Account Access and Security
347,Snowflake’s hierarchical key mode includes which keys? (Choose two.),"B,E",Secure view keys,File keys,Database master keys,Schema master keys,Account master keys,,"Snowflake’s hierarchical key model consists of four levels of keys: the root key, account master keys, table master keys, and file keys. Each account master key corresponds to one customer account in Snowflake. Each table master key corresponds to one database table in a database.","https://docs.snowflake.com/en/user-guide/security-encryption-manage#hierarchical-key-model, https://www.snowflake.com/en/blog/encryption-key-management-in-snowflake/",,Data Protection and Data Sharing
348,What should be the first option to restore data into a table?,B,Fail-Safe.,Time-Travel.,Zero-Copy Cloning.,Ask Snowflake Support,,,"Time-Travel enables accessing historical data (i.e., data that has been changed or deleted) at any point within a defined period. If we drop a table, we can restore it with time travel. You can use it with Databases, Schemas & Tables. The following diagram explains how Time-Travel works:",https://docs.snowflake.com/en/user-guide/data-time-travel,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
349,Files have been uploaded to a Snowflake internal stage. The files now need to be deleted. Which SQL command should be used to delete the files?,C,PURGE,DELETE,REMOVE,MODIFY,,,,https://docs.snowflake.com/en/sql-reference/sql/remove,,Data Transformations
350,What are characteristics of directory tables when used with unstructured data? (Choose two.),"B,E",Only cloud storage stages support directory tables.,A directory table can be added explicitly to a stage when the stage is created.,A directory table is a separate database object that can be layered explicitly on a stage.,Each directory table has grantable privileges of its own.,Directory tables store a catalog of staged files in cloud storage.,,"A directory table is an implicit object layered on a stage (not a separate database object) and is conceptually similar to an external table because it stores file-level metadata about the data files in the stage. A directory table has no grantable privileges of its own.\n

Both external (external cloud storage) and internal (Snowflake) stages support directory tables",https://docs.snowflake.com/en/user-guide/data-load-dirtables,,Data Loading and Unloading
351,What is the storage hierarchy in Snowflake?,A,Account → Databases → Schemas → Objects.,Account → Databases → Warehouses → Objects.,Account → Databases → Objects → Schemas.,Account → Schemas → Databases → Objects.,,,"The top-most container is the customer organization. All databases for your Snowflake account are contained in the account object. Securable objects such as tables, views, stages, and UDFs are contained in a schema object, which is, in turn, contained in a database.",https://docs.snowflake.com/en/user-guide/security-access-control-overview#securable-objects,,Account Access and Security
352,What aspect of an executed query is represented by the remote disk I/O statistic of the Query Profile in Snowflake?,D,Time spent reading and writing data from and to remote storage when the data being accessed does not fit into the executing virtual warehouse node memory,Time spent scanning the table partitions to filter data based on the predicate,Time spent caching the data to remote storage in order to buffer the data being extracted and exported,Time spent reading and writing data from and to remote storage when the data being accessed does not fit into either the virtual warehouse memory or the local disk,,,"For some operations (e.g. duplicate elimination for a huge data set), the amount of memory available for the compute resources used to execute the operation might not be sufficient to hold intermediate results. As a result, the query processing engine will start spilling the data to local disk. If the local disk space is not sufficient, the spilled data is then saved to remote disks.\n

This spilling can have a profound effect on query performance (especially if remote disk is used for spilling). Performance degrades drastically when a warehouse runs out of memory while executing a query because memory bytes must “spill” onto local disk storage. If the query requires even more memory, it spills onto remote cloud-provider storage, which results in even worse performance.\n

Remote Disk I/O is the metric of the Query profile which can analyze the time spent reading/writing data from/it remote storage (i.e. S3 or Azure Blob storage). This would include things like spilling to remote disk, or reading your datasets.",https://docs.snowflake.com/en/user-guide/ui-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
353,Which Snowflake edition allows a maximum of one day of Time Travel?,B,Business Critical.,Standard.,Enterprise.,No version allows only one day of Time Travel.,,,We can increase the Time Travel functionality to 90 days if we have (at least) the Snowflake Enterprise Edition.,https://docs.snowflake.com/en/user-guide/data-time-travel#data-retention-period,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
354,Account-level storage usage can be monitored via:,D,The Snowflake Web Interface (UI) in the Databases section,The Account Usage Schema -> ACCOUNT_USAGE_METRICS View,The Information Schema -> ACCOUNT_USAGE_HISTORY View,The Snowflake Web Interface (UI) in the Account -> Billing & Usage section,,,,https://docs.snowflake.com/en/user-guide/admin-usage-billing,,Account Access and Security
355,Which Snowflake object does not consume any storage costs?,A,Secure view,Transient table,Materialized view,Temporary table,,,"Transient and temporary tables contribute to the storage charges that Snowflake bills your account until explicitly dropped. Data stored in these table types contributes to the overall storage charges Snowflake bills your account while they exist.\n

Materialized views impact your costs for both storage and compute resources:\n
-Storage: Each materialized view stores query results, which adds to the monthly storage usage for your account.\n
-Compute resources: In order to prevent materialized views from becoming out-of-date, Snowflake performs automatic background maintenance of materialized views.",https://docs.snowflake.com/en/user-guide/overview-view-mview-dts#comparison-of-views-materialized-views-and-dynamic-tables,,Performance Concepts
356,What is the MINIMUM role required to set the value for the parameter ENABLE_ACCOUNT_DATABASE_REPLICATION?,A,ORGADMIN,ACCOUNTADMIN,SYSADMIN,SECURITYADMIN,,,"To enable replication for accounts, a user with the ORGADMIN role uses the SYSTEM$GLOBAL_ACCOUNT_SET_PARAMETER function to set the ENABLE_ACCOUNT_DATABASE_REPLICATION parameter to true.",https://docs.snowflake.com/en/sql-reference/functions/system_global_account_set_parameter#usage-notes,,Data Transformations
357,How many children tasks can a task have?,B,1,100,1000,10,,,Snowflake tasks are schedulable scripts that are run inside your Snowflake environment. Users can define a simple tree-like structure of tasks that starts with a root task and is linked together by task dependencies. The children's tasks only run after the parent's task finishes. A single task can have a maximum of 100 predecessor tasks and 100 child tasks.,https://docs.snowflake.com/en/user-guide/tasks-graphs#create-a-task-graph,,Performance Concepts
358,Which Snowflake object helps evaluate virtual warehouse performance impacted by query queuing?,A,Account_usage.query_history,Information_schema.warehouse_load_history,Information_schema.warehouse_metering_history,Resource monitor,,,Warehouse query load measures the average number of queries that were running or queued within a specific interval. You can customize the time period and time interval during which to evaluate warehouse performance by querying the Account Usage QUERY_HISTORY View.,https://docs.snowflake.com/en/user-guide/warehouses-load-monitoring,,Performance Concepts
359,Which of the following commands are not blocking operations? (Choose two.),"B,C",DELETE,INSERT,COPY,MERGE,UPDATE,,"The following guidelines apply in most situations:\n
COMMIT operations (including both AUTOCOMMIT and explicit COMMIT) lock resources, but usually only briefly. \n
UPDATE, DELETE, and MERGE statements hold locks that generally prevent them from running in parallel with other UPDATE, DELETE, and MERGE statements. \n
Most INSERT and COPY statements write only new partitions. Those statements often can run in parallel with other INSERT and COPY operations, and sometimes can run in parallel with an UPDATE, DELETE, or MERGE statement.",https://docs.snowflake.com/en/sql-reference/transactions#resource-locking,,Data Transformations
360,What is the Snowflake recommended Parquet file size when querying from external tables to optimize the number of parallel scanning operations?,C,1-16 MB,100-250 MB,256-512 MB,16-128 MB,,,"Parquet Files, Recommended Size Range: 256-512MB\n
Do not confuse this question with the size recommendation for COPY operations in Snowflake (100MB-250MB).",https://docs.snowflake.com/en/user-guide/tables-external-intro,,Performance Concepts
361,Which of the following is true of Snowpipe via REST API? (Choose two.),"B,C",You can only use it on Internal Stages,Snowflake automatically manages the compute required to execute the Pipe's COPY INTO commands,Snowpipe keeps track of which files it has loaded,All COPY INTO options are available during pipe creation,Snowpipe removes files after they have been loaded,,,"https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro, https://docs.snowflake.com/en/sql-reference/sql/create-pipe#usage-notes, https://docs.snowflake.com/en/user-guide/data-load-snowpipe-manage",,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture, Data Transformations"
362,What are the types of data consumer accounts available in Snowflake? (Choose two.),"C,E",Public Account,Shared Account,Full Account,Subscriber account,Reader Account,,"There are two types of data consumers. The first one is the Full Accounts, the consumers with existing Snowflake accounts. In this case, the consumer account pays for the queries they make. We also have the Reader Accounts, the consumers without Snowflake accounts. In this last case, the producer account pays all the compute credits that their warehouses use. You can see this behavior in the following diagram:",https://docs.snowflake.com/en/user-guide/data-sharing-intro#how-does-secure-data-sharing-work,,Data Protection and Data Sharing
363,Which clients does Snowflake support Multi-Factor Authentication (MFA) token caching for? (Choose two.),"A,C",ODBC driver,Spark connector,Python connector,Node.js driver,GO driver,,"Snowflake supports MFA token caching with the following drivers and connectors on macOS and Windows. This feature is not supported on Linux.\n
ODBC driver version 2.23.0 (or later).\n
JDBC driver version 3.12.16 (or later).\n
Python Connector for Snowflake version 2.3.7 (or later).",https://docs.snowflake.com/en/user-guide/security-mfa,,Account Access and Security
364,"Regardless of which notation is used, what are considerations for writing the column name and element names when traversing semi-structured data?",A,The column name is case-insensitive but element names are case-sensitive,The column name and element names are both case-insensitive.,The column name is case-sensitive but element names are case-insensitive.,The column name and element names are both case-sensitive.,,,"Regardless of which notation you use, the column name is case-insensitive but element names are case-sensitive.\n

For example, (src is a column name) in the following list, the first two paths are equivalent, but the third is not:\n
src:salesperson.name\n
SRC:salesperson.name\n
SRC:Salesperson.Name",https://docs.snowflake.com/en/user-guide/querying-semistructured,,Performance Concepts
365,What value provides information about disk usage for operations where intermediate results do not fit in memory in a Query Profile?,D,Pruning,IO,Network,Spilling,,,Spilling — information about disk usage for operations where intermediate results do not fit in memory,https://docs.snowflake.com/en/user-guide/ui-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
366,What does a Query Profile provide in Snowflake?,B,A pre-computed data set derived from a query specification and stored for later use.,A graphical representation of the main components of the processing plan for a query.,A collapsible panel in the operator tree pane that lists nodes by execution time in descending order for a query.,A multi-step query that displays each processing step in the same panel.,,,"Query Profile, available through the classic web interface, provides execution details for a query. For the selected query, it provides a graphical representation of the main components of the processing plan for the query, with statistics for each component, along with details and statistics for the overall query.",https://docs.snowflake.com/en/user-guide/ui-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
367,What types of views are available in Snowflake? (Choose three.),"A,D,E",Materialized View,Table View,External View,Secure View,Regular,Private View,,https://docs.snowflake.com/en/user-guide/views-introduction#types-of-views,,Performance Concepts
368,"Which Snowflake edition supports Protected Health Information (PHI) data (in accordance with HIPAA and HITRUST CSF regulations), and has a dedicated metadata store and pool of compute resources?",B,Enterprise,Virtual Private Snowflake (VPS),Business Critical,Standard,,,Virtual Private Snowflake offers dedicated metadata store and pool of compute resources (used in virtual warehouses).,https://docs.snowflake.com/en/user-guide/intro-editions,,Snowflake AI Data Cloud Features and Architecture
369,Which command will we use to download the files from an internal stage that were loaded through the COPY INTO <LOCATION> command?,C,UNLOAD.,PUT.,GET.,INSERT INTO.,,,"We will use the GET command to DOWNLOAD files from a Snowflake internal stage (named internal stage, user stage, or table stage) into a directory/folder on a client machine. You need to use SnowSQL to use this command.",https://docs.snowflake.com/en/sql-reference/sql/get,,Data Transformations
370,"During periods of warehouse contention, which parameter controls the maximum length of time a warehouse will hold a query for processing?",D,QUERY_TIMEOUT_IN_SECONDS,STATEMENT_TIMEOUT_IN_SECONDS,MAX_CONCURRENCY_LEVEL,STATEMENT_QUEUED_TIMEOUT_IN_SECONDS,,,"STATEMENT_QUEUED_TIMEOUT_IN_SECONDS\n

Amount of time, in seconds, a SQL statement (query, DDL, DML, etc.) remains queued for a warehouse before it is canceled by the system.",https://docs.snowflake.com/en/sql-reference/parameters#statement-queued-timeout-in-seconds,,Data Transformations
371,"Which Snowflake feature allows a user to track sensitive data for compliance, discovery, protection, and resource usage?",C,Internal tokenization,Comments,Tags,Row access policies,,,"Tags enable data stewards to monitor sensitive data for compliance, discovery, protection, and resource usage use cases through either a centralized or decentralized data governance management approach.",https://docs.snowflake.com/en/user-guide/object-tagging,,Performance Concepts
372,Which of the following statements are true concerning the Snowflake release process? (Choose three.),"B,E,F",A customer is assigned a 30 minute window (that can be moved anytime within a week) during which the system will be unavailable and customer is upgraded,It is possible for you as a user to request 24-hour early access to the upcoming releases so that you can do additional release testing before the release is rolled out.,There is usually some minimal downtime associated with Snowflake during the deployments.,"Snowflake deploys patch releases every week, but new feature releases happen once a month.",Snowflake deploys new Behavior change releases every month.,Snowflake deploys new feature releases and releases every week.,The deployment processes happen transparently in the background; users experience no downtime or disruption of service. You can see the different release types at the following link.,https://docs.snowflake.com/en/user-guide/intro-releases,,Snowflake AI Data Cloud Features and Architecture
373,Why is a federated environment used for user authentication in Snowflake?,D,To provide real-time monitoring of user activities,To enable direct integration with external databases,To enhance data security and privacy,To separate user authentication from user access,,,"In a federated environment, user authentication is separated from user access.",https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-overview#what-is-a-federated-environment,,Account Access and Security
374,"If a Small Warehouse is made up of 2 servers/cluster, how many servers/cluster make up a Medium Warehouse?",C,128,32,4,16,,,,https://docs.snowflake.com/en/user-guide/warehouses-overview,,Performance Concepts
375,Which MINIMUM set of privileges is required to temporarily bypass an active network policy by configuring the user object property MINS_TO_BYPASS_NETWORK_POLICY?,A,Only Snowflake Support can set the value for this object property,Only the role with the OWNERSHIP privilege on the network policy,Only while in the ACCOUNTADMIN role,Only while in the SECURITYADMIN role,,,"It is possible to temporarily bypass a network policy for a set number of minutes by configuring the user object property MINS_TO_BYPASS_NETWORK_POLICY, which can be viewed by executing DESCRIBE USER. Only Snowflake can set the value for this object property. Please contact Snowflake Support to set a value for this property.",https://docs.snowflake.com/en/user-guide/network-policies#bypassing-a-network-policy,,Account Access and Security
376,What is the purpose of using the OBJECT_CONSTRUCT function with the COPY INTO command?,B,Reorder the rows in a relational table and then unload the rows into a file.,Convert the rows in a relational table to a single VARIANT column and then unload the rows into a file.,Reorder the data columns according to a target table definition and then unload the rows into the table.,Convert the rows in a source file to a single VARIANT column and then load the rows from the file to a variant table.,,,"An OBJECT can contain semi-structured data and can be used to create hierarchical data structures.\n

OBJECT_CONSTRUCT returns a VARIANT object, essentially a JSON document, as an output, with either the key:value pairs as inputs or an asterisk (as in SELECT *) from a relational query.\n

You can use the OBJECT_CONSTRUCT function combined with the COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file.",https://docs.snowflake.com/en/user-guide/data-unload-considerations#unloading-a-relational-table-to-json,,Data Loading and Unloading
377,What action can a user take to address query concurrency issues?,A,Add additional clusters to the virtual warehouse.,Enable the search optimization service.,Enable the query acceleration service.,Resize the virtual warehouse to a larger instance size.,,,"Multi-cluster warehouses are best utilized for scaling resources to improve concurrency for users/queries. They are not as beneficial for improving the performance of slow-running queries or data loading. For these types of operations, resizing the warehouse provides more benefits.",https://docs.snowflake.com/en/user-guide/warehouses-multicluster,,Performance Concepts
378,What consideration should be made when loading data into Snowflake?,B,Create small data files to optimize data loading.,The number of data files that are processed in parallel is determined by the virtual warehouse.,The number of load operations that run in parallel can exceed the number of data files to be loaded.,Create small data files and stage them in cloud storage frequently.,,,One of the most typical practices of data ingestion.,https://docs.snowflake.com/en/user-guide/data-load-considerations-plan,,Data Loading and Unloading
379,Which function should be used to authorize users to access rows in a base table when using secure views with Secure Data Sharing?,D,CURRENT_ROLE(),CURRENT_USER(),CURRENT_SESSION(),CURRENT_ACCOUNT(),,,"When using secure views with Secure Data Sharing, use the CURRENT_ACCOUNT function to authorize users from a specific account to access rows in a base table.",https://docs.snowflake.com/en/user-guide/views-secure,,"Data Protection and Data Sharing, Performance Concepts"
380,"A virtual warehouse initially suffers from poor performance as a result of queries from multiple concurrent processes that are queuing. Over time, the problem resolved.
What action can be taken to prevent this from happening again?",A,Change the multi-cluster settings to add additional clusters.,Increase the size of the virtual warehouse.,Add a cluster key to the most used JOIN key.,Enable the search optimization service for the underlying tables.,,,"Multi-cluster warehouses are designed specifically for handling queuing and performance issues related to large numbers of concurrent users and/or queries. In addition, multi-cluster warehouses can help automate this process if your number of users/queries tend to fluctuate",https://docs.snowflake.com/en/user-guide/warehouses-considerations#multi-cluster-warehouses-improve-concurrency,,Performance Concepts
381,Which stream type can be used for tracking the records in external tables?,C,External,Append-only,Insert-only,Standard,,,,https://docs.snowflake.com/en/user-guide/streams-intro#types-of-streams,,Data Loading and Unloading
382,"A Snowflake query took 40 minutes to run. The results indicate that ‘Bytes spilled to local storage’ was a large number.
What is the issue and how can it be resolved?",D,The warehouse is too large. Decrease the size of the warehouse to reduce the spillage.,The warehouse consists of a single cluster. Use a multi-cluster warehouse to reduce the spillage.,The Snowflake console has timed-out. Contact Snowflake Support.,The warehouse is too small. Increase the size of the warehouse to reduce the spillage.,,,Warehouse size should be increased (Scale up). Multi cluster warehouse will just help in managing concurrency.,https://docs.snowflake.com/en/user-guide/performance-query-warehouse-memory,,Performance Concepts
383,What is the recommended Snowflake data type to store semi-structured data like JSON?,C,VARCHAR,LOB,VARIANT,RAW,,,"Semi-structured data is saved as Variant type in Snowflake tables, with a maximum limit size of 16MB, and it can be queried using JSON notation. You can store arrays, objects, etc.",https://docs.snowflake.com/en/sql-reference/data-types-semistructured,,Data Transformations
384,The VALIDATE table function has which parameter as an input argument for a Snowflake user?,A,JOB_ID,CURRENT_STATEMENT,UUID_STRING,LAST_QUERY_ID,,,"Syntax: VALIDATE( [<namespace>.]<table_name> , JOB_ID => { '<query_id>' | '_last' } )",https://docs.snowflake.com/en/sql-reference/functions/validate,,Data Transformations
385,Which command is used to take away staged files from a Snowflake stage after a successful data ingestion?,A,REMOVE,TRUNCATE,DELETE,DROP,,,"Staged files can be deleted from a Snowflake stage (user stage, table stage, or named stage) using the following methods:\n
-Files that were loaded successfully can be deleted from the stage during a load by specifying the PURGE copy option in the COPY INTO <table> command.\n
-After the load completes, use the REMOVE command to remove the files in the stage.",https://docs.snowflake.com/en/user-guide/data-load-considerations-manage,,Data Loading and Unloading
386,Which Snowflake edition (and above) allows until 90 days of Time Travel?,A,Enterprise.,Standard.,Business Critical.,Virtual Private Snowflake,,,"By default, Time travel is enabled with a 1-day retention period. However, we can increase it to 90 days if we have (at least) the Snowflake Enterprise Edition. It requires additional storage, which will be reflected in your monthly storage charges.",https://docs.snowflake.com/en/user-guide/data-time-travel#data-retention-period,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
387,In which layer of its architecture does Snowflake store its metadata statistics?,C,Compute Layer,Database Layer,Cloud Services Layer,Storage Layer,,,,https://hevodata.com/blog/snowflake-architecture-cloud-data-warehouse/,,Snowflake AI Data Cloud Features and Architecture
388,Who can access a referenced file through a scoped URL?,D,Any role specified in the GET REST API call with sufficient privileges,Only the ACCOUNTADMIN,Any user specified in the GET REST API call with sufficient privileges,Only the user who generates the URL,,,Only the user who generated the scoped URL can use the URL to access the referenced file.,https://docs.snowflake.com/en/user-guide/data-load-unstructured-rest-api,,"Data Transformations, Data Loading and Unloading"
389,What is the Snowflake multi-clustering feature for virtual warehouses used for?,C,To improve the data unloading process to the cloud,To speed up slow or stalled queries,To improve concurrency for users and queries,To improve data loading from very large data sets,,,"Multi-cluster warehouses enable you to scale compute resources to manage your user and query concurrency needs as they change, such as during peak and off hours.",https://docs.snowflake.com/en/user-guide/warehouses-multicluster,,Performance Concepts
390,What object will you use to schedule a merge statement in Snowflake so that it runs every hour?,B,Pipe.,Task.,Stream.,Table.,,,"Snowflake tasks are schedulable scripts that are run inside your Snowflake environment. No event source can trigger a task; instead, a task runs on a schedule. In this case, it will run every hour.",https://docs.snowflake.com/en/user-guide/tasks-intro,,Performance Concepts
391,Which Snowflake feature can be used to find sensitive data in a table or column?,B,Masking policies,Data classification,External functions,Row level policies,,,Data Classification allows categorizing potentially personal and/or sensitive data to support compliance and privacy regulations.,https://docs.snowflake.com/en/guides-overview-govern,,Data Protection and Data Sharing
392,A medium (M) warehouse has auto-suspend configured after 15 minutes. You have noticed that all of the queries that run on this warehouse finish within a minute. What will you do to optimize compute costs?,B,Delete the warehouse after a minute.,Reduce the auto-suspend time to 1 minute.,Use another data-warehouse.,Disable the auto-suspend option.,,,"By reducing the minutes of the ""auto-suspend"" option, the warehouse will automatically go to sleep after 60 seconds of inactivity, significantly reducing credit consumption.",https://docs.snowflake.com/en/user-guide/warehouses-considerations#automating-warehouse-suspension,,Performance Concepts
393,Which statement accurately describes how a virtual warehouse functions?,C,Each virtual warehouse is an independent compute cluster that shares compute resources with other warehouses.,All virtual warehouses share the same compute resources so performance degradation of one warehouse can significantly affect all the other warehouses.,Each virtual warehouse is a compute cluster composed of multiple compute nodes allocated by Snowflake from a cloud provider.,Increasing the size of a virtual warehouse will always improve data loading performance.,,,Query execution is performed in the processing layer. Snowflake processes queries using “virtual warehouses”. Each virtual warehouse is an MPP compute cluster composed of multiple compute nodes allocated by Snowflake from a cloud provider.,https://docs.snowflake.com/en/user-guide/intro-key-concepts,,Snowflake AI Data Cloud Features and Architecture
394,Which of the following sizes is not a Warehouse Size?,A,XXS,XS,S,M,,,"The minimum configuration for a Snowflake Warehouse is X-Small (XS), which consumes one credit/hour.",https://docs.snowflake.com/en/user-guide/warehouses-overview#warehouse-size,,Performance Concepts
395,The three main Snowflake layers are…,D,"Database, Virtual Warehouse, Metadata.","Extraction, Load, Transformation.","Staging, Data Warehouse, Dimensional.","Centralized Storage, Compute & Cloud Services.",,,,https://docs.snowflake.com/en/user-guide/intro-key-concepts,,Snowflake AI Data Cloud Features and Architecture
396,Which functions can be used to share unstructured data through a secure view? (Choose two.),"A,D",GET_PRESIGNED_URL,GET_RELATIVE_PATH,BUILD_STAGE_FILE_URL,BUILD_SCOPED_FILE_URL,GET_ABSOLUTE_PATH,,,https://docs.snowflake.com/en/user-guide/unstructured-data-sharing,,"Data Protection and Data Sharing, Data Loading and Unloading"
397,Which objects together comprise a namespace in Snowflake? (Choose two.),"C,D",Which objects together comprise a namespace in Snowflake? (Choose two.),Table,Schema,Database,Account,Virtual warehouse,,https://docs.snowflake.com/en/sql-reference/ddl-database,,Data Transformations
398,What actions can the resource monitor associated with a Warehouse take when it reaches (or is about to) hit the limit? (Choose three.),"B,D,F",Execute DROP WAREHOUSE statement.,Kill the query that is running.,Delete the Snowflake account.,Send a notification alert.,Open a Snowflake support case,Suspend the Warehouse.,"A resource monitor can Notify, Notify & Suspend, and Notify & Suspend Immediately. You can see these three actions in the following image:",https://docs.snowflake.com/en/user-guide/resource-monitors#actions,,Performance Concepts
399,Which property needs to be added to the ALTER WAREHOUSE command to verify the additional compute resources for a virtual warehouse have been fully provisioned?,D,SCALING_POLICY,QUERY_ACCELERATION_MAX_SCALE_FACTOR,RESOURCE_MONITOR,WAIT_FOR_COMPLETION,,,,https://docs.snowflake.com/en/user-guide/warehouses-tasks,,Performance Concepts
400,What is the lowest Snowflake edition that offers Time Travel up to 90 days?,D,Business Critical Edition,Standard Edition,Premier Edition,Enterprise Edition,,,,https://docs.snowflake.com/en/user-guide/data-availability,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
401,Which of the following commands are valid options for the VALIDATION_MODE parameter within the Snowflake COPY_INTO command? (Choose two.),"D,E",TRUE,RETURN_FIRST_n_ERRORS,RETURN_ERROR_SUM,RETURN_n_ROWS,RETURN_ALL_ERRORS,,VALIDATION_MODE = RETURN_n_ROWS | RETURN_ERRORS | RETURN_ALL_ERRORS,https://docs.snowflake.com/en/sql-reference/sql/copy-into-table,,Data Transformations
402,What storage cost is completely eliminated when a Snowflake table is defined as transient?,D,Time Travel,Active,Staged,Fail-safe,,,"Similar to permanent tables, transient tables contribute to the overall storage charges that Snowflake bills your account; however, because transient tables do not utilize Fail-safe, there are no Fail-safe costs (i.e. the costs associated with maintaining the data required for Fail-safe disaster recovery).",https://docs.snowflake.com/en/user-guide/tables-temp-transient,,Performance Concepts
403,"What Snowflake feature provides a data hub for secure data collaboration, with a selected group of invited members?",D,Snowflake Marketplace,Data Replication,Secure Data Sharing,Data Exchange,,,Data Exchange provides a data hub for securely collaborating around data with a selected group of members that you invite.,https://docs.snowflake.com/en/user-guide/data-exchange,,Data Protection and Data Sharing
404,Which data types can be used in a Snowflake table that holds semi-structured data? (Choose two.),"D,E",BINARY,TEXT,VARCHAR,VARIANT,ARRAY,,,https://docs.snowflake.com/en/user-guide/semistructured-intro,,Data Loading and Unloading
405,What is the minimum Snowflake edition that provides multi-cluster warehouses?,D,Premier,Business Critical Edition,Standard,Enterprise,,,,https://docs.snowflake.com/en/user-guide/intro-editions,,Snowflake AI Data Cloud Features and Architecture
406,How many shares can be consumed by a single Data Consumer?,D,"100, but can be increased by contacting support",1,10,Unlimited,,,,https://docs.snowflake.com/en/user-guide/data-sharing-intro,,Data Protection and Data Sharing
407,What information does the Query Profile provide?,D,Real-time monitoring of the database operations,Graphical representation of the data model,Detailed information about the database schema,Statistics for each component of the processing plan,,,"Query Profile provides execution details for a query. For the selected query, it provides a graphical representation of the main components of the processing plan for the query, with statistics for each component, along with details and statistics for the overall query.",https://docs.snowflake.com/en/user-guide/ui-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
408,What does the average_overlaps in the output of SYSTEM$CLUSTERING_INFORMATION refer to?,D,The average number of micro-partitions in the table associated with cloned objects.,The average number of micro-partitions stored in Time Travel.,The average number of partitions physically stored in the same location.,The average number of micro-partitions which contain overlapping value ranges.,,,,https://docs.snowflake.com/en/sql-reference/functions/system_clustering_information,,Data Transformations
409,How many predecessor tasks can a child task have?,D,All the parents that we establish.,1,1000,100,,,"A child task USED TO HAVE only a predecessor task. As a new feature of September 2022, Snowflake also supports DAG of tasks. In a DAG, each non-root task can have dependencies on multiple predecessor tasks, increasing the previous limit to 100 predecessors.",https://docs.snowflake.com/en/user-guide/tasks-graphs,,Performance Concepts
410,Which of the following are not types of streams in Snowflake? (Choose two.),"A,D",Update-only.,Append-only.,Insert-only.,Merge-only.,Standard.,,"Standard and Append-only streams are supported on tables, directory tables, and views. The Standard one tracks all DML changes to the source table, including inserts, updates, and deletes, whereas the Append-only one Tracks row inserts only. The Insert-only stream also tracks row inserts only. The difference with the previous one is that this one is only supported on EXTERNAL TABLES.",https://docs.snowflake.com/en/user-guide/streams-intro#types-of-streams,,Data Loading and Unloading
411,How is enhanced authentication achieved in Snowflake? (Choose two.),"A,D",Multi-Factor Authentication (MFA),Snowflake-managed keys,Masking policies,Federated authentication and Single Sign-On (SSO),Object level access control,,Object level access control,https://docs.snowflake.com/guides-overview-secure,,"Data Protection and Data Sharing, Account Access and Security"
412,"When unloading the data for file format type specified (TYPE = 'CSV'), SQL NULL can be converted to string ‘null’ using which file format option?",D,ESCAPE_UNENCLOSED_FIELD,SKIP_BYTE_ORDER_MARK,EMPTY_FIELD_AS_NULL,NULL_IF,,,"NULL_IF = ( 'string1' [ , 'string2' .. ] )\n

When unloading data from tables: Snowflake converts SQL NULL values to the first value in the list. Be careful to specify a value that you want interpreted as NULL. For example, if you are unloading data to a file that will get read by another system, make sure to specify a value that will be interpreted as NULL by that system.",https://docs.snowflake.com/en/user-guide/data-unload-considerations#empty-strings-and-null-values,,Data Loading and Unloading
413,Which Snowflake data types can be used to build nested hierarchical data? (Choose two),"C,D",INTEGER,VARCHAR,OBJECT,VARIANT,LIST,,"You can use Snowflake data types to construct a hierarchy to hold your semi-structured data by using the following properties of data types:\n
-A VARIANT can hold a value of any other data type, including an ARRAY or an OBJECT.\n
-An ARRAY or OBJECT holds a value of type VARIANT.",https://docs.snowflake.com/en/user-guide/semistructured-intro,,Data Loading and Unloading
414,Which of the following services are NOT provided by the Cloud Services Layer? (Choose two.),"B,D",Metadata Management.,Storage.,Authentication.,Query Execution.,Infrastructure Management.,,"The Cloud Services layer is a collection of services coordinating activities across Snowflake. It's in charge of Authentication, Infrastructure management, Metadata management, Query parsing and optimization, and Access control.",https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture,,Snowflake AI Data Cloud Features and Architecture
415,Which of these features is NOT supported by Snowflake?,D,Manage roles.,Manage users.,Monitor usage and cost.,Manage the data that 3rd party applications upload to the marketplace.,,,"You can provide and consume listings offered privately or publicly using the Snowflake Marketplace, discovering and accessing a variety of third-party datasets. Becoming a provider of listings in Snowflake makes it easier to manage sharing from your account to other Snowflake accounts.",https://docs.snowflake.com/en/guides-overview-sharing,,Data Protection and Data Sharing
416,When should a multi-cluster virtual warehouse be used in Snowflake?,D,When there is significant disk spilling shown on the Query Profile,When dynamic vertical scaling is being used in the warehouse,When there are no concurrent queries running on the warehouse,When queuing is delaying query execution on the warehouse,,,,https://docs.snowflake.com/en/user-guide/warehouses-multicluster#what-is-a-multi-cluster-warehouse,,Performance Concepts
417,"If you want a multi-cluster warehouse, which is the lowest Snowflake edition that you should opt for?",D,Virtual Private Snowflake.,Business Critical.,Standard.,Enterprise.,,,,https://docs.snowflake.com/en/user-guide/intro-editions#compute-resource-management,,Snowflake AI Data Cloud Features and Architecture
418,What parameter controls if the Virtual Warehouse starts immediately after the CREATE WAREHOUSE statement?,D,START_TIME = CURRENT_DATE(),START_AFTER_CREATE = TRUE/FALSE,START_THE = 60 // (seconds from now),INITIALLY_SUSPENDED = TRUE/FALSE,,,"Syntax:\n
CREATE [ OR REPLACE ] WAREHOUSE [ IF NOT EXISTS ] <name>\n
[ [ WITH ] objectProperties ]\n
[ objectParams ]\n
Where:\n
objectProperties ::=\n
WAREHOUSE_SIZE = XSMALL | SMALL | MEDIUM | LARGE | XLARGE | XXLARGE | XXXLARGE | X4LARGE | X5LARGE | X6LARGE\n
MAX_CLUSTER_COUNT = <num>\n
MIN_CLUSTER_COUNT = <num>\n
SCALING_POLICY = STANDARD | ECONOMY\n
AUTO_SUSPEND = <num> | NULL\n
AUTO_RESUME = TRUE | FALSE\n
INITIALLY_SUSPENDED = TRUE | FALSE\n
RESOURCE_MONITOR = <monitor_name>\n
COMMENT = '<string_literal>'\n
ENABLE_QUERY_ACCELERATION = TRUE | FALSE\n
QUERY_ACCELERATION_MAX_SCALE_FACTOR = <num>",https://docs.snowflake.com/en/sql-reference/sql/create-warehouse#optional-properties-objectproperties,,Data Transformations
419,Which query contains a Snowflake hosted file URL in a directory table for a stage named bronzestage?,D,select * from table(information_schema.stage_directory_file_registration_history( stage_name=>'bronzestage'));,select metadata$filename from @bronzestage;,list @bronzestage;,select * from directory(@bronzestage);,,,Following parameter: FILE_URL -Snowflake-hosted file URL to the file.,https://docs.snowflake.com/en/user-guide/data-load-dirtables-manage,,Data Loading and Unloading
420,"When floating-point number columns are unloaded to CSV or JSON files, Snowflake truncates the values to approximately what?",D,"(14,8)","(12,2)","(10,4)","(15,9)",,,,https://docs.snowflake.com/en/user-guide/data-unload-considerations,,Data Loading and Unloading
421,Which of the following statements are true of VALIDATION_MODE in Snowflake? (Choose two.),"B,D",The VALIDATION_MODE parameter supports COPY statements that transform data during a load,The VALIDATION_MODE option will validate data to be loaded by the COPY statement without completing the load and will return possible errors,The VALIDATION_MODE option will validate data to be loaded by the COPY statement while completing the load and will return the rows that could not be loaded without error,VALIDATION_MODE=RETURN_ALL_ERRORS is a parameter of the COPY command,The VALIDATION_MODE parameter supports COPY statements that load data from external stages only,,,https://docs.snowflake.com/en/user-guide/data-load-bulk-ts,,Data Loading and Unloading
422,Which property helps us control the credits consumed by a multi-cluster warehouse?,D,Maximum Clusters (MAX_CLUSTERS),Maximum Credits (MAX_CREDITS),Auto scale (AUTO_SCALE),Scaling policy (SCALING_POLICY),,,"When you create a multi-cluster warehouse, you need to specify a scaling policy to help you control the credits consumed by the multi-cluster warehouse. There are two types of policies; the ""Standard policy"" prioritizes starting additional warehouses over conserving credits. The ""Economy policy"" is a more restrictive policy that prioritizes conserving credits over conserving starting additional warehouses. You can set the scaling policy by executing the CREATE WAREHOUSE or ALTER WAREHOUSE command specifying the SCALING_POLICY. For example:\n
ALTER WAREHOUSE mywh SET SCALING_POLICY = 'ECONOMY';",https://docs.snowflake.com/en/user-guide/warehouses-multicluster#setting-the-scaling-policy-for-a-multi-cluster-warehouse,,Performance Concepts
423,Snowflake best practice recommends that which role be used to enforce a network policy on a Snowflake account?,D,ACCOUNTADMIN,USERADMIN,SYSADMIN,SECURITYADMIN,,,,https://docs.snowflake.com/en/sql-reference/sql/create-network-policy,,Data Transformations
424,Which roles can create shares and resource monitors?,D,SECURITYADMIN,SYSADMIN,USERADMIN,ACCOUNTADMIN,,,"ACCOUNTADMIN is the only role that is able to create Shares and Resource Monitors by default. However, account administrators can choose to enable users with other roles to view and modify resource monitors using SQL.",https://docs.snowflake.com/en/user-guide/resource-monitors,,Performance Concepts
425,What is the only supported character set for loading and unloading data from all supported file formats?,D,UTF-16,WINDOWS-1253,ISO-8859-1,UTF-8,,,,https://docs.snowflake.com/en/sql-reference/sql/create-file-format,,Data Transformations
426,Which system functions are available in Snowflake to view/monitor the clustering metadata for a table? (Choose two.),"B,D",SYSTEM$CLUSTERING_STATUS,SYSTEM$CLUSTERING_DEPTH,SYSTEM$CLUSTERING_METADATA,SYSTEM$CLUSTERING_INFORMATION,SYSTEM$CLUSTERING,,"The clustering depth measures the average depth of the overlapping micro-partitions for specified columns in a table (1 or greater). The smaller the cluster depth is, the better clustered the table is. You can use any previous commands to get the Cluster Depth of a table.",https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#monitoring-clustering-information-for-tables,,Performance Concepts
427,How a Snowpipe charges calculated?,D,Number of Pipes in account,Total storage bucket size,Per-second/per Warehouse size,Per-second/per-core granularity,,,,https://docs.snowflake.com/en/user-guide/data-load-snowpipe-billing,,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture"
428,Which are the metadata columns for staged files? (Choose two.),"C,D",METADATA$FILEFORMAT,METADATA$FILE_SIZE,METADATA$FILENAME,METADATA$FILE_ROW_NUMBER,METADATA$FILE_ROW_ID,,"The METADATA$FILENAME column is the name of the staged data file that the current row belongs to. The METADATA$FILE_ROW_NUMBER is the row number for each record in the container staged data file. This is a way of query the stage metadata:\n


SELECT metadata$filename, metadata$file_row_number from @MY_STAGE",https://docs.snowflake.com/en/user-guide/querying-metadata,,Performance Concepts
429,Which data formats are supported by Snowflake when unloading semi-structured data? (Choose two.),"B,D",Binary file in Avro,Newline Delimited JSON,Comma-separated JSON,Binary file in Parquet,Plain text file containing XML elements,,"Binary file in Parquet, Newline Delimited JSON (ndjson)",https://docs.snowflake.com/en/user-guide/data-unload-prepare#supported-file-formats,,Data Loading and Unloading
430,Which are the additional columns that the streams create? (Choose three.),"B,D,E",METADATA$COLUMN_ID,METADATA$ISUPDATE,METADATA$IS_DELETED,METADATA$ACTION,METADATA$ROW_ID,METADATA$ISREAD,"METADATA$ACTION Indicates the DML operation (INSERT, DELETE) recorded.\n

METADATA$ISUPDATE indicates whether the operation was part of an UPDATE statement.\n

METADATA$ROW_ID is a unique and immutable ID for the row.",https://docs.snowflake.com/en/user-guide/streams-intro#stream-columns,,Data Loading and Unloading
431,A user is loading JSON documents composed of a huge array containing multiple records into Snowflake. The user enables the STRIP_OUTER_ARRAY file format option. What does the STRIP_OUTER_ARRAY file format do?,D,It removes the trailing spaces in the last element of the outer array and loads the records into separate table columns.,It removes the NULL elements from the JSON object eliminating invalid data and enables the ability to load the records.,It removes the last element of the outer array.,It removes the outer array structure and loads the records into separate table rows.,,,"STRIP_OUTER_ARRAY, Removes the outer set of square brackets [ ] when loading the data, separating the initial array into multiple lines",https://docs.snowflake.com/en/user-guide/semistructured-considerations#data-size-limitations,,Data Loading and Unloading
432,In which different ways can we query historical data? (Choose three.),"C,D,E",By backup.,By user.,By query statement ID.,By offset.,By timestamp.,By session.,"Querying over historical data is one of the main functionalities of Snowflake Time Travel, apart from restoring deleted objects. With Snowflake, you don't need to duplicate or back up data from key points in the past. Here you have an example of querying the historical data by query statement ID:\n

SELECT *\n
FROM my_table\n
BEFORE(STATEMENT => '<query_ID>');",https://docs.snowflake.com/en/user-guide/data-time-travel#time-travel-sql-extensions,,"Data Transformations, Snowflake AI Data Cloud Features and Architecture, Data Protection and Data Sharing"
433,What is a characteristic of data micro-partitioning in Snowflake?,D,Micro-partitioning requires the definition of a partitioning schema,Micro-partitioning may introduce data skew,Micro-partitioning can be disabled within a Snowflake account,Micro-partitioning happens when the data is loaded,,,Micro-partitioning is automatically performed on all Snowflake tables. Tables are transparently partitioned using the ordering of the data as it is inserted/loaded.,https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#what-are-micro-partitions,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
434,"What is common between Fivetran, Informatica, Stitch, and Talend?",D,They are Snowflake Security partners.,They are Snowflake programming interfaces partners.,They are Snowflake Business Intelligence partners.,They are Snowflake Data Integration partners.,,,"There are two types of partners, technology partners, and solution partners. The technology partners are the ones that integrate their solutions with Snowflake, and they can be divided into Data Integration, ML & Data Science, Security & Governance, Business Intelligence, SQL Editors, and Programming Interfaces. In this case, they all belong to the Data Integration Partners. You can see the Snowflake ecosystem in the following image:",https://docs.snowflake.com/en/user-guide/ecosystem-etl,,"Snowflake AI Data Cloud Features and Architecture, Data Transformations"
435,Which of the following accurately represents how a table fits into Snowflake's logical container hierarchy?,D,Database -> Schema -> Table -> Account,Database -> Table -> Schema -> Account,Account -> Schema -> Database -> Table,Account -> Database -> Schema -> Table,,,,https://docs.snowflake.com/en/sql-reference/ddl-database,,Data Transformations
436,A running virtual warehouse is suspended. What is the MINIMUM amount of time that the warehouse will incur charges for when it is restarted?,D,1 second,60 minutes,5 minutes,60 seconds,,,The minimum billing charge for provisioning compute resources is 1 minute (i.e. 60 seconds).,https://docs.snowflake.com/en/user-guide/warehouses-considerations#how-are-credits-charged-for-warehouses,,Performance Concepts
437,Which types of subqueries does Snowflake support? (Choose two.),"C,D","EXISTS, ANY / ALL, and IN subqueries in WHERE clauses: these subqueries can be uncorrelated only","EXISTS, ANY / ALL, and IN subqueries in WHERE clauses: these subqueries can be correlated only","EXISTS, ANY / ALL, and IN subqueries in WHERE clauses: these subqueries can be correlated or uncorrelated",Uncorrelated scalar subqueries in any place that a value expression can be used,Uncorrelated scalar subqueries in WHERE clauses,,"Snowflake currently supports the following types of subqueries:\n
Uncorrelated scalar subqueries in any place that a value expression can be used.\n
Correlated scalar subqueries in WHERE clauses.\n
EXISTS, ANY / ALL, and IN subqueries in WHERE clauses. These subqueries can be correlated or uncorrelated.",https://docs.snowflake.com/en/user-guide/querying-subqueries,,Performance Concepts
438,How can a Snowflake user traverse semi-structured data?,D,Insert a double colon (::) between the VARIANT column name and any second-level element.,Insert a double colon (::) between the VARIANT column name and any first-level element.,Insert a colon (:) between the VARIANT column name and any second-level element.,Insert a colon (:) between the VARIANT column name and any first-level element.,,,It is important to be familiar with the syntax for querying semi-structured data.,https://community.snowflake.com/s/article/querying-semi-structured-data,,Data Transformations
439,Users with the ACCOUNTADMIN role can execute which of the following commands on existing users?,C,"Can SHOW users, INDEX a given user, or ALTER or DELETE a user","Can DEFINE users, DESCRIBE a given user, or ALTER or DELETE a user","Can SHOW users DESCRIBE a given user, or ALTER or DROP a user","Can SHOW users, DEFINE a given user or ALTER, DROP, or MODIFY a user",,,"Only these operations are allowed CREATE USER , ALTER USER , DROP USER , DESCRIBE USER",https://docs.snowflake.com/en/sql-reference/sql/show-users,,Data Transformations
440,The property MINS_TO_BYPASS_NETWORK_POLICY is set at which level?,C,Organization,Role,User,Account,,,"The user object property MINS_TO_BYPASS_NETWORK_POLICY defines the number of minutes in which a user can access Snowflake without conforming to an existing network policy.\n
MINS_TO_BYPASS_NETWORK_POLICY allows the user to temporarily bypass a network policy for a set number of minutes.",https://docs.snowflake.com/en/sql-reference/sql/desc-user,,Data Transformations
441,What is generally the FASTEST way to bulk load data files from a stage?,B,Using the Snowpipe REST API,Specifying a list of specific files to load,Using pattern matching to identify specific files by pattern,Loading by path (internal stages) / prefix,,,"Of the three bulk load options for identifying/specifying data files to load from a stage, providing a discrete list of files is generally the fastest; however, the FILES parameter supports a maximum of 1,000 files, meaning a COPY command executed with the FILES parameter can only load up to 1,000 files.",https://docs.snowflake.com/en/user-guide/data-load-considerations-load,,Data Loading and Unloading
442,What statement is true about Snowflake’s unique architecture?,A,Multi-Cluster Shared Data.,One Node Private Data.,One Node Shared Data.,Multi-Cluster Private Data.,,,"Snowflake's architecture is a hybrid of traditional shared-disk and shared-nothing database architectures. Snowflake uses a central data repository for persisted data accessible from all compute nodes in the platform. At the same time, it processes queries using virtual warehouses where each node in the cluster stores a portion of the entire data set locally.",https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture,,Snowflake AI Data Cloud Features and Architecture
443,What is the default behavior of internal stages in Snowflake?,B,Named internal stages are created by default.,Each user and table are automatically allocated an internal stage.,Users must manually create their own internal stages.,Data files are automatically staged to a default location.,,,,https://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage,,Data Loading and Unloading
444,"According to Snowflake best practice recommendations, which system-defined roles should be used to create custom roles? (Choose two.)","C,E",SYSADMIN,ORGADMIN,USERADMIN,ACCOUNTADMIN,SECURITYADMIN,,Custom account roles can be created using the USERADMIN role (or a higher role),https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles,,Account Access and Security
445,What is used during the FIRST execution of SELECT COUNT(*) FROM ORDER?,A,Metadata-based result,Cache result,Remote disk cache,Virtual warehouse cache,,,"Some queries include steps that are pure metadata/catalog operations rather than data-processing operations. These steps consist of a single operator. Some examples include:\n
-Metadata-based Result\n
-A query whose result is computed based purely on metadata, without accessing any data. These queries are not processed by a virtual warehouse. For example:\n
SELECT COUNT(*) FROM …\n
SELECT CURRENT_DATABASE()",https://docs.snowflake.com/en/user-guide/ui-query-profile#metadata-operators,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
446,What entity is responsible for hosting and sharing data in Snowflake?,A,Data provider,Reader account,Managed account,Data consumer,,,A data provider is any Snowflake account that creates shares and makes them available to other Snowflake accounts to consume.,https://docs.snowflake.com/en/user-guide/data-sharing-intro#about-providers,,Data Protection and Data Sharing
447,Which function is used to convert rows in a relational table to a single VARIANT column?,C,ARRAY_AGG,ARRAY_CONSTRUCT,OBJECT_CONSTRUCT,OBJECT_AGG,,,You can use the OBJECT_CONSTRUCT function combined with the COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file.,https://docs.snowflake.com/en/user-guide/data-unload-considerations,,Data Loading and Unloading
448,Why would a Snowflake user decide to use a materialized view instead of a regular view?,B,The query results are not used frequently.,The base tables do not change frequently.,The query is not resource intensive.,The results of the view change often.,,,,https://docs.snowflake.com/en/user-guide/views-materialized,,Performance Concepts
449,"As a best practice, clustering keys should only be defined on tables of which minimum size?",B,Multi-Gigabyte (GB) Range,Multi-Terabyte (TB) Range,Multi-Kilobyte (KB) Range,Multi-Megabyte (MB) Range,,,,https://docs.snowflake.com/en/user-guide/tables-clustering-keys,,Performance Concepts
450,"Which VALIDATION_MODE value will return the errors across the files specified in a COPY command, including files that were partially loaded during an earlier load?",C,RETURN_ERRORS,RETURN_-1_ROWS,RETURN_ALL_ERRORS,RETURN_n_ROWS,,,"RETURN_ALL_ERRORS: Returns all errors across all files specified in the COPY statement, including files with errors that were partially loaded during an earlier load because the ON_ERROR copy option was set to CONTINUE during the load.",https://docs.snowflake.com/en/sql-reference/sql/copy-into-table,,Data Transformations
451,Which governance feature is supported by all Snowflake editions?,B,Masking policies,OBJECT_DEPENDENCIES view,Row access policies,Object tags,,,"Object tags, Masking Policies and Row Access Policies are for Enterprise and above editions. The only option remaining is Object Dependencies",https://docs.snowflake.com/en/user-guide/intro-editions,,Snowflake AI Data Cloud Features and Architecture
452,"In Snowflake, the use of federated authentication enables which Single Sign-On (SSO) workflow activities? (Choose two.)","A,E",Logging into Snowflake,Initiating user sessions,Authorizing users,Performing role authentication,Logging out of Snowflake,,"Federated authentication enables the following SSO workflows:\n
-Logging into Snowflake.\n
-Logging out of Snowflake.\n
-System timeout due to inactivity.",https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-overview,,Account Access and Security
453,Which privileges are required for a user to restore an object? (Choose two.),B,UNDROP,CREATE,UPDATE,MODIFY,OWNERSHIP,,,https://docs.snowflake.com/en/user-guide/security-access-control-privileges,,Account Access and Security
454,Which privilege is required to use the search optimization service in Snowflake?,C,GRANT SEARCH OPTIMIZATION ON DATABASE TO ROLE,GRANT SEARCH OPTIMIZATION ON SCHEMA TO ROLE,GRANT ADD SEARCH OPTIMIZATION ON SCHEMA TO ROLE,GRANT ADD SEARCH OPTIMIZATION ON DATABASE TO ROLE,,,"To add, configure, or remove search optimization for a table, you must have the following privileges:\n
-You must have OWNERSHIP privilege on the table.\n
-You must have ADD SEARCH OPTIMIZATION privilege on the schema that contains the table.\n

GRANT ADD SEARCH OPTIMIZATION ON SCHEMA <schema_name> TO ROLE <role>",https://docs.snowflake.com/en/user-guide/search-optimization-service#what-access-control-privileges-are-needed-for-the-search-optimization-service,,"Performance Concepts, Snowflake AI Data Cloud Features and Architecture"
455,What is one of the characteristics of data shares?,C,Data shares work by copying data to consumer accounts.,Data shares support full DML operations.,Data shares utilize secure views for sharing view objects.,Data shares are cloud agnostic and can cross regions by default.,,,"For data security and privacy reasons, only secure views are supported in shares at this time. If a standard view is added to a share, Snowflake returns an error.\n
Shared databases are read-only.\n
With Secure Data Sharing, no actual data is copied or transferred between accounts. All sharing uses Snowflake’s services layer and metadata store.\n
Database replication will be needed to allow data providers to securely share data with data consumers across different regions and cloud platforms.",https://docs.snowflake.com/en/user-guide/data-sharing-provider#general-data-sharing-considerations-and-usage,,Data Protection and Data Sharing
456,For which use cases is running a virtual warehouse required? (Choose two.) A. __B. | C. D. E,"A,B",When loading data into a table,When unloading data from a table,When executing a LIST command,When executing a SHOW command,When creating a table,,"Executing SQL SELECT statements that require compute resources (e.g. retrieving rows from tables and views).\n

Performing DML operations, such as:\n
-Updating rows in tables (DELETE , INSERT , UPDATE).\n
-Loading data into tables (COPY INTO ).\n
-Unloading data from tables (COPY INTO)",https://docs.snowflake.com/en/user-guide/warehouses,,Performance Concepts
457,"Queries in Snowflake are getting queued on the warehouses and delaying the ETL processes of the company. What are the possible solution options you can think of, considering we have the Snowflake Enterprise edition? (Choose two.)","C,E",Contact Snowflake support to increase the size of the warehouse.,Upgrade Snowflake edition,Resize the warehouse.,Set auto-resize parameter to TRUE.,Use a multi-cluster warehouse.,,"By resizing the warehouse, your company will scale up, reducing the time to execute big queries. Using multi-cluster warehouses, you will have more queries running simultaneously and a high concurrency when they execute, and this is the definition of scaling out. You can see the differences between the different ways to scale in the following picture:",https://docs.snowflake.com/en/user-guide/warehouses-considerations#scaling-up-vs-scaling-out,,Performance Concepts
458,What is used to diagnose and troubleshoot network connections to Snowflake?,A,SnowCD,Snowpark,SnowSQL,Snowsight,,,SnowCD (i.e. Snowflake Connectivity Diagnostic Tool) helps users to diagnose and troubleshoot their network connection to Snowflake.,https://docs.snowflake.com/en/user-guide/snowcd,,"Snowflake AI Data Cloud Features and Architecture, Account Access and Security"
459,What is a characteristic of materialized views in Snowflake?,C,Aggregate functions can be used as window functions in materialized views.,Multiple tables can be joined in the underlying query of a materialized view.,Materialized views do not allow joins.,Clones of materialized views can be created directly by the user.,,,"The following limitations apply to creating materialized views:\n
-A materialized view can query only a single table.\n
-Joins, including self-joins, are not supported.\n
A materialized view cannot query:\n
-A materialized view.\n
-A non-materialized view.\n
-A UDTF (user-defined table function).",https://docs.snowflake.com/en/user-guide/views-materialized#label-limitations-on-creating-materialized-views,,Performance Concepts
460,Which Snowflake URL type allows users or applications to download or access files directly from Snowflake stage without authentication?,C,Directory,File,Pre-signed,Scoped,,,"Pre-signed URLs are used to download or access files, via a web browser for example, without authenticating into Snowflake or passing an authorization token.",https://www.snowflake.com/blog/snowflake-launches-unstructured-data-support-in-public-preview/?lang=es,,Data Loading and Unloading
461,What can you easily check to see if a large table will benefit from explicitly defining a clustering key?,B,Clustering status.,Clustering depth.,Values in a table.,Clustering ratio.,,,"The clustering depth measures the average depth of the overlapping micro-partitions for specified columns in a table (1 or greater). The smaller the cluster depth is, the better clustered the table is. You can get the clustering depth of a Snowflake table using this command:\n
SELECT SYSTEM$CLUSTERING_DEPTH('MY_TABLE', '(col1, col2)');",https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#clustering-depth,,Performance Concepts
462,How does a Snowflake user extract the URL of a directory table on an external stage for further transformation?,B,Use the DESCRIBE STAGE command.,Use the GET_STAGE_LOCATION function.,Use the SHOW STAGES command.,Use the GET_ABSOLUTE_PATH function.,,,"The GET_STAGE_LOCATION function returns the location of a stage, including the URL of the directory table. The syntax for the GET_STAGE_LOCATION function.\n

SELECT GET_STAGE_LOCATION(@my_stage)",https://docs.snowflake.com/en/sql-reference/functions/get_stage_location,,Data Transformations
463,How are network policies defined in Snowflake?,A,They are a set of rules that control access to Snowflake accounts by specifying the IP addresses or ranges of IP addresses that are allowed to connect to Snowflake.,They are a set of rules that define how data can be transferred between different Snowflake accounts within an organization.,They are a set of rules that dictate how Snowflake accounts can be used between multiple users.,They are a set of rules that define the network routes within Snowflake.,,,,https://docs.snowflake.com/en/user-guide/network-policies,,Account Access and Security
464,How does the ACCESS_HISTORY view enhance overall data governance pertaining to read and write operations? (Choose two.),"B,E",Determines whether a given row in a table can be accessed by the user by filtering the data based on a given policy,Provides a unified picture of what data was accessed and when it was accessed,Protects sensitive data from unauthorized access while allowing authorized users to access it at query runtime,Identifies columns with personal information and tags them so masking policies can be applied to protect sensitive data,Shows how the accessed data was moved from the source to the target objects,,,https://docs.snowflake.com/en/user-guide/access-history,,Account Access and Security
465,Which query type is supported for implementing the search optimization service?,B,Substring search queries on external tables,Geography value column searches using geospatial functions,String searches on columns using the COLLATE function,Queries with column concatenation,,,,https://docs.snowflake.com/en/user-guide/search-optimization-service,,"Performance Concepts, Snowflake AI Data Cloud Features and Architecture"
466,What is the SNOWFLAKE.ACCOUNT_USAGE view that contains information about which objects were read by queries within the last 365 days (1 year)?,A,ACCESS_HISTORY,OBJECT_HISTORY,VIEWS_HISTORY,LOGIN_HISTORY,,,"Querying the ACCESS_HISTORY View This Account Usage view can be used to query the access history of Snowflake objects (e.g. table, view, column) within the last 365 days (1 year).",https://docs.snowflake.com/en/sql-reference/account-usage/access_history,,Data Transformations
467,What transformations are supported in a CREATE PIPE .. AS COPY `¦ FROM (`¦) statement? (Choose two.),"C,E",Incoming data can be joined with other tables.,Data can be filtered by an optional WHERE clause.,Columns can be reordered.,Row level access can be defined.,Columns can be omitted.,,,https://docs.snowflake.com/en/sql-reference/sql/create-pipe,,Data Transformations
468,Which function will provide the proxy information needed to protect Snowsight?,B,SYSTEM$GET_TAG,SYSTEM$ALLOWLIST,SYSTEM$GET_PRIVATELINK,SYSTEM$AUTHORIZE_PRIVATELINK,,,"To determine the fully qualified URL and port for Snowsight, review the SNOWSIGHT_DEPLOYMENT entry in the return value of the SYSTEM$ALLOWLIST function.",https://docs.snowflake.com/en/user-guide/ui-snowsight-gs,,Snowflake AI Data Cloud Features and Architecture
469,Authorization to execute CREATE [object] statements comes only from which role?,C,Secondary role,Database role,Primary role,Application role,,,Note that authorization to execute CREATE <object> statements to create objects is provided by the primary role.,https://docs.snowflake.com/en/sql-reference/sql/use-secondary-roles,,Data Transformations
470,Which certifications are compliant with Snowflake? (Choose three.),"A,B,E",HIPAA.,FedRAMP.,ISO 9000.,SC-900.,PCI-DSS.,,"They won't ask you in-depth questions about this topic in the exam, but it's important to remember some of the most important ones.",https://www.snowflake.com/snowflakes-security-compliance-reports,,Account Access and Security
471,Which character or character combination identifies a table stage?,A,“@%”,“%”,“/@”,“@”,,,"Note that the @% character combination identifies a table stage.\n
Linux or macOS\n
-PUT file:///data/data.csv @%mytable;\n
Windows\n
-PUT file://C:\data\data.csv @%mytable;",https://docs.snowflake.com/en/user-guide/data-load-local-file-system-stage,,Data Loading and Unloading
472,"By default, how long is the standard retention period for Time Travel across all Snowflake accounts?",C,90 days,7 days,1 day,0 days,,,"By default, Time travel is enabled with a 1-day retention period. However, we can increase it to 90 days if we have (at least) the Snowflake Enterprise Edition. It requires additional storage, which will be reflected in your monthly storage charges. You can see how the Time Travel functionality works in the following image:",https://docs.snowflake.com/en/user-guide/data-time-travel,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
473,Which of the following are characteristics of schemas used in Snowflake? (Choose two.),"A,C",A schema represents a logical grouping of database objects.,A schema may contain one or more databases.,A database may contain one or more schemas.,Each schema is contained within a virtual warehouse.,A table can span more than one schema.,,"Databases and schemas are used to organize data stored in Snowflake:\n
-A database is a logical grouping of schemas. Each database belongs to a single Snowflake account.\n
-A schema is a logical grouping of database objects (tables, views, etc.). Each schema belongs to a single database.",https://docs.snowflake.com/en/sql-reference/ddl-database,,Data Transformations
474,How can a data provider share their Snowflake data? (Choose two.),"A,E",Direct share,Snowpark API,External function,External table,Snowflake Marketplace listing,,,https://docs.snowflake.com/en/user-guide/data-sharing-intro#about-providers,,Data Protection and Data Sharing
475,Which statements are NOT correct about micro-partitions in Snowflake? (Choose two.),"B,C",Contiguous units of storage.,Non-contiguous units of storage.,50 and 500MB of compressed data.,50 and 500MB of uncompressed data.,Organized in a columnar way.,,"This definition is a must, and we need to know it perfectly “All data in Snowflake tables are automatically divided into micro-partitions, which are contiguous units of storage between 50 and 500MB of uncompressed data, organized in a columnar way”.",https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
476,How can a user get the MOST detailed information about individual table storage details in Snowflake?,A,TABLE_STORAGE_METRICS view,SHOW TABLES command,TABLES view,SHOW EXTERNAL TABLES command,,,,https://docs.snowflake.com/en/sql-reference/account-usage/table_storage_metrics,,Data Transformations
477,"What are the correct settings for column and element names, regardless of which notation is used while accessing elements in a JSON object?",A,The column name is case-insensitive and the element name is case-sensitive.,Both the column name and the element name are case-insensitive.,Both the column name and the element name are case-sensitive.,The column name is case-sensitive and the element names are case-insensitive.,,,"The column name is case-insensitive and the element name is case-sensitive.\n

Regardless of which notation you use, the column name is case-insensitive but element names are case-sensitive. For example, in the following list, the first two paths are equivalent, but the third is not:\n
src:salesperson.name\n
SRC:salesperson.name\n
SRC:Salesperson.Name",https://docs.snowflake.com/en/user-guide/querying-semistructured%20Important,,Performance Concepts
478,What information is stored in the ACCESS_HISTORY view?,C,Names and owners of the roles that are currently enabled in the session,History of the files that have been loaded into Snowflake,Query details such as the objects included and the user who executed the query,Details around the privileges that have been granted for all objects in an account,,,,https://docs.snowflake.com/en/sql-reference/account-usage/access_history#columns,,Data Transformations
479,Which cache can also be referred to as SSD or local cache?,B,Results cache.,Warehouse cache.,Standard cache.,Metadata cache.,,,"Every warehouse has an attached Warehouse cache, also known as the SSD or Local cache. While the data warehouse runs, the table fetched in the query will remain in this cache. When the warehouse is suspended, the information will be lost.",https://community.snowflake.com/s/article/Caching-in-the-Snowflake-Cloud-Data-Platform,,"Performance Concepts, Snowflake AI Data Cloud Features and Architecture"
480,How many warehouses do you need to run to have Snowpipe constantly running?,A,You don't need any warehouse as Snowpipe is a serverless feature.,1,10,100,,,"Snowpipe enables loading data when the files are available in any (internal/external) stage. You use it when you have a small volume of frequent data, and you load it continuously (micro-batches). Snowpipe is serverless, which means that it doesn’t use Virtual Warehouses. You can see how Snowpipe works in the following diagram:",https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro,,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture"
481,What privileges are required to create a task?,A,The role must have access to the target schema and the CREATE TASK privilege on the schema itself.,"Many Snowflake DDLs are metadata operations only, and CREATE TASK DDL can be executed without virtual warehouse requirement or task specific grants.",The GLOBAL privilege CREATE TASK is required to create a new task.,Tasks are created at the Application level and can only be created by the Account Admin role.,,,,https://docs.snowflake.com/en/sql-reference/sql/create-task#access-control-requirements,,Data Transformations
482,From what stage can a Snowflake user omit the FROM clause while loading data into a table?,C,The internal named stage,The user stage,The table stage,The external named stage,,,"Note that when copying data from files in a table stage, the FROM clause can be omitted because Snowflake automatically checks for files in the table stage.",https://docs.snowflake.com/en/user-guide/data-load-local-file-system-copy,,Data Loading and Unloading
483,Which of the following file formats is not supported by Snowflake?,B,XML,XLSX,Avro,ORC,,,"A File Format object describes and stores the format information required to load data into Snowflake tables. CSV, JSON, Parquet, XML, Avro & ORC are the supported Snowflake file formats. To import XLSX, you'll have to convert it to CSV first.",https://docs.snowflake.com/en/user-guide/data-load-prepare#supported-file-formats,,Data Loading and Unloading
484,A tabular User-Defined Function (UDF) is defined by specifying a return clause that contains which keyword?,A,TABLE,TABULAR,VALUES,ROW_NUMBER,,,"RETURNS TABLE(..): Specifies that the UDF should return a table. Inside the parentheses, specify name-and-type pairs for columns (as described below) to include in the returned table.",https://docs.snowflake.com/en/developer-guide/udf/sql/udf-sql-tabular-functions,,Data Transformations
485,After how many days does the COPY INTO load metadata expire?,C,14 days.,180 days.,64 days.,1 day.,,,"The information about the loaded files is stored in Snowflake metadata. It means that you cannot COPY the same file again in the next 64 days unless you specify it (with the ""FORCE=True"" option in the COPY command). You can see this behavior in the following image:",https://docs.snowflake.com/en/user-guide/data-load-considerations-load#load-metadata,,Data Loading and Unloading
486,The MAXIMUM size for a serverless task run is equivalent to what size virtual warehouse?,C,Large,Medium,2X-Large,4X-Large,,,The maximum size for a serverless task run is equivalent to an XXLARGE warehouse.,https://docs.snowflake.com/en/user-guide/tasks-intro,,Performance Concepts
487,How does Snowflake reorganize data when it is loaded? (Choose two.),"B,E",Zipped format,Compressed format,Raw format,Binary format,Columnar format,,"When data is loaded into Snowflake, Snowflake reorganizes that data into its internal optimized, compressed, columnar format.",https://docs.snowflake.com/en/user-guide/intro-key-concepts,,Snowflake AI Data Cloud Features and Architecture
488,Which formats are supported for unloading data from Snowflake? (Choose two.),"B,E",ORC,"Delimited (CSV, TSV, etc.)",XML,Avro,JSON,,,https://docs.snowflake.com/en/user-guide/data-unload-prepare,,Data Loading and Unloading
489,What does Snowflake recommend a user do if they need to connect to Snowflake with a tool or technology that is not listed in Snowflake’s partner ecosystem?,B,Use a custom-built connector.,Connect through Snowflake’s JDBC or ODBC drivers.,Contact Snowflake Support for a new driver.,Use Snowflake’s native API.,,,,https://docs.snowflake.com/en/user-guide/ecosystem-all,,Snowflake AI Data Cloud Features and Architecture
490,"By default, the COPY INTO statement will separate table data into a set of output files to take advantage of which Snowflake feature?",A,Parallel processing,Query plan caching,Time Travel,Query acceleration,,,"By default, the COPY INTO statement will separate table data into a set of output files to take advantage of Snowflake's parallel processing feature. This means that when data is unloaded, it can be split into multiple files and each file can be processed simultaneously by different nodes in the cluster, improving performance. The number of output files can be controlled by specifying the number of file parts in the COPY INTO statement.\n

Default for COPY INTO is SINGLE = FALSE which breaks data into multiple files; SINGLE = TRUE downloads data into a single file",https://docs.snowflake.com/en/sql-reference/sql/copy-into-location#unloading-data-to-a-single-file,,Data Transformations
491,Which of the following statements is true of Snowflake?,A,It was built specifically for the cloud,It was designed as a hybrid database to allow customers to store data either on premises or in the cloud,It was built for Hadoop Architecture,It was built as an on-premises solution and then ported to the cloud,,,,https://docs.snowflake.com/en/user-guide/intro-cloud-platforms,,Snowflake AI Data Cloud Features and Architecture
492,What is the MINIMUM configurable idle timeout value for a session policy in Snowflake?,A,5 minutes,15 minutes,2 minutes,10 minutes,,,"The timeout period begins upon a successful authentication to Snowflake. If a session policy is not set, Snowflake uses a default value of 240 minutes (i.e. 4 hours). The minimum configurable idle timeout value for a session policy is 5 minutes. When the session expires, the user must authenticate to Snowflake again.",https://docs.snowflake.com/en/user-guide/session-policies#session-policies,,Account Access and Security
493,"Which Snowflake object returns a set of rows instead of a single, scalar value, and can be accessed in the FROM clause of a query?",B,There is no object in Snowflake with the ability to return a set of rows,UDTF,Stored procedure,UDF,,,"User-defined functions (UDFs) let you extend the system to perform operations that are not available through Snowflake’s built-in, system-defined functions.\n

UDTFs can return multiple rows for each input row; that’s the only difference with UDFs.",https://docs.snowflake.com/en/developer-guide/udf/python/udf-python-tabular-functions,,Data Transformations
494,What is the most granular object that the Time Travel retention period can be defined on?,B,Account,Table,Schema,Database,,,"The time travel data retention can be overwritten at the table level ""When creating a table, schema, or database, the account default can be overridden using the DATA_RETENTION_TIME_IN_DAYS parameter in the command.""",https://docs.snowflake.com/en/user-guide/data-time-travel,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
495,The use of which Snowflake table type will reduce costs when working with ETL workflows?,A,Temporary,Transient,Permanent,External,,,"Snowflake supports creating temporary tables for storing non-permanent, transitory data (e.g. ETL data, session-specific data). Temporary tables only exist within the session in which they were created and persist only for the remainder of the session.",https://docs.snowflake.com/en/user-guide/tables-temp-transient,,Performance Concepts
496,Which of the following statements would be used to export/unload data from Snowflake?,C,EXPORT TO @stage,"EXPORT_TO_STAGE(stage => @stage, select => 'select * from t1');",COPY INTO @stage,INSERT INTO @stage,,,,https://docs.snowflake.com/en/user-guide/data-unload-considerations,,Data Loading and Unloading
497,"What is the main function of Business Intelligence tools (e.g., Tableau or Quicksight)?",B,Carry out Machine Learning analysis.,Create charts from Snowflake data to give more business insights.,Transform data from other source systems and move them into Snowflake stages.,Extract data from other source systems and move them into Snowflake stages.,,,"Business Intelligence (BI) tools are software applications that enable organizations to collect, analyze, and present data in a user-friendly way to make better business decisions. BI tools can help organizations identify trends, patterns, and insights in their data, which can optimize business processes, improve performance, and gain a competitive advantage. You can create charts like this one using Tableau from Snowflake data. You should create views to be able to use VARIANT columns in these types of tools, apart from paying them separately. You can see an example of a Tableau chart in the following image:",https://docs.snowflake.com/en/user-guide/ecosystem-bi,,Snowflake AI Data Cloud Features and Architecture
498,What is the minimum Snowflake edition that provides data sharing?,A,Standard,Enterprise,Business Critical Edition,Premier,,,,https://docs.snowflake.com/en/user-guide/intro-editions#data-sharing,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
499,At what level can the ALLOW_CLIENT_MFA_CACHING parameter be set?,B,Session,Account,Role,User,,,Account — Can only be set for Account,https://docs.snowflake.com/en/sql-reference/parameters#label-allow-client-mfa-caching,,"Data Transformations, Account Access and Security"
500,Which SQL command will download all the data files from an internal table stage named TBL_EMPLOYEE to a local window directory or folder on a client machine in a folder named folder with space within the C drive?,C,PUT 'file://C:\folder with space\*' @%TBL_EMPLOYEE;,PUT 'file://C:/folder with space/*' @%TBL_EMPLOYEE;,GET @%TBL_EMPLOYEE 'file://C:/folder with space/';,GET @%TBL_EMPLOYEE 'file://C:\folder with space\';,,,"If the directory path includes special characters, the entire file URI must be enclosed in single quotes. Note that the drive and path separator is a forward slash (/) in enclosed URIs (e.g. 'file://C:/temp/load data' for a path in Windows that includes a directory named load data).",https://docs.snowflake.com/en/sql-reference/sql/get,,Data Transformations
501,A Snowflake user is trying to load a 125 GB file using SnowSQL. The file continues to load for almost an entire day. What will happen at the 24-hour mark?,C,The file will stop loading and all data up to that point will be committed.,The file’s number of allowable hours to load can be programmatically controlled to load easily into Snowflake.,The file loading could be aborted without any portion of the file being committed.,The file will continue to load until all contents are loaded.,,,"Loading very large files (e.g. 100 GB or larger) is not recommended.\n

If you must load a large file, carefully consider the ON_ERROR copy option value. Aborting or skipping a file due to a small number of errors could result in delays and wasted credits. In addition, if a data loading operation continues beyond the maximum allowed duration of 24 hours, it could be aborted without any portion of the file being committed.",https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare,,Data Loading and Unloading
502,"If a virtual warehouse is suspended, what happens to the warehouse cache?",B,The cache is maintained for up to two hours and can be restored if the warehouse is restarted within this limit.,The cache is dropped when the warehouse is suspended and is no longer available upon restart.,The cache is maintained for the auto_suspend duration and can be restored if the warehouse is restarted within this limit.,"The warehouse cache persists for as long as the warehouse exists, regardless of its suspension status.",,,"This cache is dropped when the warehouse is suspended, which may result in slower initial performance for some queries after the warehouse is resumed.",https://docs.snowflake.com/en/user-guide/warehouses-considerations,,Performance Concepts
503,Which of the following view types are available in Snowflake? (Choose two.),"A,E",Secure view,External view,Embedded view,Layered view,Materialized view,,,https://docs.snowflake.com/en/user-guide/views-introduction,,Performance Concepts
504,Which command line flags can be used to log into a Snowflake account using SnowSQL? (Choose two.),"C,E",-c,-o,-d,-e,-a,,"a, ~-accountname TEXT\n
Your account identifier. Honors $SNOWSQL_ACCOUNT.\n
-d, dbname TEXT\n
Database to use. Honors $SNOWSQL_DATABASE.",https://docs.snowflake.com/en/user-guide/snowsql-start,,Snowflake AI Data Cloud Features and Architecture
505,Which properties of a Resource Monitor can be modified?,C,"Credit Quota, Schedule, Actions.","Credit Quota, Monitor Level, Schedule.","Credit Quota, Monitor Level, Schedule, Actions.","Monitor Level, Schedule, Actions.","Schedule, Actions.",,"The Credit Quota specifies the number of Snowflake credits allocated to the monitor for the specified frequency interval.\n

The Monitor Level specifies whether the resource monitor is used to monitor the credit usage for your entire account or individual warehouses.\n

The Schedule indicates when the monitor will start monitoring and when the credits will reset to 0.\n

Each action specifies a threshold and the action to perform when the threshold is reached within the specified interval.",https://docs.snowflake.com/en/user-guide/resource-monitors#resource-monitor-properties,,Performance Concepts
506,"When a database is cloned, which objects in the clone inherit all granted privileges from the source object? (Choose two.)","A,C",Schemas,Account,Tables,Database,Internal named stages,,"Only child objects inherit the privileges. If the source object is a database or schema, the clone inherits all granted privileges on the clones of all child objects contained in the source object:\n
-For databases, contained objects include schemas, tables, views, etc.\n
-For schemas, contained objects include tables, views, etc.",https://docs.snowflake.com/en/user-guide/object-clone,,Performance Concepts
507,A user has unloaded data from Snowflake to a stage. Which SQL command should be used to validate which data was loaded into the stage?,A,list @file_stage,view @file_stage,verify @file_stage,show @file_stage,,,,https://docs.snowflake.com/en/sql-reference/sql/list,,Data Transformations
508,A Snowflake user needs to share unstructured data from an internal stage to a reporting tool that does not have Snowflake access. Which file function should be used?,A,GET_PRESIGNED_URL,BUILD_STAGE_FILE_URL,GET_STAGE_LOCATION,BUILD_SCOPED_FILE_URL,,,"Pre-signed URL function is used to download or access files without authenticating into Snowflake or passing an authorization token. Pre-signed URLs are open; any user or application can directly access or download the files. Ideal for business intelligence applications or reporting tools that need to display the unstructured file contents.\n

Query the GET_PRESIGNED_URL function.",https://docs.snowflake.com/en/user-guide/unstructured-intro#types-of-urls-available-to-access-files,,Data Loading and Unloading
509,"By definition, a secure view is exposed only to users with what privilege?",B,USAGE,OWNERSHIP,IMPORT SHARE,REFERENCES,,,OWNERSHIP: The definition of a secure view is only exposed to authorized users (i.e. users who have been granted the role that owns the view).,https://docs.snowflake.com/en/user-guide/views-secure,,"Data Protection and Data Sharing, Performance Concepts"
510,Which data types in Snowflake are synonymous for FLOAT? (Choose two.),"B,E",NUMERIC,REAL,NUMBER,DECIMAL,DOUBLE,,"DOUBLE, DOUBLE PRECISION, REAL are synonymous with float",https://docs.snowflake.com/en/sql-reference/intro-summary-data-types,,Data Transformations
511,In which editions can we configure MFA Authentication?,C,Enterprise.,Standard.,All of them.,Business Critical.,,,"MFA login is designed primarily for connecting to Snowflake through the web interface, but it is also fully supported by SnowSQL and the Snowflake JDBC and ODBC drivers. MFA is available in all the Snowflake editions as another security layer, and you can set it in the settings tab.",https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#monitoring-clustering-information-for-tables,,Performance Concepts
512,Which REST API can be used with unstructured data?,C,loadHistoryScan,insertFiles,GET /api/files/,insertReport,,,,https://docs.snowflake.com/en/user-guide/data-load-unstructured-rest-api,,"Data Transformations, Data Loading and Unloading"
513,Which object can be used with Secure Data Sharing?,B,User-Defined Function (UDF),External table,View,Materialized view,,,"You can share the following Snowflake objects:\n
-Databases\n
-Tables\n
-Dynamic tables\n
-External tables\n
-Iceberg tables\n
-Secure views\n
-Secure materialized views\n
-Secure user-defined functions (UDFs)",https://docs.snowflake.com/en/user-guide/data-sharing-intro,,Data Protection and Data Sharing
514,What type of account can be used to share data with a consumer who does not have a Snowflake account?,A,Reader,Data provider,Data consumer,Organization,,,"Data sharing is only supported between Snowflake accounts. As a data provider, you might want to share data with a consumer who does not already have a Snowflake account or is not ready to become a licensed Snowflake customer.\n

To facilitate sharing data with these consumers, you can create reader accounts. Reader accounts (formerly known as “read-only accounts”) provide a quick, easy, and cost-effective way to share data without requiring the consumer to become a Snowflake customer.",https://docs.snowflake.com/en/user-guide/data-sharing-intro#reader-accounts-for-third-party-access,,Data Protection and Data Sharing
515,What privilege does a user need in order to receive or request data from the Snowflake Marketplace?,B,IMPORTED PRIVILEGES,IMPORT SHARE,CREATE SHARE,CREATE DATA EXCHANGE LISTING,,,You must use the ACCOUNTADMIN role or another role with the CREATE DATABASE and IMPORT SHARE privileges to access a listing.,https://other-docs.snowflake.com/en/collaboration/consumer-listings-access#accessing-listings-on-the-marketplace,,Data Protection and Data Sharing
516,Which Snowflake objects are automatically created by default every time you create a database? (Choose two.),"B,E",The ANALYTICS_SCHEMA.,The PUBLIC schema.,The METADATA_SCHEMA.,The DEFAULT_SCHEMA.,The INFORMATION_SCHEMA.,,"The INFORMATION_SCHEMA contains views for all the objects in the database, as well as views for account-level objects, and table functions for historical and usage data across your account. The PUBLIC schema is the default schema for the database, and all objects are, by default, created inside it if no other schema is specified.",https://docs.snowflake.com/en/sql-reference/sql/create-database#general-usage-notes,,Data Transformations
517,Which validation option is the only one that supports the COPY INTO (location) command?,B,RETURN_ALL_ERRORS,RETURN_ROWS,RETURN_ERRORS,RETURN__ROWS,,,"Loading:\n
COPY INTO (table) VALIDATION_MODE = RETURN_N_ROWS, RETURN_ERRORS, RETURN_ALL_ERRORS\n

Unloading:\n
COPY INTO (location) VALIDATION_MODE = RETURN_ROWS","https://docs.snowflake.com/en/sql-reference/sql/copy-into-table, https://docs.snowflake.com/en/sql-reference/sql/copy-into-location",,Data Transformations
518,A user has a standard multi-cluster warehouse auto-scaling policy in place. Which condition will trigger a cluster to shut-down?,A,When after 2-3 consecutive checks the system determines that the load on the least-loaded cluster could be redistributed.,When after 5-6 consecutive checks the system determines that the load on the least-loaded cluster could be redistributed.,When after 5-6 consecutive checks the system determines that the load on the most-loaded cluster could be redistributed.,When after 2-3 consecutive checks the system determines that the load on the most-loaded cluster could be redistributed.,,,"After 2 to 3 consecutive successful checks (performed at 1 minute intervals), which determine whether the load on the least-loaded cluster could be redistributed to the other clusters without spinning up the cluster again.",https://docs.snowflake.com/en/user-guide/warehouses-multicluster,,Performance Concepts
519,Which of the following statements describes a benefit of Snowflake’s separation of compute and storage? (Choose two.),"A,B",Compute can be scaled up or down without the requirement to add more storage.,Storage expands without the requirement to add more compute.,Use of storage avoids disk spilling.,Growth of storage and compute are tightly coupled.,Compute and storage can be scaled together.,,"Both can be managed separately as per business needs. They are not bounded, this is what cloud is for.",https://docs.snowflake.com/en/user-guide/intro-key-concepts,,Snowflake AI Data Cloud Features and Architecture
520,What SQL command would be used to view all roles that were granted to USER1?,A,show grants to user USER1;,show grants user USER1;,show grants on user USER1;,describe user USER1;,,,"SHOW GRANTS TO ..\n

ROLE role_name: Lists all privileges and roles granted to the role.\n

USER user_name: Lists all the roles granted to the user. Note that the PUBLIC role, which is automatically available to every user, is not listed.",https://docs.snowflake.com/en/sql-reference/sql/show-grants#variants,,Data Transformations
521,Which command can we use to restore a deleted table on Snowflake?,C,RESTORE TABLE <mytable>,REPLACE TABLE <mytable>,UNDROP TABLE <mytable>,REBUILD TABLE <mytable>,,,"To restore objects, we use the command “UNDROP”. We can use it with Databases, Schemas, or Tables. If we try to restore an object with a name that already exists, Snowflake will give an error.",https://docs.snowflake.com/en/sql-reference/sql/undrop-table,,Data Transformations
522,What are the primary authentication methods that Snowflake supports for securing REST API interactions? (Choose two.),"C,E",Username and password authentication,Multi-Factor Authentication (MFA),OAuth,Federated authentication,Key pair authentication,,"When you send a request, the request must include authentication information. The next sections explain how to add this information to the request:\n
-Using OAuth\n
-Using key-pair authentication",https://docs.snowflake.com/en/developer-guide/sql-api/authenticating,,"Data Transformations, Account Access and Security"
523,How do Snowflake data providers share data that resides in different databases?,A,Secure views,External tables,User-Defined Functions (UDFs),Materialized views,,,"Snowflake data providers can share data that resides in different databases by using secure views. A secure view can reference objects such as schemas, tables, and other views from one or more databases, as long as these databases belong to the same account.",https://docs.snowflake.com/en/user-guide/data-sharing-mutiple-db,,Data Protection and Data Sharing
524,"What setting in Snowsight determines the databases, tables, and other objects that can be seen and the actions that can be performed on them?",C,Column-level security,Masking policy,Active role,Multi-Factor Authentication (MFA),,,"While using Snowsight, you can change the active role in your current session. Your active role determines the databases, tables, and other objects you can see and the actions you can perform on them.",https://docs.snowflake.com/en/user-guide/ui-snowsight-gs,,Snowflake AI Data Cloud Features and Architecture
525,What are types of partners in the Snowflake ecosystem? (Choose two.),"A,E",Solution Partners.,Standard Partners.,Private Partners.,Personalized Partners.,Technology Partners.,,"Technology Partners integrate their solutions with Snowflake to get data quickly into Snowflake and offer software, driver, interfaces, etc. Solution Partners are trusted and validated experts, like consulting partners. You can see the whole Snowflake ecosystem in the following image:",https://docs.snowflake.com/en/user-guide/ecosystem,,Snowflake AI Data Cloud Features and Architecture
526,"A user has semi-structured data to load into Snowflake but is not sure what types of operations will need to be performed on the data. Based on this situation, what type of column does Snowflake recommend be used?",B,ARRAY,VARIANT,TEXT,OBJECT,,,"Snowflake natively supports semi-structured data, which means semi-structured data can be loaded into relational tables without requiring the definition of a schema in advance. Snowflake supports loading semi-structured data directly into columns of type VARIANT.\n

Typically, tables used to store semi-structured data consist of a single VARIANT column. Once the data is loaded, you can query the data similar to structured data. You can also perform other tasks, such as extracting values and objects from arrays. For more information, see the FLATTEN table function.",https://docs.snowflake.com/en/user-guide/data-load-prepare,,Data Loading and Unloading
527,Which SQL statement will require a virtual warehouse to run?,B,SELECT COUNT(*) FROM TBL_EMPLOYEE;,"INSERT INTO TBL_EMPLOYEE(EMP_ID, EMP_NAME, EMP_SALARY, DEPT) VALUES(1, 'Adam', 20000, 'Finance’);","CREATE OR REPLACE TABLE TBL_EMPLOYEE
(
EMP_ID NUMBER,
EMP_NAME VARCHAR(30),
EMP_SALARY NUMBER,
DEPT VARCHAR(20)
);",ALTER TABLE TBL_EMPLOYEE ADD COLUMN EMP_REGION VARCHAR(20);,,,"A warehouse provides the required resources, such as CPU, memory, and temporary storage, to perform the following operations in a Snowflake session:\n

Executing SQL SELECT statements that require compute resources (e.g. retrieving rows from tables and views).\n

Performing DML operations, such as:\n
-Updating rows in tables (DELETE , INSERT , UPDATE).\n
-Loading data into tables (COPY INTO <table>).\n
-Unloading data from tables (COPY INTO <location>).\n

Queries using Snowflake metadata do not require a Warehouse to be turned on and do not consume credits.",https://docs.snowflake.com/en/user-guide/warehouses,,Performance Concepts
528,What happens to the incoming queries when a warehouse does not have enough resources to process them?,B,Queries are aborted.,Queries are queued and executed when the warehouse has resources.,Snowflake resizes the warehouse.,Snowflake adds more clusters.,,,"If the warehouse does not have enough remaining resources to process a query, the query is queued, pending resources that become available as other running queries complete.",https://docs.snowflake.com/en/user-guide/performance-query-warehouse-queue,,Performance Concepts
529,What step can reduce data spilling in Snowflake?,D,Increasing the amount of remote storage for the virtual warehouse,Using a Common Table Expression (CTE) instead of a temporary table,Increasing the virtual warehouse maximum timeout limit,Using a larger virtual warehouse,,,"Adjusting the available memory of a warehouse can improve performance because a query runs substantially slower when a warehouse runs out of memory, which results in bytes “spilling” onto storage.",https://docs.snowflake.com/en/user-guide/performance-query-warehouse,,Performance Concepts
530,"There are 300 concurrent users on a production Snowflake account using a single cluster virtual warehouse. The queries are small, but the response time is very slow. What is causing this to occur?",C,The queries are not taking advantage of the data cache.,The warehouse parameter STATEMENT_QUEUED_TIMEOUT_IN_SECONDS is set too low.,"The warehouse is queuing the queries, increasing the overall query execution time.",The application is not using the latest native ODBC driver which is causing latency.,,,"High number of concurrent users with a single cluster virtual warehouse. This would be a good use case for using multi cluster warehouse, which are designed to handle concurrency problems.",https://docs.snowflake.com/en/user-guide/warehouses-multicluster,,Performance Concepts
531,Which SQL commands should be used to write a recursive query if the number of levels is unknown? (Choose two.),"C,F",Oracle Cloud,MATCH RECOGNIZE,CONNECT BY,QUALIFY,LISTAGG,WITH,,https://docs.snowflake.com/en/user-guide/queries-hierarchical,,Performance Concepts
532,What does the LATERAL modifier for the FLATTEN function do?,B,Retrieves a single instance of a repeating element in the flattened data,Joins information outside the object with the flattened data,Extracts the path of the flattened data,Casts the values of the flattened data,,,"FLATTEN is a table function that produces a lateral view of a VARIANT, OBJECT, or ARRAY column. The function returns a row for each object, and the LATERAL modifier joins the data with any information outside of the object.",https://docs.snowflake.com/en/user-guide/querying-semistructured,,Performance Concepts
533,Which character identifies a user stage?,B,“~”,“@~”,“@%”,“@”,,,"Each user has a Snowflake personal stage allocated to them by default for storing files, and no one can access them except the user it belongs to. It's represented with the ""@~"" character. In the following example, we are uploading the file ""myfile.csv"" to the stage from the current user:\n
PUT file://C:\data\myfile.csv @~",https://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage#user-stages,,Data Loading and Unloading
534,Which of the following file formats are supported by Snowflake? (Choose three.),"B,C,D",XLSX.,CSV.,XML.,Avro.,TXT.,HTML.,"A File Format object describes and stores the format information required to load data into Snowflake tables. You can specify different parameters, such as the file’s delimiter, if you want to skip the header or not, etc. Snowflake supports both Structured and Semi-Structured Data. You can see the different file formats in the following image:",https://docs.snowflake.com/en/user-guide/intro-summary-loading#data-file-details,,Data Loading and Unloading
535,Which Snowflake feature allows administrators to identify unused data that may be archived or deleted?,A,Access history,Object tagging,Data classification,Dynamic Data Masking,,,"Each row in the ACCESS_HISTORY view contains a single record per SQL statement. The record describes the columns the query accessed directly and indirectly (i.e. the underlying tables that the data for the query comes from). These records facilitate regulatory compliance auditing and provide insights on popular and frequently accessed tables and columns since there is a direct link between the user (i.e. query operator), the query, the table or view, the column, and the data.",https://docs.snowflake.com/en/user-guide/access-history,,Account Access and Security
536,What are the main differences between the Virtual Private Snowflake (VPS) and Business Critical Editions? (Select TWO),"C,D","Snowflake VPS provides customer-managed encryption keys through Tri-Secret secure, whereas it’s not included in the Business Critical Edition.","Snowflake VPS provides a direct proxy to virtual networks // on-premises data centers using AWS PrivateLink, whereas it’s not included in the Business Critical Edition.","Snowflake VPS provides a dedicated metadata store and pool of computing resources, whereas it’s not included in the Business Critical Edition.","Snowflake VPS provides a completely separate Snowflake environment, isolated from all other Snowflake accounts, whereas it’s not included in the Business Critical Edition.",,,Tri-Secret secure and AWS PrivateLink are also provided in the Business Critical Edition. Check out the Snowflake Documentation for comparisons.,https://docs.snowflake.com/en/user-guide/intro-editions,,Snowflake AI Data Cloud Features and Architecture
537,A company needs to allow some users to see Personally Identifiable Information (PII) while limiting other users from seeing the full value of the PII. Which Snowflake feature will support this?,D,Data encryption,Role based access control,Row access policies,Data masking policies,,,"If you have a table with a column including PII, masking rows will not solve the issue. What we need is to make the data in this column visible to some, and masked to some. Thus we need to use dynamic data masking.",https://docs.snowflake.com/en/user-guide/security-column-ddm-intro,,Data Protection and Data Sharing
538,A task went into a loop. How long will the task run before Snowflake finishes it?,C,4 hours.,30 minutes.,60 minutes.,15 minutes.,,,"Tasks have a maximum duration of 60 minutes by default. If they haven't finished by then, they will be automatically terminated. You can configure the time limit on a single task run before it times out with the option ""USER_TASK_TIMEOUT_MS"" when creating the task. However, before significantly increasing the time limit on a task, consider whether to refactor the SQL statement or increase the warehouse size.",https://docs.snowflake.com/en/user-guide/tasks-ts#task-timed-out-or-exceeded-the-schedule-window,,Performance Concepts
539,What data type should be used to store JSON data natively in Snowflake?,D,String,Object,JSON,VARIANT,,,,https://docs.snowflake.com/en/user-guide/script-data-load-transform-json,,"Data Loading and Unloading, Data Transformations"
540,Which of the following roles or privileges are required to view the table function TASK_HISTORY? (Choose three.),"B,C,D",SECURITYADMIN.,MONITOR EXECUTION privilege.,ACCOUNTADMIN.,Task owner (OWNERSHIP privilege),SYSADMIN.,,"The function returns the history of task usage for your entire Snowflake account or a specified task. It returns results for the ACCOUNTADMIN role, the task owner, or a role with the global MONITOR EXECUTION privilege.\n

It returns task activity within the last 7 days or the next scheduled execution within the next 8 days.",https://docs.snowflake.com/en/sql-reference/functions/task_history#usage-notes,,Data Transformations
541,"If a transaction disconnects and goes into a detached state, which cannot be committed or rolled back, how long will Snowflake take to abort the transaction?",A,4 hours.,60 minutes.,15 minutes.,12 hours.,,,"If the transaction is left open or not aborted by the user, Snowflake automatically rolls back the transaction after being idle for four hours.\n

You can still abort a running transaction with the system function: SYSTEM$ABORT_TRANSACTION.",https://docs.snowflake.com/en/sql-reference/transactions#aborting-transactions,,Data Transformations
542,"What would happen if we executed the following command?
    CREATE OR REPLACE TABLE newTable
    CLONE table1;",D,"“newTable” is created, and Snowflake internally executes a pipe to copy all the data from “table1”",“newTable” is created with all the data from “table1”,"“newTable” is created, and Snowflake internally executes a batch job to copy all the data from “table1”",Snowflake creates a new entry in the metadata store to keep track of the new clone. The existing micro-partitions of “table1” are mapped to the new table.,,,"Zero-Copy cloning does NOT duplicate data; it duplicates the metadata of the micro-partitions. When you modify some cloned data, it will consume storage.",https://docs.snowflake.com/en/user-guide/object-clone,,Performance Concepts
543,What is the abbreviated form to get all the files in the stage for the current user?,D,SHOW @%;,LIST @~;,LS @usr;,LS @~;,,,LIST (normal form) / LS (abbrev form),https://docs.snowflake.com/en/sql-reference/sql/list,,Data Transformations
544,How does a Snowflake stored procedure compare to a User-Defined Function (UDF)?,A,"A single executable statement can call only one stored procedure. In contrast, a single SQL statement can call multiple UDFs.","A single executable statement can call multiple stored procedures. In contrast, multiple SQL statements can call the same UDFs.","A single executable statement can call only two stored procedures. In contrast, a single SQL statement can call multiple UDFs.","Multiple executable statements can call more than one stored procedure. In contrast, a single SQL statement can call multiple UDFs.",,,"Multiple UDFs may be called with one statement; a single stored procedure is called with one statement\n
A single SQL statement can call multiple UDFs.\n
A single SQL statement can call only one stored procedure.",https://docs.snowflake.com/en/developer-guide/stored-procedures-vs-udfs,,Data Transformations
545,Which objects will incur storage costs associated with Fail-safe?,C,Data files available in external stages,External tables,Permanent tables,Data files available in internal stages,,,,https://docs.snowflake.com/en/user-guide/data-cdp-storage-costs,,Data Protection and Data Sharing
546,"When reviewing the load for a warehouse using the load monitoring chart, the chart indicates that a high volume of queries is always queuing in the warehouse. According to recommended best practice, what should be done to reduce the queue volume? (Choose two.)","B,D",Stop and start the warehouse to clear the queued queries.,Migrate some queries to a new warehouse to reduce load.,Scale up the warehouse size to allow queries to execute faster.,Use multi-clustered warehousing to scale out warehouse capacity.,Limit user access to the warehouse so fewer queries are run against it.,,"If the running query load is high or there’s queuing, consider starting a separate warehouse and moving queued queries to that warehouse. Alternatively, if you are using multi-cluster warehouses, you could change your multi-cluster settings to add additional clusters to handle higher concurrency going forward.",https://docs.snowflake.com/en/user-guide/warehouses-load-monitoring#slow-query-performance,,Performance Concepts
547,Which statistics are displayed in a Query Profile that indicate that intermediate results do not fit in memory? (Choose two.),"D,E",Percentage scanned from cache,Partitions scanned,Bytes scanned,Bytes spilled to remote storage,Bytes spilled to local storage,,"Spilling — information about disk usage for operations where intermediate results do not fit in memory:\n
Bytes spilled to local storage — volume of data spilled to local disk.\n
Bytes spilled to remote storage — volume of data spilled to remote disk.",https://docs.snowflake.com/en/user-guide/ui-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
548,Which database objects can be shared using Snowflake Secure Data Sharing?,C,Tables.,"Tables, External tables, Secure views.","Tables, External tables, Secure views, Secure materialized views, Secure UDFs.","Tables, External tables, Secure views, Secure materialized views.","Tables, External tables.",,Secure Data Sharing lets you share selected objects in a database in your account with other Snowflake accounts. You can share all the previous database objects.,https://docs.snowflake.com/en/user-guide/data-sharing-intro,,Data Protection and Data Sharing
549,How does Snowflake improve the performance of queries that are designed to filter out a significant amount of data?,C,The use of TableScan,The use of indexing,The use of pruning,By increasing the number of partitions scanned,,,,https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#query-pruning,,Performance Concepts
550,Which user preferences can be set for a user profile in Snowsight? (Choose two.),"C,D",Default schema,Username,Multi-Factor Authentication (MFA),Notifications,Default database,,"On your profile, you can review and set the following user details:\n
-Profile photo\n
-Username (cannot be changed)\n
-First Name\n
-Last Name\n
-Password\n
-Email\n

You can also set the following preferences:\n
-Default role & warehouse\n
-Default experience\n
-Language: Select the language to use for Snowsight. Snowflake currently supports the following languages: English (US), Japanese (日本語)\n
-Notifications: Select whether to send a browser notification when a query finishes running in the background. When you set this preference for the first time, your browser prompts you to allow notifications from Snowflake.(If your active role has access to set up resource monitor notifications, you can also select a checkbox to set up Email notifications from resource monitors.)\n
-Multi-factor authentication: Select whether to enroll in multi-factor authentication (MFA).",https://docs.snowflake.com/en/user-guide/ui-snowsight-profile,,Snowflake AI Data Cloud Features and Architecture
551,"In an auto-scaling multi-cluster virtual warehouse with the setting SCALING_POLICY = ECONOMY enabled, when is another cluster started?",A,When the system has enough load for 6 minutes,When the system has enough load for 8 minutes,When the system has enough load for 10 minutes,When the system has enough load for 2 minutes,,,Only if the system estimates there’s enough query load to keep the cluster busy for at least 6 minutes,https://docs.snowflake.com/en/user-guide/warehouses-multicluster,,Performance Concepts
552,Which command will you run to list all users and roles to which a role has been granted?,B,SHOW GRANTS IN ROLE <ROLE>,SHOW GRANTS OF ROLE <ROLE>,SHOW USERS OF ROLE <ROLE>,SHOW GRANTS TO ROLE <ROLE>,,,"“SHOW GRANTS OF ROLE” will list the users, whereas “SHOW GRANTS TO ROLE” will list the privileges to which this role has access.",https://docs.snowflake.com/en/sql-reference/sql/show-grants,,Data Transformations
553,"A user created a transient table and made several changes to it over the course of several days. Three days after the table was created, the user would like to go back to the first version of the table. How can this be accomplished?",C,Contact Snowflake Support to have the data retrieved from Fail-safe storage.,Use the FAIL_SAFE parameter for Time Travel to retrieve the data from Fail-safe storage.,The transient table version cannot be retrieved after 24 hours.,"Use Time Travel, as long as DATA_RETENTION_TIME_IN_DAYS was set to at least 3 days.",,,,https://docs.snowflake.com/en/user-guide/tables-temp-transient,,Performance Concepts
554,A user needs to ingest 1 GB of data that is available in an external stage using a COPY INTO command. How can this be done with MAXIMUM performance and the LEAST cost?,B,Ingest the data in a compressed format as a single file.,"Split the file into smaller files of 100-250 MB each, compress and ingest each of the smaller files.",Ingest the data in an uncompressed format as a single file.,Split the file into smaller files of 100-250 MB each and ingest each of the smaller files in an uncompressed format.,,,,https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare,,Data Loading and Unloading
555,Which statement describes Snowflake tables?,A,Snowflake tables are logical representations of underlying physical data.,Snowflake tables are the physical instantiation of data loaded into Snowflake.,Snowflake tables require that clustering keys be defined to perform optimally.,Snowflake tables are owned by a user.,,,"All data in Snowflake is stored in database tables, logically structured as collections of columns and rows. To best utilize Snowflake tables, particularly large tables, it is helpful to have an understanding of the physical structure behind the logical structure.",https://docs.snowflake.com/en/user-guide/tables-micro-partitions,,Performance Concepts
556,Which virtual warehouse consideration can help lower compute resource credit consumption?,C,Setting up a multi-cluster virtual warehouse,Resizing the virtual warehouse to a larger size,Automating the virtual warehouse suspension and resumption settings,Increasing the maximum cluster count parameter for a multi-cluster virtual warehouse,,,,https://docs.snowflake.com/en/user-guide/warehouses-considerations#automating-warehouse-suspension,,Performance Concepts
557,Which Snowflake view is used to support compliance auditing?,A,ACCESS_HISTORY,COPY_HISTORY,ROW_ACCESS_POLICIES,QUERY_HISTORY,,,"The ACCESS_HISTORY view in Snowflake is primarily used to support compliance auditing. This view contains information about historical access and usage patterns related to tables and views within your Snowflake account. It provides details on who accessed the data, when, and from which IP addresses, among other audit-related information.",https://docs.snowflake.com/en/user-guide/access-history,,Account Access and Security
558,Which possibilities give us Snowflake to resize a Warehouse? (Choose two.),"C,E",Creating a new warehouse with the new size.,Using the SQL command ALTER WAREHOUSE <name> MODIFY warehouse_size=<SIZE>,Using the Snowflake UI in the Warehouse configuration.,Using the SQL command CHANGE WAREHOUSE <name> SET warehouse_size=<SIZE>,Using the SQL command ALTER WAREHOUSE <name> SET warehouse_size=<SIZE>,,"Resizing a warehouse to a larger size is helpful to improve the performance of large, complex queries against large data sets; and improve performance while loading and unloading significant amounts of data.",https://docs.snowflake.com/en/user-guide/warehouses-tasks#resizing-a-warehouse,,Performance Concepts
559,What command will you execute if you want to disable the query cache?,A,ALTER SESSION SET USE_CACHED_RESULT = FALSE;,ALTER SESSION SET USE_CACHED_RESULT = OFF;,ALTER SESSION SET USE_CACHED_RESULT = TRUE;,ALTER SESSION SET USE_CACHED_RESULT = ON;,,,"This command turns off the query result caching feature for the current session. When the caching is disabled, the results of queries are not stored in the cache, and subsequent executions of the same query will not use the cached results. This can negatively affect query performance, especially for queries executed frequently or with long execution times, but it might be useful for development purposes.",https://docs.snowflake.com/en/sql-reference/parameters#use-cached-result,,Data Transformations
560,Which Snowflake role can set up a Snowflake Share by default?,D,PUBLIC,SYSADMIN,SECURITYADMIN,ACCOUNTADMIN,,,"Only the ACCOUNTADMIN role has the ""CREATE SHARE"" privilege by default. The privilege can be granted to additional roles as needed.",https://docs.snowflake.com/en/sql-reference/sql/create-share#access-control-requirements,,"Data Transformations, Data Protection and Data Sharing"
561,What are benefits of using Snowpark with Snowflake? (Choose two.),"B,E",Snowpark automatically sets up Spark within Snowflake virtual warehouses.,Snowpark does not require that a separate cluster be running outside of Snowflake.,Snowpark scale and compute management are handled by the user.,Snowpark uses a Spark engine to generate optimized SQL query plans.,"Snowpark executes as much work as possible by leveraging pushdown for all operations, including user-defined functions (UDF).",,"In comparison to using the Snowflake Connector for Spark, developing with Snowpark includes the following benefits:\n
-Support for interacting with data within Snowflake using libraries and patterns purpose built for different languages without compromising on performance or functionality.\n
-Support for authoring Snowpark code using local tools such as Jupyter, VS Code, or IntelliJ.\n
-Support for pushdown for all operations, including Snowflake UDFs. This means Snowpark pushes down all data transformation and heavy lifting to the Snowflake data cloud, enabling you to efficiently work with data of any size.\n
-No requirement for a separate cluster outside of Snowflake for computations. All of the computations are done within Snowflake. Scale and compute management are handled by Snowflake.",https://docs.snowflake.com/en/developer-guide/snowpark/index#key-features,,"Snowflake AI Data Cloud Features and Architecture, Data Transformations"
562,Which sequence (order) of object privileges should be used to grant a custom role read-only access on a table?,D,B,A,D,C,,,When designing a RBAC and assigning grants it is very important to follow the principle of ‘least privilege’.,https://docs.snowflake.com/en/user-guide/security-access-control-configure#creating-custom-read-only-roles,https://i.imgur.com/tIUpnsH.png,Account Access and Security
563,Which feature is integrated to support Multi-Factor Authentication (MFA) at Snowflake?,C,One Login,Authy,Duo Security,RSA SecurID Access,,,"MFA support is provided as an integrated Snowflake feature, powered by the Duo Security service, which is managed completely by Snowflake.",https://docs.snowflake.com/en/user-guide/security-mfa,,Account Access and Security
564,"Using COPY INTO <location> command, to which locations is not possible to unload data from a table?",C,"Named external stage that references an external location (Amazon S3, Google Cloud Storage, or Microsoft Azure).",Named internal stage (or table/user stage).,Local Drive.,An external location like Amazon S3 or Azure.,,,"Once the data is in the internal stage, you can download them into your local drive using the GET command. You can also unload data into an external location, as we can see in the following image:",https://docs.snowflake.com/en/sql-reference/sql/copy-into-location,,Data Transformations
565,What is a recommended approach for optimizing query performance in Snowflake?,B,Use a large number of joins to combine data from multiple tables.,Use a smaller number of larger tables rather than a larger number of smaller tables.,"Select all columns from tables, even if they are not needed in the query.",Use subqueries whenever possible.,,,"Snowflake makes use of clustering on tables. Users can utilize cluster key to enhance query performance (partition pruning) on large tables. So, the fewer and larger the tables, the better the pruning and clustering will work.\n

The lesser the number of joins between several tables, the better performance will be in general.\n

Other recommendations like Select all columns is the complete opposite of what Snowflake recommends. Selecting only the required columns is a common query optimization technique in Snowflake that can improve query performance and reduce resource consumption.\n

Subqueries can be useful, but they can also slow down your queries.",https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#query-pruning,,Performance Concepts
566,Which Snowflake edition offers the highest level of security for organizations that have the strictest requirements?,A,Virtual Private Snowflake (VPS),Standard,Enterprise,Business Critical,,,Virtual Private Snowflake offers our highest level of security for organizations that have the strictest requirements,https://docs.snowflake.com/en/user-guide/intro-editions#feature-edition-matrix,,Snowflake AI Data Cloud Features and Architecture
567,"When unloading data with the COPY INTO command, what is the purpose of the PARTITION BY parameter option?",D,To delimit the records in the output file using the specified expression.,To sort the contents of the output file by the specified expression.,To include a new column in the output using the specified window function expression.,"To split the output into multiple files, one for each distinct value of the specified expression.",,,The PARTITION BY copy option accepts an expression by which the unload operation partitions table rows into separate files unloaded to the specified stage.,https://docs.snowflake.com/en/user-guide/data-unload-overview,,Data Loading and Unloading
568,How can a Snowflake user load duplicate files with a COPY INTO command?,D,The COPY INTO options should be set to ON_ERROR = CONTINUE,The COPY INTO options should be set to RETURN_FAILED_ONLY = FALSE,The COPY INTO options should be set to PURGE = FALSE,The COPY INTO options should be set to FORCE = TRUE,,,"FORCE = TRUE | FALSE\n

Definition: Boolean that specifies to load all files, regardless of whether they’ve been loaded previously and have not changed since they were loaded. Note that this option reloads files, potentially duplicating data in a table.",https://docs.snowflake.com/en/sql-reference/sql/copy-into-table,,Data Transformations
569,What is the minimum Snowflake edition that you need for the Data Sharing capability?,A,Standard,Business Critical,Enterprise,Virtual Private Snowflake,,,Secure Data Sharing lets you share selected objects in a database in your account with other Snowflake accounts. All the data-sharing features are available for these three types of editions.,https://docs.snowflake.com/en/user-guide/intro-editions#data-sharing,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
570,What is a characteristic of a tag associated with a masking policy?,D,A tag can be dropped after a masking policy is assigned.,A tag can have multiple masking policies for each data type.,A tag can have multiple masking policies with varying data types.,A tag can have only one masking policy for each data type.,,,The tag can support one masking policy for each data type that Snowflake supports.,https://docs.snowflake.com/en/user-guide/tag-based-masking-policies#overview,,Performance Concepts
571,"A team runs the same query daily, generally with a frequency of fewer than 24 hours, and it takes around 10 minutes to execute. They realized that the underlying data changes because of an ETL process that runs every morning. How can they use the results cache to save the 10 minutes that the query is being executed?",C,"After the ETL run, increase the warehouse size. Decrease it after the query runs.","After the ETL run, use Time-Travel feature.","After the ETL run, execute the identical queries so that the result remains in the cache.","After the ETL run, copy the tables to another database for the team to query.",,,"In this case, because the underlying data changes every morning due to the ETL process, the results cache may not be useful for the daily query execution. However, suppose the team executes an identical query immediately after the ETL process runs. In that case, the results of that query will be stored in the results cache and can be retrieved for subsequent queries. By doing so, the team can save the 10 minutes that the query is being executed by retrieving the results from the cache.",https://docs.snowflake.com/en/user-guide/querying-persisted-results,,Performance Concepts
572,"By default, which role allows a user to manage a Snowflake Data Exchange share?",D,SECURITYADMIN,SYSADMIN,USERADMIN,ACCOUNTADMIN,,,"By default, the privileges required to create and manage shares are granted only to the ACCOUNTADMIN role, ensuring that only account administrators can perform these tasks.",https://docs.snowflake.com/en/user-guide/security-access-privileges-shares,,"Data Protection and Data Sharing, Account Access and Security"
573,"When using SnowSQL, which configuration options are required when unloading data from a SQL query run on a local machine? (Choose two.)",B,quiet,output_file,echo,force_put_overwrite,output_format,,"Quiet is also correct, but this is optional. Not a REQUIRED parameter",https://docs.snowflake.com/en/user-guide/snowsql-use#exporting-data.,,Snowflake AI Data Cloud Features and Architecture
574,What should be considered when deciding to use a Secure View? (Choose two.),"A,B",No details of the query execution plan will be available in the query profiler.,Secure views do not take advantage of the same internal optimizations as standard views.,Once created there is no way to determine if a view is secure or not.,It is not possible to create secure materialized views.,The view definition of a secure view is still visible to users by way of the information schema.,,"The internals of a secure view are not exposed in Query Profile (in the web interface).\n

Some of the internal optimizations for views require access to the underlying data in the base tables for the view. This access might allow data that is hidden from users of the view to be exposed through user code, such as user-defined functions, or other programmatic methods. Secure views do not utilize these optimizations, ensuring that users have no access to the underlying data.",https://docs.snowflake.com/en/user-guide/views-secure,,"Data Protection and Data Sharing, Performance Concepts"
575,The effects of query pruning can be observed by evaluating which statistics? (Choose two.),"B,E",Bytes scanned,Partitions scanned,Bytes written,Bytes read from result,Partitions total,,"Pruning — information on the effects of table pruning:\n
Partitions scanned — number of partitions scanned so far.\n
Partitions total — total number of partitions in a given table.",https://docs.snowflake.com/en/user-guide/ui-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
576,After how many days does the load history of Snowpipe expire?,D,180 days.,90 days.,1 day.,14 days.,,,"The load history is stored in the metadata of the pipe for 14 days. Must be requested from Snowflake via a REST endpoint, SQL table function, or ACCOUNT_USAGE view.",https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro#load-history,,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture"
577,"In which Snowflake layer does Snowflake reorganize data into its internal optimized, compressed, columnar format?",B,Metadata Management,Database Storage,Cloud Services,Query Processing,,,"When data is loaded into Snowflake, Snowflake reorganizes that data into its internal optimized, compressed, columnar format. Snowflake stores this optimized data in cloud storage.",https://docs.snowflake.com/en/user-guide/intro-key-concepts#database-storage,,Snowflake AI Data Cloud Features and Architecture
578,Which of the below columns will you consider while choosing a cluster key? (Choose two.),"C,D",Columns with extremely low cardinality.,Columns with extremely high cardinality.,Columns are frequently used in join predicates.,Columns that are typically used in the selective filters.,,,"A column with very low cardinality (e.g., a column indicating only whether a person is male or female) might yield minimal pruning. On the other hand, a column with very high cardinality (e.g., a column containing UUID or nanosecond timestamp values) is also typically not a good candidate to use directly as a clustering key.",https://docs.snowflake.com/en/user-guide/tables-clustering-keys#considerations-for-choosing-clustering-for-a-table,,Performance Concepts
579,Why would a Snowflake user create a secure view instead of a standard view?,D,"Secure views support additional functionality that is not supported for standard views, such as column masking and row level access policies.","With a secure view, the underlying data is replicated to a separate storage layer with enhanced encryption.",The secure view is only available to end users with the corresponding SECURE_ACCESS property.,"End users are unable to see the view definition, and internal optimizations differ with a secure view.",,,,https://docs.snowflake.com/en/user-guide/views-secure,,"Data Protection and Data Sharing, Performance Concepts"
580,What causes objects in a data share to become unavailable to a consumer account?,B,The consumer account runs the GRANT INPORTED PRIVILEGES command on the data share every 24 hours.,The objects in the data share are being deleted and the grant pattern is not re-applied systematically.,The consumer account acquires the data share through a private data exchange.,The DATA_RETENTION_TIME_IN_DAYS parameter in the consumer account is set to 0.,,,"Any objects that you remove from a share are instantly unavailable to the consumers accounts who have created databases from the share.\n

For example, if you remove a table from a share, users in consumer accounts can no longer query the data in the table as soon as the table is removed from the share.",https://docs.snowflake.com/en/user-guide/data-sharing-provider,,Data Protection and Data Sharing
581,A user has unloaded data from a Snowflake table to an external stage. Which command can be used to verify if data has been uploaded to the external stage named my_stage?,B,display @my_stage,list @my_stage,show @my_stage,view @my_stage,,,,https://docs.snowflake.com/en/sql-reference/sql/list,,Data Transformations
582,What can a Snowflake user do with the information included in the details section of a Query Profile?,D,Determine the source system that the queried table is from.,Determine the role of the user who ran the query.,Determine if the query was on structured or semi-structured data.,Determine the total duration of the query.,,,,https://docs.snowflake.com/en/user-guide/ui-query-profile#query-operator-details,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
583,Which of the following is not a valid context functions in Snowflake?,C,SELECT CURRENT_IP_ADDRESS(),SELECT CURRENT_CLIENT(),SELECT CURRENT_PROVIDER(),SELECT CURRENT_ACCOUNT(),,,,https://docs.snowflake.com/en/sql-reference/functions-context,,Data Transformations
584,At what level is the MIN_DATA_RETENTION_TIME_IN_DAYS parameter set?,C,Database,Schema,Account,Table,,,"MIN_DATA_RETENTION_TIME_IN_DAYS - Account level\n

DATA_RETENTION_TIME_IN_DAYS - Object / Account level",https://docs.snowflake.com/en/sql-reference/parameters#min-data-retention-time-in-days,,Data Transformations
585,"Which command can be added to the COPY command to make it load all files, whether or not the load status of the files is known?",B,LOAD_UNCERTAIN_FILES = TRUE,FORCE = TRUE,LOAD_UNCERTAIN_FILES = FALSE,FORCE = FALSE,,,"To load files whose metadata has expired, set the LOAD_UNCERTAIN_FILES copy option to true. The copy option references load metadata, if available, to avoid data duplication, but also attempts to load files with expired load metadata.\n

Alternatively, set the FORCE option to load all files, ignoring load metadata if it exists. Note that this option reloads files, potentially duplicating data in a table.",https://docs.snowflake.com/en/sql-reference/sql/copy-into-table,,Data Transformations
586,What is the expiration period for a file URL used to access unstructured data in cloud storage?,A,An unlimited amount of time,The remainder of the session,The length of time specified in the expiration_time argument,The same length of time as the expiration period for the query results cache,,,File Url Expiration time is permanent.,https://docs.snowflake.com/en/user-guide/unstructured-intro,,Data Loading and Unloading
587,Which Query Profile result indicates that a warehouse is sized too small?,C,The number of processed rows is very high.,The number of partitions scanned is the same as partitions total.,Bytes are spilling to external storage.,There are a lot of filter nodes.,,,,https://community.snowflake.com/s/article/Performance-impact-from-local-and-remote-disk-spilling,,Performance Concepts
588,What happens to the privileges granted to Snowflake system-defined roles?,D,The privileges can be revoked by an ACCOUNTADMIN.,The privileges can be revoked by any user-defined role with appropriate privileges.,The privileges can be revoked by an ORGADMIN.,The privileges cannot be revoked.,,,"System-defined roles cannot be dropped. In addition, the privileges granted to these roles by Snowflake cannot be revoked.",https://docs.snowflake.com/en/user-guide/security-access-control-overview,,Account Access and Security
589,Which function returns an integer between 0 and 100 when used to calculate the similarity of two strings?,D,APPROXIMATE_JACCARD_INDEX,MINHASH_COMBINE,APPROXIMATE_SIMILARITY,JAROWINKLER_SIMILARITY,,,"Computes the Jaro-Winkler similarity between two input strings. The function returns an integer between O and 100, where 0 indicates no similarity and 100 indicates an exact match.",https://docs.snowflake.com/en/sql-reference/functions/jarowinkler_similarity,,Data Transformations
590,Which statements are correct concerning the leveraging of third-party data from the Snowflake Data Marketplace? (Choose two.),"B,D",Data is not available for copying or moving to an individual Snowflake account.,"Data is live, ready-to-query, and can be personalized.",Data transformations are required when combining Data Marketplace datasets with existing data in Snowflake.,Data is available without copying or moving.,Data needs to be loaded into a cloud provider as a consumer account.,,"Data in the Snowflake Data Marketplace is already formatted and ready to query, and can be personalized for specific business needs.\n

Data from the Snowflake Data Marketplace is accessed through Snowflake's Secure Data Sharing technology, which allows users to access the data without copying or moving it to their own account.\n

Loading data into a cloud provider as a consumer account is not required to leverage data from the Snowflake Data Marketplace, and the data can be accessed and used in a Snowflake account without restriction.\n

Data transformations may not be required when combining Data Marketplace datasets with existing data in Snowflake, as it depends on the specific data being used and how it needs to be combined or analyzed.",https://docs.snowflake.com/en/user-guide/data-share-consumers,,Data Protection and Data Sharing
591,"If you want a dedicated virtual warehouse, which is the lowest Snowflake edition you should opt for?",D,Virtual Private Snowflake.,Enterprise.,Business Critical.,Standard.,,,"In Snowflake, all the Virtual Warehouses are dedicated to the users. If you create a virtual warehouse, you will only be the one using it.",https://docs.snowflake.com/en/user-guide/intro-editions,,Snowflake AI Data Cloud Features and Architecture
592,"A permanent table and temporary table have the same name, TBL1, in a schema. What will happen if a user executes select * from TBL1;?",D,The permanent table will take precedence over the temporary table.,The table that was created most recently will take precedence over the older table.,An error will say there cannot be two tables with the same name in a schema.,The temporary table will take precedence over the permanent table.,,,All queries and other operations performed in the session on the table affect only the temporary table.,https://docs.snowflake.com/en/user-guide/tables-temp-transient#potential-naming-conflicts-with-other-table-types,,Performance Concepts
593,For how long are we billed if our warehouse runs for 48 seconds?,C,We are not going to be billed if the query scans less than 10 micro-partitions.,We are not going to be billed as the warehouse hasn't run for 1 minute.,1 minute.,48 seconds.,,,"When compute resources are provisioned for a warehouse, the minimum billing charge for provisioning compute resources is 1 minute. Even if your warehouse runs for less than a minute, we will be billed for a minute.",https://docs.snowflake.com/en/user-guide/cost-understanding-compute#label-virtual-warehouse-credit-usage,,Performance Concepts
594,"A warehouse ran for 62 seconds, and it was suspended. After some time, it ran for another 20 seconds. For how many seconds will you be billed?",A,122 seconds.,62 seconds.,20 seconds.,92 seconds.,,,"You will be billed for 122 seconds (62 + 60 seconds) because warehouses are billed for a minimum of one minute. The price would be different if the warehouse wasn't suspended before executing the second query.\n

For example, if we had only run a query, and it had only run for 62 seconds, you would be billed for these 62 seconds. If it had only run for 20 seconds, you would've been billed for 60 seconds.",https://docs.snowflake.com/en/user-guide/cost-understanding-compute#label-virtual-warehouse-credit-usage,,Performance Concepts
595,What is the default Time Travel retention period?,D,90 days,45 days,7 days,1 day,,,Default of 1 day.,https://docs.snowflake.com/en/user-guide/data-time-travel#data-retention-period,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
596,Which Snowflake edition supports private communication between Snowflake and your other VPCs through AWS PrivateLink?,B,Standard.,Business Critical.,All Snowflake editions supports private communication between Snowflake and your other VPCs through AWS PrivateLink.,Enterprise.,,,"AWS PrivateLink is an AWS service for creating private VPC endpoints that allow direct, secure connectivity between your AWS VPCs and the Snowflake VPC without traversing the public Internet. This feature requires the Business Critical edition or higher.",https://docs.snowflake.com/en/user-guide/intro-editions#security-governance-and-data-protection,,"Snowflake AI Data Cloud Features and Architecture, Data Protection and Data Sharing"
597,What action can a Resource Monitor not take when it hits the limit?,D,Notify.,Notify & Suspend Immediately.,Notify & Suspend.,Notify & Increase the limit.,,,"- Notify --> It performs no action but sends an alert notification (email/web UI).\n

- Notify & Suspend --> It sends a notification and suspends all assigned warehouses after all statements being executed by the warehouse (s) have been completed.\n

- Notify & Suspend Immediately --> It sends a notification and suspends all assigned warehouses immediately.",https://docs.snowflake.com/en/user-guide/resource-monitors#resource-monitor-notifications,,Performance Concepts
598,Increasing the size of a virtual warehouse from an X-Small to an X-Large is an example of which of the following?,D,Scaling out,Concurrent sizing,Right sizing,Scaling up,,,,https://docs.snowflake.com/en/user-guide/warehouses-considerations#warehouse-resizing-improves-performance,,Performance Concepts
599,What is the MAXIMUM number of days that Snowflake resets the 24-hour retention period for a query result every time the result is used?,D,60 days,1 day,10 days,31 days,,,"Each time the persisted result for a query is reused, Snowflake resets the 24-hour retention period for the result, up to a maximum of 31 days from the date and time that the query was first executed. After 31 days, the result is purged and the next time the query is submitted, a new result is generated and persisted.",https://docs.snowflake.com/en/user-guide/querying-persisted-results,,Performance Concepts
600,"While loading data through the COPY command, you can transform the data. Which of the below transformations is not allowed?",A,Filters.,Truncate columns.,Reorder columns.,Cast.,Omit columns.,,,https://docs.snowflake.com/en/user-guide/data-load-transform#supported-functions,,"Data Transformations, Data Loading and Unloading"
601,Which applications can use key pair authentication? (Choose two).,"C,E",SnowCD,Snowflake Marketplace,SnowSQL,Snowsight,Snowflake connector for Python,,,https://docs.snowflake.com/en/user-guide/key-pair-auth,,Account Access and Security
602,In which Snowflake edition is Tri-Secret Secure option available?,A,Business Critical or higher.,Standard or higher.,Tri-Secret Secure option is not available.,Enterprise or higher.,,,Tri-Secret Secure combines a Snowflake-maintained key and a customer-managed key in the cloud provider platform that hosts your Snowflake account to create a composite master key to protect your Snowflake data. Customer-managed encryption keys through Tri-Secret Secure are available in the Business Critical and VPS editions.,https://docs.snowflake.com/en/user-guide/resource-monitors#resource-monitor-notifications,,Performance Concepts
603,How can a producer share a table with a consumer located in a different region?,B,Unload all data to a stage and then deploy a pipeline to move data to the consumer's stage in other region.,Replicate your account to another region and create a share from that region.,This is not a problem; producers and consumers can be in different regions.,Create a script to replicate your data in the consumer account.,,,"Data sharing works within the same region; however, you can replicate your account to another region and then share data from that replicated account within that account’s region. This is also true across cloud platforms. You can see this behavior in the following image:",https://docs.snowflake.com/en/user-guide/secure-data-sharing-across-regions-platforms,,Data Protection and Data Sharing
604,At what levels can a resource monitor be configured? (Choose two.),"A,E",Account,Schema,Database,Organization,Virtual warehouse,,,https://docs.snowflake.com/en/user-guide/resource-monitors,,Performance Concepts
605,In which hierarchy is tag inheritance possible?,C,Account » User » Role,Database » View » Column,Schema » Table » Column,Account » User » Schema,,,A tag is inherited based on the Snowflake securable object hierarchy.,https://docs.snowflake.com/en/user-guide/object-tagging#tag-lineage,,Performance Concepts
606,A user has enabled the STRIP_OUTER_ARRAY file format option for the COPY INTO {table} command to remove the outer array structure. What else will this format option and command do?,A,Load the records into separate table rows.,Unload the records from separate table rows.,Ensure each unique element stores values of a single native data type.,Export data files in smaller chunks.,,,Enable the STRIP_OUTER_ARRAY file format option for the COPY INTO <table> command to remove the outer array structure and load the records into separate table rows.,https://docs.snowflake.com/en/user-guide/semistructured-considerations,,Data Loading and Unloading
607,Which service does Snowflake use to provide the Zero-Copy cloning functionality?,D,Cache.,SSD Cache of the Virtual Warehouses.,Backup management services.,Metadata from the service layer.,,,"Zero-Copy cloning does NOT duplicate data; it duplicates the metadata of the micro-partitions. For this reason, Zero-Copy cloning doesn’t consume storage. When you modify some cloned data, it will consume storage because Snowflake has to recreate the micro-partitions.",https://docs.snowflake.com/user-guide/tables-storage-considerations#label-cloning-tables,,Performance Concepts
608,"Snowflake's approach to access control combines aspects of two different models. One model remarks, ""each object has an owner, who can in turn grant access to that object"". What is the name of this model?",A,Discretionary Access Control (DAC),Account ownership model.,Role-based Access Control (RBAC),Object ownership model.,,,"Discretionary Access Control (DAC) remarks that ""each object has an owner, who can, in turn, grant access to that object"". In contrast, the Role-based Access Control (RBAC) remarks that ""access privileges are assigned to roles, which are in turn assigned to users"".",https://docs.snowflake.com/en/user-guide/security-access-control-overview,,Account Access and Security
609,What is a core benefit of clustering?,A,To increase scan efficiency in queries by improving pruning,To improve performance by creating a separate file for point lookups,To provide data redundancy by duplicating micro-partitions,To guarantee uniquely identifiable records in the database,,,,https://docs.snowflake.com/en/user-guide/tables-clustering-keys.htm,,Performance Concepts
610,What file format provides the fastest load performance?,A,CSV.,Parquet.,Avro.,JSON.,,,"When we talk about loading data, you get the most significant speed at loading CSV files. However, Snowflake is fast and flexible, and you can also use other formats like JSON or Parquet.",https://community.snowflake.com/s/article/How-to-Load-Terabytes-Into-Snowflake-Speeds-Feeds-and-Techniques,,"Performance Concepts, Data Loading and Unloading"
611,When can user session variables be accessed in a Snowflake scripting procedure?,D,When the procedure is defined as STRICT.,When the procedure is defined to execute as OWNER.,When the procedure is defined with an argument that has the same name and type as the session variable.,When the procedure is defined to execute as CALLER.,,,,https://community.snowflake.com/s/article/Using-session-variables-in-a-stored-procedure,,Data Transformations
612,What computer language can be selected when creating User-Defined Functions (UDFs) using the Snowpark API?,A,Python,SQL,JavaScript,Swift,,,"Snowpark API supports: Python, Scala and Java",https://docs.snowflake.com/en/developer-guide/snowpark/index,,"Snowflake AI Data Cloud Features and Architecture, Data Transformations"
613,What is the purpose of a resource monitor in Snowflake?,A,To control costs and credit usage by virtual warehouses,To monitor the query performance of virtual warehouses,To create and suspend virtual warehouses automatically,To manage cloud services needed for virtual warehouses,,,,https://docs.snowflake.com/en/user-guide/resource-monitors,,Performance Concepts
614,Which encryption algorithm is used by Snowflake tables when we load data into them?,C,SHA 256.,SHA 128.,AES 256.,AES 128.,,,"All ingested data stored in Snowflake tables, and all files stored in internal stages for data loading and unloading, are encrypted using AES-256 strong encryption.",https://docs.snowflake.com/en/user-guide/admin-security,,Account Access and Security
615,"In (at least), how many availability zones does Snowflake replicate your data to?",A,Three.,Two.,One.,It depends of the Snowflake Edition.,,,Cloud storage synchronously and automatically replicates the stored data across multiple devices and at least three availability zones.,https://developers.snowflake.com/wp-content/uploads/2021/06/Snowflake-High-Availability-for-Data-Apps-Whitepaper.pdf,,Snowflake AI Data Cloud Features and Architecture
616,"User1, who has the SYSADMIN role, executed a query on Snowsight. User2, who is in the same Snowflake account, wants to view the result set of the query executed by User1 using the Snowsight query history. What will happen if User2 tries to access the query history?",C,If User2 has the SECURITYADMIN role they will be able to see the results.,If User2 has the ACCOUNTADMIN role they will be able to see the results.,User2 will be unable to view the result set of the query executed by User1.,If User2 has the SYSADMIN role they will be able to see the results.,,,"You can view results only for queries you have executed. If you have privileges to view queries executed by another user, the Query Detail page displays the details for the query, but, for data privacy reasons, the page does not display the actual query result.",https://docs.snowflake.com/en/user-guide/ui-history,,Snowflake AI Data Cloud Features and Architecture
617,Which command removes a role from another role or a user in Snowflake?,C,ALTER ROLE,USE SECONDARY ROLES,REVOKE ROLE,USE ROLE,,,REVOKE ROLE: Removes a role from another role or a user.,https://docs.snowflake.com/en/sql-reference/sql/revoke-role,,Data Transformations
618,"In order to access Snowflake Marketplace listings, who needs to accept the Snowflake Consumer Terms of Service?",D,SYSADMIN,SECURITYADMIN,ACCOUNTADMIN,ORGADMIN,,,"The organization administrator only needs to accept the Snowflake Provider and Consumer Terms once for your organization. After the terms have been accepted, anyone in your organization that has a role with the necessary privileges can become a consumer of listings.\n

Note: You must be an organization administrator (i.e. a user granted the ORGADMIN role) to accept the terms.",https://other-docs.snowflake.com/en/collaboration/consumer-becoming,,Data Protection and Data Sharing
619,How does a Snowflake user reference a directory table created on stage mystage in a SQL query?,A,SELECT * FROM DIRECTORY (@mystage),SELECT * FROM TABLE (@mystage DIRECTORY),SELECT * FROM @mystage::DIRECTORY,SELECT * FROM TO_TABLE (DIRECTORY @mystage),,,,https://docs.snowflake.com/en/user-guide/data-load-dirtables-manage,,Data Loading and Unloading
620,What option will you specify to delete the stage files after a successful load into a Snowflake table with the COPY INTO command?,B,DELETE = TRUE,PURGE = TRUE,REMOVE = TRUE,TRUNCATE = TRUE,,,"If the PURGE option is set to TRUE, Snowflake will try its best to remove successfully loaded data files from stages. If the purge operation fails for any reason, it won't return any error for now.\n

COPY INTO mytable PURGE = TRUE;",https://docs.snowflake.com/en/sql-reference/sql/copy-into-table#copy-options-copyoptions,,Data Transformations
621,Which command is used to start configuring Snowflake for Single Sign-On (SSO)?,C,CREATE NETWORK RULE,CREATE PASSWORD POLICY,CREATE SECURITY INTEGRATION,CREATE SESSION POLICY,,,Snowflake uses a SAML2 security integration to integrate with the IdP you are using to implement federated authentication. Use the CREATE SECURITY INTEGRATION command to start configuring Snowflake for SSO.,https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-security-integration,,Account Access and Security
622,How can the Query Profile be used to identify the costliest operator of a query?,C,Select the TableScan operator node and look at the percentage scanned from cache.,Select any node in the operator tree and look at the number of micro-partitions scanned.,Find the operator node with the highest fraction of time or percentage of total time.,Look at the number of rows between operator nodes across the operator tree.,,,"Operator Nodes by Execution Time: A collapsible panel in the operator tree pane lists nodes by execution time in descending order, enabling users to quickly locate the costliest operator nodes in terms of execution time. The panel lists all nodes that lasted for 1% or longer of the total execution time of the query (or the execution time for the displayed query step, if the query was executed in multiple processing steps).",https://docs.snowflake.com/en/user-guide/ui-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
623,Which command can be used to list all network policies available in an account? A.,A,SHOW NETWORK POLICIES,SHOW SESSION POLICIES,DESCRIBE NETWORK POLICY,DESCRIBE SESSION POLICY,,,,https://docs.snowflake.com/en/sql-reference/sql/show-network-policies,,Data Transformations
624,"A clustering key was defined on a table, but it is no longer needed. How can the key be removed?",D,ALTER TABLE REMOVE CLUSTERING KEY,ALTER TABLE DELETE CLUSTERING KEY,ALTER TABLE PURGE CLUSTERING KEY,ALTER TABLE DROP CLUSTERING KEY,,,ALTER TABLE <name> DROP CLUSTERING KEY,https://docs.snowflake.com/en/sql-reference/sql/alter-table,,Data Transformations
625,What privileges are necessary for a consumer in the Data Exchange to make a request and receive data? (Choose two.),"B,D",REFERENCE_USAGE,IMPORT SHARE,USAGE,CREATE DATABASE,OWNERSHIP,,"To access a listing, you must use the ACCOUNTADMIN role or another role with the CREATE DATABASE and IMPORT SHARE privileges.",https://other-docs.snowflake.com/en/collaboration/consumer-becoming,,Data Protection and Data Sharing
626,Which tasks are performed in the Snowflake Cloud Services layer? (Choose two.),"C,D",Infrastructure security,Maintaining Availability Zones,Management of metadata,Parsing and optimizing queries,Computing the data,,,https://docs.snowflake.com/en/user-guide/intro-key-concepts#cloud-services,,Snowflake AI Data Cloud Features and Architecture
627,How is the data storage cost computed for Snowflake?,D,Based on the amount of compressed data stored on the last day of the month.,Based on the amount of uncompressed data stored on the last day of the month.,Based on the average daily amount of uncompressed data stored.,Based on the average daily amount of compressed data stored.,,,"Storage costs benefit from the automatic compression of all data stored, and the total compressed file size is used to calculate the storage bill for an account.",https://www.snowflake.com/pricing/pricing-guide/,,Snowflake AI Data Cloud Features and Architecture
628,"What Snowflake database object is derived from a query specification, stored for later use, and can speed up expensive aggregation on large data sets?",D,Secure view,Temporary table,External table,Materialized view,,,Simple but very frequent question in exams. Materialized views are an important topic.,https://docs.snowflake.com/en/user-guide/views-materialized,,Performance Concepts
629,What operations can be performed while loading a simple CSV file into a Snowflake table using the COPY INTO command? (Choose two.),"A,E",Converting the datatypes,Grouping by operations,Performing aggregate calculations,Selecting the first few rows,Reordering the columns,,"The COPY command supports:
-Column reordering, column omission, and casts using a SELECT statement. There is no requirement for your data files to have the same number and ordering of columns as your target table.\n
-The ENFORCE_LENGTH | TRUNCATECOLUMNS option, which can truncate text strings that exceed the target column length.",https://docs.snowflake.com/en/user-guide/data-load-transform,,"Data Transformations, Data Loading and Unloading"
630,Column level security in Snowflake allows the application of a masking policy to a column within a table or view. Which two features are related to column-level security? (Choose two.),"A,D",Dynamic Data Masking.,Lock Databases.,Data Encryption,External Tokenization,Conditional Tokenization.,,"Dynamic Data Masking is a security feature in Snowflake that enables you to mask sensitive data (for example, credit card numbers or passwords) in real-time, based on the user's permissions and role. When a user with restricted access attempts to access the masked data, the data is replaced with a masked value or redacted to ensure that sensitive information is not exposed. You can see how it works in the image below.\n

External Tokenization is a data protection method in Snowflake that allows organizations to tokenize sensitive data before loading that data into Snowflake and dynamically detokenize data at query runtime using masking policies with Writing External Functions.\n

Both features require Enterprise Edition (or higher).",https://docs.snowflake.com/en/user-guide/security-column-intro,,Data Protection and Data Sharing
631,"You have the following data in a variant column from the table “myTable”. How can you query the favorite technology that Gonzalo uses?

{ 
""name"": ""Chris Snow"",
""favouriteTechnology"": Snowflake,
""hobbies"":[ 
        {""name"": ""soccer""},
        {""name"": ""music""},
        {""name"": ""hiking""}
 ]}",D,SELECT src:$favouriteTechnology FROM myTable;,SELECT favouriteTechnology FROM myTable;,SELECT CONVERT_JSON(src:favouriteTechnology) FROM myTable;,SELECT src:favouriteTechnology FROM myTable;,,,,https://docs.snowflake.com/en/user-guide/querying-semistructured,,Performance Concepts
632,"How many credits will consume a medium-size warehouse with 2 clusters running in auto-scaled mode for 3 hours, considering that the first cluster runs continuously and the second one runs for 30 minutes in the second hour?",C,10,16,14,8,,,"A medium size warehouse with one cluster consumes four credits per hour. The first cluster will run continuously for three hours, consuming 12 credits. The second one will run for only 30 minutes, consuming two credits. The total of the warehouse will be 14 credits.",https://docs.snowflake.com/en/user-guide/warehouses-overview#warehouse-size,,Performance Concepts
633,What happens when a network policy includes values that appear in both the allowed and blocked IP address lists?,C,Snowflake issues an error message and adds the duplicate IP address values to both the allowed and blocked IP address lists.,Those IP addresses are allowed access to the Snowflake account as Snowflake applies the allowed IP address list first.,Those IP addresses are denied access to the Snowflake account as Snowflake applies the blocked IP address list first.,Snowflake issues an alert message and adds the duplicate IP address values to both the allowed and blocked IP address lists.,,,"When a network policy includes values in both the allowed and blocked IP address lists, Snowflake applies the blocked IP address list first.",https://docs.snowflake.com/en/user-guide/network-policies,,Account Access and Security
634,Which of the following commands cannot be executed from the Snowflake UI? (Choose two.),"A,D",PUT.,LIST <stages>,COPY INTO.,GET.,SHOW.,,"These two commands cannot be executed from the Snowflake web interface; instead, you should use the SnowSQL client to GET or PUT data files.","https://docs.snowflake.com/en/sql-reference/sql/put, https://docs.snowflake.com/en/sql-reference/sql/get",,Data Transformations
635,Which chart type is supported in Snowsight for Snowflake users to visualize data with dashboards?,C,Pie chart,Area chart,Heat grid,Box plot,,,"Snowsight supports the following types of charts:\n
-Bar charts\n
-Line charts\n
-Scatterplots\n
-Heat grids\n
-Scorecards\n

As of documentation date 2024-08. Snowsight evolves frequently, this question may be updated as capabilities evolve.",https://docs.snowflake.com/en/user-guide/ui-snowsight-visualizations,,Snowflake AI Data Cloud Features and Architecture
636,Which command is used to unload data from a table or move a query result to a stage?,B,MERGE,COPY INTO,PUT,GET,,,Use the COPY INTO <location> command to copy the data from the Snowflake database table into one or more files in a Snowflake or external stage.,https://docs.snowflake.com/en/user-guide/data-unload-overview,,Data Loading and Unloading
637,Which commands can only be executed using SnowSQL? (Choose two.),"B,E",LIST,PUT,COPY INTO,REMOVE,GET,,"Usage Notes for GET and PUT commands\n
The command cannot be executed from the Worksheets page in either Snowflake web interface; instead, use the SnowSQL client or Drivers to upload data files, or check the documentation for a specific Snowflake client to verify support for this command.",https://docs.snowflake.com/en/sql-reference/sql/put,,Data Transformations
638,"A user is unloading data to a stage using this command:

copy into @message from (select object_construct('id', 1, 'first_name', 'Snowflake', 'last_name', 'User', 'city', 'Bozeman')) file_format = (type = json)

What will the output file in the stage be?",C,A single uncompressed JSON file with multiple VARIANT columns,Multiple uncompressed JSON files with multiple VARIANT columns,A single compressed JSON file with a single VARIANT column,Multiple compressed JSON files with a single VARIANT column,,,You can use the OBJECT_CONSTRUCT function combined with the COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file.,https://docs.snowflake.com/en/user-guide/data-unload-considerations#unloading-a-relational-table-to-json,,Data Loading and Unloading
639,Which term is used to describe information about disk usage for operations where intermediate results cannot be accommodated in a Snowflake virtual warehouse memory?,A,Spilling,Pruning,Join explosion,Queue overloading,,,"When Snowflake warehouse cannot fit an operation in memory, it starts spilling (storing) data first to the local disk of a warehouse node, and then to remote storage.\n

In such a case, Snowflake first tries to temporarily store the data on the warehouse local disk. As this means extra IO operations, any query that requires spilling will take longer than a similar query running on similar data that is capable to fit the operations in memory.",https://community.snowflake.com/s/article/Performance-impact-from-local-and-remote-disk-spilling,,Performance Concepts
640,"When unloading data from Snowflake to AWS, what permissions are required? (Choose two.)","C,E",s3:GetBucketLocation,s3:CopyObject,s3:DeleteObject,s3:GetBucketAcl,s3:PutObject,,"Snowflake requires the following permissions on an S3 bucket and folder to create new files in the folder (and any sub-folders):\n -s3:DeleteObject\n
-s3:PutObject",https://docs.snowflake.com/en/user-guide/data-unload-s3#configuring-an-s3-bucket-for-unloading-data,,Data Loading and Unloading
641,"We need to temporarily store intermediate data, which an ETL process will only use. We don't need the data outside the ETL process. If you want to optimize storage cost, what type of table will you create to store this data?",B,Permanent.,Temporary.,External.,Transient.,,,"With temporary tables, you can optimize storage costs, as when the Snowflake session ends, data stored in the table is entirely purged from the system. But they also require storage costs while the session is active.\n

A temporary table is purged once the session ends, so the retention period is for 24 hours or the remainder of the session.",https://docs.snowflake.com/en/user-guide/tables-temp-transient,,Performance Concepts
642,What COPY INTO SQL command should be used to unload data into multiple files?,B,MULTIPLE=TRUE,SINGLE=FALSE,SINGLE=TRUE,MULTIPLE=FALSE,,,The default is SINGLE = FALSE (i.e. unload into multiple files).,https://docs.snowflake.com/en/user-guide/data-unload-overview#bulk-unloading-into-single-or-multiple-files,,Data Loading and Unloading
643,What does the worksheet and database explorer feature in Snowsight allow users to do?,D,Combine multiple worksheets into a single worksheet.,Tag frequently accessed worksheets for ease of access.,Add or remove users from a worksheet.,Move a worksheet to a folder or a dashboard.,,,,https://docs.snowflake.com/en/user-guide/ui-snowsight-worksheets,,Snowflake AI Data Cloud Features and Architecture
644,What criteria does Snowflake use to determine the current role when initiating a session? (Choose two.),"C,E","If no role was specified as part of the connection and a default role has not been set for the Snowflake user, the session will not be initiated and the log in will fail.","If a role was specified as part of the connection and that role has not been granted to the Snowflake user, it will be ignored and the default role will become the current role.","If a role was specified as part of the connection and that role has been granted to the Snowflake user, the specified role becomes the current role.","If a role was specified as part of the connection and that role has not been granted to the Snowflake user, the role is automatically granted and it becomes the current role.","If no role was specified as part of the connection and a default role has been defined for the Snowflake user, that role becomes the current role.",,,https://docs.snowflake.com/en/user-guide/security-access-control-overview#label-access-control-role-enforcement,,Account Access and Security
645,Which statement is true about Multi-Factor Authentication (MFA) in Snowflake?,A,Any Snowflake user can self-enroll in MFA through the web interface.,Snowflake users are automatically enrolled in MFA.,MFA can be enforced or applied for a given role.,Users enroll in MFA by submitting a request to Snowflake Support.,,,,https://docs.snowflake.com/en/user-guide/security-mfa,,Account Access and Security
646,"A sales table FCT_SALES has 100 million records. The following query was executed:

SELECT COUNT (1) FROM FCT_SALES;

How did Snowflake fulfill this query?",B,Query against a virtual warehouse cache,Query against the metadata cache,Query against the most-recently created micro-partition,Query against the result set cache,,,The count() is one of the operations that is resolved in the Metadata Layer.,https://docs.snowflake.com/en/user-guide/ui-query-profile#metadata-operators,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
647,"Based on Snowflake recommendations, when creating a hierarchy of custom roles, the top-most custom role should be assigned to which role?",C,USERADMIN,SECURITYADMIN,SYSADMIN,ACCOUNTADMIN,,,,https://docs.snowflake.com/en/user-guide/security-access-control-overview#custom-roles,,Account Access and Security
648,How does the PARTITION BY option affect an expression for a COPY INTO command?,A,The unload operation partitions table rows into separate files unloaded to the specified stage.,A single file will be loaded with a Snowflake-defined partition key and Snowflake will use this key for pruning.,A single file will be loaded with a user-defined partition key and the user can use this partition key for clustering.,The unload operation partitions table rows into separate files unloaded to the specified table.,,,The PARTITION BY copy option accepts an expression by which the unload operation partitions table rows into separate files unloaded to the specified stage.,https://docs.snowflake.com/en/user-guide/data-unload-overview,,Data Loading and Unloading
649,How can a dropped internal stage be restored?,B,Execute the UNDROP command.,Recreate the dropped stage.,Enable Time Travel.,Clone the dropped stage.,,,"Recreate the dropped stage. Dropped stages cannot be recovered; they must be recreated.\n
Clone the dropped stage. - Incorrect, you cannot clone a previously dropped object.\n
Execute the UNDROP command - Incorrect, UNDROP command cannot be used with stages.\n
\n
Using Time Travel, you can perform the following actions within a defined period of time:\n
-Query data in the past that has since been updated or deleted.\n
-Create clones of entire tables, schemas, and databases at or before specific points in the past.\n
-Restore tables, schemas, and databases that have been dropped.","https://docs.snowflake.com/en/sql-reference/sql/drop-stage, https://docs.snowflake.com/en/sql-reference/sql/undrop, https://docs.snowflake.com/en/user-guide/data-time-travel#introduction-to-time-travel",,"Data Transformations, Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
650,Which table function should be used to view details on a Directed Acyclic Graph (DAG) run that is presently scheduled or is executing?,B,TASK_DEPENDENTS,CURRENT_TASK_GRAPHS,TASK_HISTORY,COMPLETE_TASK_GRAPHS,,,"CURRENT_TASK_GRAPHS: Returns the status of a graph run that is currently scheduled or is executing. A graph is currently defined as a single scheduled task or a DAG of tasks composed of a scheduled root task and one or more child tasks (i.e. tasks that have a defined predecessor task). For the purposes of this function, root task refers to either the single scheduled task or the root task in a DAG.",https://docs.snowflake.com/en/sql-reference/functions/current_task_graphs,,Data Transformations
651,Which statements about Snowflake tasks are true? (Choose two.),"C,D",A task can not execute a call to a Stored Procedure.,A task can execute multiple SQL Statements.,A task can execute a call to a Stored Procedure.,A task can execute a single SQL Statement.,A task can execute a function.,,"Only one SQL statement is allowed to be executed through a task. If you need to execute multiple statements, build a procedure.",https://docs.snowflake.com/en/user-guide/tasks-intro,,Performance Concepts
652,Which of the following file formats is not supported by Snowflake to unload data?,B,Parquet.,Avro.,CSV.,JSON.,,,"A File Format object describes and stores the format information required to load data into Snowflake tables. You can specify different parameters, such as the file’s delimiter, if you want to skip the header or not, etc. You can see the different file formats in the following image:",https://docs.snowflake.com/en/user-guide/intro-summary-unloading,,Data Loading and Unloading
653,Which of the below columns are usually a good choice for clustering keys?,A,Store_id in a 2TB table.,Gender male/female in a 20TB table.,Timestamp in a 10TB table.,UUID column from a Customer in a 10TB table.,,,"A column with very low cardinality (gender in this case) might yield minimal pruning. On the other hand, a column with very high cardinality (UUID or timestamp in this case) is also typically not a good candidate to use directly as a clustering key, as there will be a lot of values. Store_id is the most convenient option.",https://docs.snowflake.com/en/user-guide/tables-clustering-keys,,Performance Concepts
654,Snowflake’s access control framework combines which models for securing data? (Choose two.),"B,C",Rule-based Access Control (RuBAC),Discretionary Access Control (DAC),Role-based Access Control (RBAC),Attribute-based Access Control (ABAC),Access Control List (ACL),,"Snowflake’s approach to access control combines aspects from both of the following models:\n
-Discretionary Access Control (DAC): Each object has an owner, who can in turn grant access to that object.\n
-Role-based Access Control (RBAC): Access privileges are assigned to roles, which are in turn assigned to users.",https://docs.snowflake.com/en/user-guide/security-access-control-overview,,Account Access and Security
655,"Which function can be used with the COPY INTO statement to convert rows from a relational table to a single VARIANT column, and to unload rows into a JSON file?",A,OBJECT_CONSTRUCT,OBJECT_AS,FLATTEN,TO_VARIANT,,,You can use the OBJECT_CONSTRUCT function combined with the COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file.,https://docs.snowflake.com/en/user-guide/data-unload-considerations,,Data Loading and Unloading
656,A user unloaded a Snowflake table called mytable to an internal stage called mystage. Which command can be used to view the list of files that has been uploaded to the stage?,D,list @%mystage;,list @mytable;,list @%mytable;,list @mystage;,,,,https://docs.snowflake.com/en/sql-reference/sql/list,,Data Transformations
657,A JSON file that contains lots of dates and arrays needs to be processed in Snowflake. The user wants to ensure optimal performance while querying the data. How can this be achieved?,B,Store the data in a table with a VARIANT data type. Query the table.,Flatten the data and store it in structured data types in a flattened table. Query the table.,Store the data in a table with a VARIANT data type and include STRIP_NULL_VALUES while loading the table. Query the table.,Store the data in an external stage and create views on top of it. Query the views.,,,"For better pruning and less storage consumption, we recommend flattening your OBJECT and key data into separate relational columns if your semi-structured data includes:\n
-Dates and timestamps, especially non-ISO 8601 dates and timestamps, as string values\n
-Numbers within strings\n
-Arrays\n

Non-native values (such as dates and timestamps in JSON) are stored as strings when loaded into a VARIANT column, so operations on these values could be slower and also consume more space than when stored in a relational column with the corresponding data type.",https://docs.snowflake.com/en/user-guide/semistructured-considerations#storing-semi-structured-data-in-a-variant-column-vs-flattening-the-nested-structure,,Data Loading and Unloading
658,Which feature of Snowflake’s Continuous Data Protection (CDP) has associated costs?,D,End-to-end encryption,Multi-Factor Authentication (MFA),Network policies,Fail-safe,,,,https://docs.snowflake.com/en/user-guide/data-cdp-storage-costs,,Data Protection and Data Sharing
659,What compute resource is used when loading data using Snowpipe?,B,Snowpipe uses virtual warehouses provided by the user.,Snowpipe uses compute resources provided by Snowflake.,Snowpipe uses an Apache Kafka server for its compute resources.,Snowpipe uses cloud platform compute resources provided by the user.,,,Snowpipe uses compute resources provided by Snowflake (i.e. a serverless compute model).,https://docs.snowflake.com/en/user-guide/data-load-overview,,Data Loading and Unloading
660,What actions are supported by Snowflake resource monitors? (Choose two.),"D,E",Suspend immediately,Abort,Alert,Notify,Notify and suspend,,"Resource monitors support the following actions:\n
-Notify & Suspend Send a notification (to all account administrators with notifications enabled) and suspend all assigned warehouses after all statements being executed by the warehouse(s) have completed.\n
-Notify & Suspend Immediately Send a notification (to all account administrators with notifications enabled) and suspend all assigned warehouses immediately, which cancels any statements being executed by the warehouses at the time.\n
-Notify Perform no action, but send an alert notification (to all account administrators with notifications enabled).",https://docs.snowflake.com/en/user-guide/resource-monitors#resource-monitor-notifications,,Performance Concepts
661,What is a key benefit of using organizations in Snowflake?,C,Ability to use zero-copy cloning across accounts,Ability to use ACCOUNT_USAGE views,Ability to consolidate account management and billing,Ability to access new releases for testing and validation purposes,,,Ability to consolidate account management and billing. The rest of the options are not technically possible or are technically possible but do not depend on the use of organizations.,https://docs.snowflake.com/en/user-guide/organizations,,Snowflake AI Data Cloud Features and Architecture
662,Which of these Snowflake components/objects is NOT typically used in building continuous ELT pipelines?,A,Data Exchange.,Snowpipe.,Snowflake Connector for Kafka.,Streams.,,,"Data Exchange is your own data hub for securely collaborating around data between a selected group of members you invite. It enables providers to publish data that consumers can then discover. You can use your Data Exchange to exchange data between business units internal to your company and collaborate with external parties such as vendors, suppliers, partners, and customers.","https://docs.snowflake.com/en/user-guide/data-exchange, https://docs.snowflake.com/en/user-guide/data-pipelines-intro",,"Data Protection and Data Sharing, Data Loading and Unloading"
663,What is the function of the PUBLIC schema in Snowflake?,B,It’s the schema where information about pricing will be stored.,Default schema where objects are going to be created.,"It’s the schema that even non-Snowflake users will be able to access, as it’s public.",It’s the schema where non-PII data will be stored.,,,"A schema is a logical grouping of database objects (tables, views, etc.), and each schema belongs to a single database. The PUBLIC schema is the default schema for a database, and all objects are, by default, created inside it if no other schema is specified.","https://docs.snowflake.com/en/sql-reference/sql/create-database#general-usage-notes, https://docs.snowflake.com/en/sql-reference/sql/use-database#usage-notes",,Data Transformations
664,Which types of tables typically benefit from creating a cluster key?,B,Medium tables (around 10GB of data),Very large tables (multi-terabytes of data),Small tables (around 1GB of data),Large tables (around 100GB of data),,,"Although clustering can substantially improve the performance and reduce the cost of some queries, the compute resources used to perform clustering consume credits. As such, you should cluster only when queries will benefit substantially from the clustering in huge tables.",https://docs.snowflake.com/en/user-guide/tables-clustering-keys#considerations-for-choosing-clustering-for-a-table,,Performance Concepts
665,The owner of a task (the one who has the OWNERSHIP privilege) is deleted. What will happen to the task?,C,The task will belong to the ACCOUNTADMIN role.,The task is deleted.,The task will belong to the role that dropped the owner’s role.,The task is suspended.,,,"When the owner of a task is deleted, the task is ""re-possessed"" to the role that dropped the owner's role. This ensures that ownership moves to a role closer to the role hierarchy's root. In this case, the task will have to be resumed explicitly by the new owner, as it's automatically paused.",https://docs.snowflake.com/en/sql-reference/sql/drop-role#usage-notes,,Data Transformations
666,What is the maximum length of time travel available in the Snowflake Standard Edition?,C,90 Days,30 Days,1 Day,7 Days,,,90 days in enterprise or higher edition only.,https://docs.snowflake.com/en/user-guide/data-time-travel#data-retention-period,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
667,What general guideline does Snowflake recommend when setting the auto-suspension time limit?,D,Set query warehouses for suspension after 30 minutes.,Set tasks for immediate suspension.,Set query warehouses for suspension after 15 minutes.,Set tasks for suspension after 5 minutes.,,,"If you enable auto-suspend, we recommend setting it to a low value (e.g. 5 or 10 minutes or less) because Snowflake utilizes per-second billing. This will help keep your warehouses from running (and consuming credits) when not in use.",https://docs.snowflake.com/en/user-guide/warehouses-considerations#automating-warehouse-suspension,,Performance Concepts
668,Which schema has the RESOURCE_MONITORS view?,B,WAREHOUSE_USAGE_SCHEMA,READER_ACCOUNT_USAGE,ACCOUNT_USAGE,INFORMATION_SCHEMA,,,,https://docs.snowflake.com/en/sql-reference/account-usage/resource_monitors,,Data Transformations
669,Why should a Snowflake user configure a secure view? (Choose two.),"A,D",To protect hidden data from other users,To encrypt the data in transit,To improve the performance of a query,To hide the view definition from other users,To execute faster than a standard view,,"Some of the internal optimizations for views require access to the underlying data in the base tables for the view. This access might allow data that is hidden from users of the view to be exposed through user code, such as user-defined functions, or other programmatic methods. Secure views do not utilize these optimizations, ensuring that users have no access to the underlying data.\n

For security or privacy reasons, you might not wish to expose the underlying tables or internal structural details for a view. With secure views, the view definition and details are visible only to authorized users (i.e. users who are granted the role that owns the view).",https://docs.snowflake.com/en/user-guide/views-secure,,"Data Protection and Data Sharing, Performance Concepts"
670,"While using a COPY command with a Validation_mode parameter, which of the following statements will return an error?",B,Statements that have duplicate file names,Statements that transform data during a load,Statements that have a specific data type in the source,Statements that insert a duplicate record during a load,,,The VALIDATION_MODE parameter does not support COPY statements that transform data during a load.,https://docs.snowflake.com/en/user-guide/data-load-transform#validation-mode-parameter,,"Data Transformations, Data Loading and Unloading"
671,"For directory tables, what stage allows for automatic refreshing of metadata?",B,Table stage,Named external stage,User stage,Named internal stage,,,"You can automatically refresh the metadata for a directory table by using the following event notification services:\n
-Amazon S3: Amazon SQS (Simple Queue Service)\n
-Google Cloud Storage: Google Cloud Pub/Sub\n
-Microsoft Azure: Microsoft Azure Event Grid",https://docs.snowflake.com/en/user-guide/data-load-dirtables-auto,,Data Loading and Unloading
672,What tasks can an account administrator perform in the Data Exchange? (Choose two.),"A,B",Add and remove members.,Approve and deny listing approval requests.,Transfer listing ownership.,Transfer ownership of a provider profile.,Delete data categories.,,"By default, only an account administrator (a user with the ACCOUNTADMIN role) in the Data Exchange administrator account can manage a Data Exchange, which includes the following tasks:\n
-Add or remove members.\n
-Approve or deny listing approval requests.\n
-Approve or deny provider profile approval requests.\n
-Show categories.",https://docs.snowflake.com/en/user-guide/data-exchange-marketplace-privileges,,Data Protection and Data Sharing
673,"What is the output of the command.
    SELECT TOP 100 AGE
    FROM USERS;",C,The TOP 100 grades in ascendent order.,The TOP 100 grades ordered by the creation date of the data.,Non-deterministic list of 100 grades.,The TOP 100 grades in descendent order.,,,We'd need the ORDER BY clause if we want to generate the other results.,"https://docs.snowflake.com/en/sql-reference/sql/select, https://docs.snowflake.com/en/sql-reference/constructs/top_n, https://docs.snowflake.com/en/sql-reference/constructs/order-by",,Data Transformations
674,What is the COPY INTO command option default for unloading data into multiple files?,A,SINGLE = FALSE,SINGLE = TRUE,SINGLE = NULL,SINGLE = 0,,,The COPY INTO <location> command provides a copy option (SINGLE) for unloading data into a single file or multiple files. The default is SINGLE = FALSE (i.e. unload into multiple files).,https://docs.snowflake.com/en/user-guide/data-unload-overview,,Data Loading and Unloading
675,What is used to limit the credit usage of a virtual warehouse within a Snowflake account?,A,Resource monitor,Load monitor,Query Profile,Stream,,,,https://docs.snowflake.com/en/user-guide/resource-monitors,,Performance Concepts
676,"You have a multi-cluster warehouse running with the standard scaling policy. The maximum number of clusters is set to 8. If a lot of queries are queried, and the warehouse is constantly starting new clusters, what is the maximum time the warehouse will start all the clusters?",B,8 minutes.,160 seconds.,They all start at the same time.,80 seconds.,,,"Each successive cluster waits to start 20 seconds after the prior one has started. For example, if your warehouse is configured with ten max clusters, it can take 200+ seconds to start all 10 clusters. This doesn't happen using the economy policy, that it will only start new clusters if the system estimates there’s enough query load to keep the cluster busy for at least 6 minutes. You can take a look to the following picture to know the differences between these scaling policies:",https://docs.snowflake.com/en/user-guide/warehouses-multicluster#setting-the-scaling-policy-for-a-multi-cluster-warehouse,,Performance Concepts
677,"You have the following data in a variant column called “person_data” from the table “myTable”. How can you query the second hobby of Chris (“music”)?

{ 
""name"": ""Chris"",
""favouriteTechnology"": Snowflake,
""hobbies"":[ 
	{""name"": ""soccer""},
	{""name"": ""music""},
	{""name"": ""hiking""}
 ]}",C,SELECT person_data:hobbies(1),SELECT person_data:hobbies[1],SELECT person_data:hobbies[1].name,SELECT person_data:hobbies(1).name,,,,https://docs.snowflake.com/en/user-guide/querying-semistructured,,Performance Concepts
678,Which Snowflake URL type is used by directory tables?,D,Pre-signed,Scoped,Virtual-hosted style,File,,,"Conceptually, directory tables are similar to external tables in that they store file-level metadata about the data files in a stage. Query a directory table to retrieve the Snowflake-hosted file URL to each file in the stage. A file URL permits prolonged access to a specified file. That is, the file URL does not expire. The same file URL is returned by calling the BUILD_STAGE_FILE_URL function.",https://docs.snowflake.com/en/user-guide/data-load-dirtables,,Data Loading and Unloading
679,A view is defined on a permanent table. A temporary table with the same name is created in the same schema as the referenced table. What will the query from the view return?,D,An error stating that the referenced object could not be uniquely identified.,An error stating that the view could not be compiled.,The data from the permanent table.,The data from the temporary table.,,,"Similar to the other table types (transient and permanent), temporary tables belong to a specified database and schema; however, because they are session-based, they aren't bound by the same uniqueness requirements. This means you can create temporary and non-temporary tables with the same name within the same schema.\n

However, note that the temporary table takes precedence in the session over any other table with the same name in the same schema.",https://docs.snowflake.com/en/user-guide/tables-temp-transient,,Performance Concepts
680,What activities can be monitored by a user directly from Snowsight's Activity tab without using the Account_Usage views? (Choose two.),"D,E",Event usage history,Login history,Virtual warehouse metering history,Query history,Copy history,,It is highly recommended before the exam to browse the new Snowflake Snowsight UI and familiarize yourself with the various capabilities it offers. Some questions like this will appear on the exam.,https://docs.snowflake.com/en/user-guide/ui-snowsight-activity,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
681,Snowflake's approach to the management of system access combines which of the following models? (Choose two.),"B,E",Security Assertion Markup Language (SAML),Role-Based Access Control (RBAC),Mandatory Access Control (MAC),"Create, Read, Update, and Delete (CRUD)",Discretionary Access Control (DAC),Identity Access Management (IAM),"Snowflake’s approach to access control combines aspects from both of the following models:\n
-Discretionary Access Control (DAC): Each object has an owner, who can in turn grant access to that object.\n
-Role-based Access Control (RBAC): Access privileges are assigned to roles, which are in turn assigned to users.",https://docs.snowflake.com/en/user-guide/security-access-control-overview,,Account Access and Security
682,What do temporary and transient tables have in common in Snowflake? (Choose two.),"A,E",Both tables have no Fail-safe period.,Both tables are visible only to a single user session.,"For both tables, the retention period does not end when the session ends.","For both tables, the retention period ends when the tables are dropped.",Both tables have data retention period maximums of one day.,,,https://docs.snowflake.com/user-guide/tables-temp-transient#comparison-of-table-types,,Performance Concepts
683,Which Snowflake partner category is represented at the top of this diagram (labeled 1)?,C,Machine Learning and Data Science,Business Intelligence,Data Integration,Security and Governance,,,,https://docs.snowflake.com/en/user-guide/ecosystem-security,https://i.imgur.com/9noZ4NN.png,"Snowflake AI Data Cloud Features and Architecture, Data Protection and Data Sharing"
684,A PUT command can be used to stage local files from which Snowflake interface?,A,SnowSQL,Snowsight,Snowflake classic web interface (UI),.NET driver,,,"PUT command Usage The command cannot be executed from the Worksheets page in the Snowflake web interface; instead, use the SnowSQL client to upload data files, or check the documentation for the specific Snowflake client to verify support for this command.",https://docs.snowflake.com/en/sql-reference/sql/put,,Data Transformations
685,What happens when the values for both an ALLOWED_IP_LIST and a BLOCKED_IP_LIST are used in a network policy?,D,Snowflake ignores the ALLOWED_IP_LIST first.,Snowflake ignores the BLOCKED_IP_LIST first.,Snowflake applies the ALLOWED_IP_LIST first.,Snowflake applies the BLOCKED_IP_LIST first.,,,"When a network policy includes values in both the allowed and blocked IP address lists, Snowflake applies the blocked IP address list first.",https://docs.snowflake.com/en/user-guide/network-policies,,Account Access and Security
686,Which DDL/DML operation is allowed on an inbound data share?,C,ALTER TABLE,INSERT INTO,SELECT,MERGE,,,"Shared databases are read-only. Users in a consumer account can view/query data, but cannot insert or update data, or create any objects in the database.",https://docs.snowflake.com/en/user-guide/data-share-consumers,,Data Protection and Data Sharing
687,What action should be taken if a Snowflake user wants to share a newly created object in a database with consumers?,C,Recreate the object with a different name in the database before sharing.,Use the automatic sharing feature for seamless access.,Use the GRANT privilege .. TO SHARE command to grant the necessary privileges.,Drop the object and then re-add it to the database to trigger sharing.,,,"GRANT <privilege> … TO SHARE: Grants access privileges for databases and other supported database objects (schemas, UDFs, tables, and views) to a share. Granting privileges on these objects effectively adds the objects to the share, which can then be shared with one or more consumer accounts.","https://docs.snowflake.com/en/user-guide/data-sharing-gs, https://docs.snowflake.com/en/sql-reference/sql/grant-privilege-share",,"Data Transformations, Data Protection and Data Sharing"
688,How is the MANAGE GRANTS privilege applied?,A,Globally,At the database level,At the schema level,At the table level,,,"In general, a role with any one of the following sets of privileges can grant privileges on an object to other roles:\n
-The global MANAGE GRANTS privilege.\n
-Only the SECURITYADMIN and ACCOUNTADMIN system roles have the MANAGE GRANTS privilege; however, the privilege can be granted to custom roles.",https://docs.snowflake.com/en/sql-reference/sql/grant-privilege#access-control-requirements,,Data Transformations
689,The time-travel retention period of a table is configured to be ten days. You now increase the retention period to 20 days. What will happen with the table's data after this increment? (Choose two.),"B,C",Changes will impact only new data.,Any data that is ten days older and moved to fail-safe will not have any impact.,Any data which has not reached the ten days time-travel period will now have time-travel extended for 20 days.,Any data that is between 10 and 20 days older will have time-travel extended.,,,"Increasing the time-travel retention period impacts the new data and the data that hasn't reached the time-travel period. In this case, the new data and the data that hasn't reached the ten days will be extended to 20 days.",https://docs.snowflake.com/en/user-guide/data-time-travel#changing-the-data-retention-period-for-an-object,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
690,What happens when a suspended virtual warehouse is resized in Snowflake?,D,It will return a warning,It will return an error.,The suspended warehouse is resumed and new compute resources are provisioned immediately.,The additional compute resources are provisioned when the warehouse is resumed.,,,"Resizing a suspended warehouse does not provision any new compute resources for the warehouse. It simply instructs Snowflake to provision the additional compute resources when the warehouse is next resumed, at which time all the usage and credit rules associated with starting a warehouse apply.",https://docs.snowflake.com/en/user-guide/warehouses-tasks,,Performance Concepts
691,When does Snowflake automatically encrypt data that is loaded into Snowflake? (Choose two.),"B,C",After the data is micro-partitioned.,After loading the data into an internal stage.,After loading the data into a table.,Only when using an encrypted stage.,After loading data into an external stage.,,"1. If the stage is an external stage, the user may optionally encrypt the data files using client-side encryption (see Client-Side Encryption for more information). We recommend client-side encryption for data files in external stages; but if the data is not encrypted, Snowflake immediately encrypts the data when it is loaded into a table.\n

If the stage is an internal (i.e. Snowflake) stage data files are automatically encrypted by the Snowflake client on the user’s local machine prior to being transmitted to the internal stage, in addition to being encrypted after they are loaded into the stage.\n

2. The user loads the data from the stage into a table.\n
The data is transformed into Snowflake’s proprietary file format and stored in a cloud storage container. In Snowflake, all data at rest is always encrypted and encrypted with TLS in transit. Snowflake also decrypts data when data is transformed or operated on in a table, and then re-encrypts the data when the transformations and operations are complete.",https://docs.snowflake.com/en/user-guide/security-encryption-end-to-end,,Data Protection and Data Sharing
692,Which ALTER commands will impact a column's availability in Time Travel?,A,ALTER TABLE … SET DATA TYPE …,ALTER TABLE … SET NOT NULL …,ALTER TABLE … RENAME COLUMN …,ALTER TABLE … DROP COLUMN …,,,"Decreasing the precision of a number column can impact Time Travel, for example, converting from NUMBER(20,2) to NUMBER(10,2). SET DATA TYPE is the command that can make that.",https://docs.snowflake.com/en/user-guide/data-time-travel#changing-the-data-retention-period-for-an-object,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
693,Which types of charts does Snowsight support? (Choose two.),"B,C",Column charts,Bar charts,Scorecards,Area charts,Radar charts,,"Snowsight supports the following types of charts:\n
-Bar charts\n
-Line charts\n
-Scatterplots\n
-Heat grids\n
-Scorecards",https://docs.snowflake.com/en/user-guide/ui-snowsight-visualizations,,Snowflake AI Data Cloud Features and Architecture
694,A Snowflake user has two tables that contain numeric values and is trying to find out which values are present in both tables. Which set operator should be used?,D,MERGE,UNION,MINUS,INTERSECT,,,"INTERSECT: Returns rows from one query’s result set which also appear in another query’s result set, with duplicate elimination.",https://docs.snowflake.com/en/sql-reference/operators-query,,Data Transformations
695,"When creating a table using the command:
    CREATE TABLE MY_TABLE 
        (NAME STRING(100)); 
What would the command ""DESC TABLE MY_TABLE;"" display as the column type?",A,Varchar.,Text.,Char.,String.,,,"Varchar has different synonyms, like STRING , TEXT , NVARCHAR , CHAR , CHARACTER…, but in the end, they are all VARCHAR type when describing the table. Take a look at the following example, where all the column types are VARCHAR:","https://docs.snowflake.com/en/sql-reference/sql/desc-table#output, https://docs.snowflake.com/en/user-guide/data-time-travel#changing-the-data-retention-period-for-an-object",,"Data Transformations, Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
696,In which Snowflake editions is the Snowflake Marketplace not available?,A,Virtual Private Snowflake (VPS) edition.,Standard edition.,Business Critical Edition.,Snowflake Marketplace is available in all Snowflake editions.,Enterprise edition.,,There are some restrictions in the Snowflake VPS edition. You can check all of them in the following image (via docs.snowflake.com):,"https://docs.snowflake.com/en/user-guide/intro-editions#data-sharing, https://other-docs.snowflake.com/en/collaboration/virtual-private-snowflake/about-vps-collaboration#provision-of-data-products",,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
697,What is the name of the SnowSQL file that can store connection information?,C,snowsql.pubkey,snowsql.cnf,config,history,,,"SnowSQL supports multiple configuration files that allow organizations to define base values for connection parameters, default settings, and variables while allowing individual users to customize their personal settings in their own <HOME_DIR>/.snowsql/config files.",https://docs.snowflake.com/en/user-guide/snowsql-config,,Snowflake AI Data Cloud Features and Architecture
698,At which point is data encrypted when using a PUT command?,B,When it gets micro-partitioned,Before it is sent from the user's machine,When it reaches the virtual warehouse,After it reaches the internal stage,,,Always end-to-end encryption,https://docs.snowflake.com/en/sql-reference/sql/put,,Data Transformations
699,What does the orange bar on an operator represent when reviewing the Query Profile?,B,The cost of the operator in terms of the virtual warehouse CPU utilization.,The fraction of time that this operator consumed within the query step.,The fraction of data scanned from cache versus remote disk for the operator.,A measure of progress of the operator's execution.,,,"Fraction of time that this operator consumed within the query step (e.g. 25% for Aggregate [5]). This information is also reflected in the orange bar at the bottom of the operator node, allowing for easy visual identification of performance-critical operators.",https://docs.snowflake.com/en/user-guide/ui-query-profile,https://i.imgur.com/3ffTbkS.png,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
700,Which of the following listing types are not available in the Snowflake Data Marketplace?,D,Personalized Listing.,Free Listing.,Paid Listing.,Private Listing.,,,"Free Listing (also known as Standard Listing) is the best for providing generic, aggregated, or non-customer-specific data. In contrast, consumers can request specific datasets from providers using Personalized Listing. Snowflake recently added Paid Listings, where, as a provider, you can charge consumers to access or use your listing.\n

There is another type, Private Listings, where you can use listings to share data and other information directly with other Snowflake accounts. However, they are unavailable in the Data Marketplace, as the question asks for. ",https://other-docs.snowflake.com/collaboration/collaboration-marketplace-about,,Data Protection and Data Sharing
701,The COPY INTO command can unload data from a table directly into which locations? (Choose two.),"C,E",A network share on a client machine,A Snowpipe REST endpoint,A named external stage that references an external cloud location,A local directory or folder on a client machine,A named internal stage,,,https://docs.snowflake.com/en/sql-reference/sql/copy-into-location,,Data Transformations
702,"A user executes the following SQL query:

    create table SALES_BKP like SALES;

What are the cost implications for processing this query?",C,Storage costs will be generated based on the size of the data.,Processing costs will be generated based on how long the query takes.,No costs will be incurred as the query will use metadata.,The cost for running the virtual warehouse will be charged by the second.,,,CREATE TABLE … LIKE (creates an empty copy of an existing table),https://docs.snowflake.com/en/sql-reference/sql/create-table,,Data Transformations
703,"By default, how many inbound share(s) have every Snowflake account?",A,"Two, the ACCOUNT_USAGE and the SAMPLE_DATA shares.","Two, the ACCOUNT_USAGE and the INFORMATION shares.","One, the ACCOUNT_USAGE share.","Three, the ACCOUNT_USAGE, the DATA, and the INFORMATION shares.",,,Snowflake shares metadata information about the usage of your account in the ACCOUNT_USAGE share. You can also access different sample datasets for learning and testing Snowflake’s functionalities with the SAMPLE_DATA share. You can see them in the Snowflake UI if you have enough privileges.,"https://docs.snowflake.com/en/user-guide/sample-data, https://docs.snowflake.com/en/sql-reference/snowflake-db",,"Snowflake AI Data Cloud Features and Architecture, Data Transformations"
704,To which entity do we grant privileges?,A,Roles.,Account.,Users.,Groups.,,,"Privileges are granted to roles, and roles are granted to users.",https://docs.snowflake.com/en/sql-reference/sql/grant-privilege,,Data Transformations
705,Which functionality is not provided by the query profile?,B,Statistics for each component of the query.,Hints for improving the query performance.,Graphical representation of the main components of the processing plan of the query.,Details and statistics for the overall query.,,,"You can see the query profiler in the following picture. We can see the graphical representation of the components and some statistics for the overall query and for each component of the query. Still, unfortunately, there are no hints to improve it, so we need to become good Snowflake developers to spot bottlenecks by ourselves!",https://docs.snowflake.com/en/user-guide/ui-snowsight-activity#label-snowsight-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
706,"When unloading data to an external stage, which compression format can be used for Parquet files with the COPY INTO command?",B,ZSTD,LZO,BROTLI,GZIP,,,,https://docs.snowflake.com/en/sql-reference/sql/copy-into-location#type-parquet,,Data Transformations
707,"Which Snowflake table is an implicit object layered on a stage, where the stage can be either internal or external?",A,Directory table,Temporary table,A table with a materialized view,Transient table,,,"A directory table is a Snowflake table that is an implicit object layered on a stage, where the stage can be either internal or external. A directory table allows querying the metadata and contents of the files in the stage using standard SQL statements.",https://docs.snowflake.com/en/user-guide/data-load-dirtables,,Data Loading and Unloading
708,What is the impact on queries that are being executed when a resource monitor set to the “Notify & Suspend” threshold level is exceeded?,D,All statements being executed are cancelled.,All statements being executed are queued.,All statements being executed are restarted.,All statements being executed are completed.,,,"-Notify & Suspend: Send a notification (to all account administrators with notifications enabled) and suspend all assigned warehouses after all statements being executed by the warehouse(s) have completed.\n
-Notify & Suspend Immediately: Send a notification (to all account administrators with notifications enabled) and suspend all assigned warehouses immediately, which cancels any statements being executed by the warehouses at the time.",https://docs.snowflake.com/en/user-guide/resource-monitors,,Performance Concepts
709,Which statements are true concerning Snowflake’s underlying cloud infrastructure? (Choose three.),"B,C,F",Snowflake data and services are deployed in a single availability zone within a cloud provider’s region.,Snowflake data and services are deployed in at least three availability zones within a cloud provider’s region.,Snowflake uses the core compute and storage services of each cloud provider for its own compute and storage.,Snowflake data and services are available in a single cloud provider and a single region; the use of multiple cloud providers is not supported.,Snowflake can be deployed in a customer’s private cloud using the customer’s own compute and storage resources for Snowflake compute and storage.,"All three layers of Snowflake’s architecture (storage, compute, and cloud services) are deployed and managed entirely on a selected cloud platform.","Snowflake is provided as Software-as-a-Service (SaaS) that runs completely on cloud infrastructure. This means that all three layers of Snowflake’s architecture (storage, compute, and cloud services) are deployed and managed entirely on a selected cloud platform. In addition, Snowflake’s virtual warehouses and cloud services layers are similarly deployed across three availability zones in a region.","https://docs.snowflake.com/en/user-guide/intro-cloud-platforms,
https://developers.snowflake.com/wp-content/uploads/2021/06/Snowflake-High-Availability-for-Data-Apps-Whitepaper.pdf",,Snowflake AI Data Cloud Features and Architecture
710,Masking policies can be applied to which of the following Snowflake objects? (Choose two.),"A,E",A table,A User-Defined Function (UDF),A stream,A pipe,A materialized view,A stored procedure,"In Snowflake, masking policies are schema-level objects, which means a database and schema must exist in Snowflake before a masking policy can be applied to a column. Currently, Snowflake supports using Dynamic Data Masking on tables and views.",https://docs.snowflake.com/en/user-guide/security-column-intro#apply-a-conditional-masking-policy-on-a-column,,Data Protection and Data Sharing
711,"If all virtual warehouse resources are maximized while processing a query workload, what will happen to new queries that are submitted to the warehouse?",C,All queries will terminate when the resources are maximized.,The warehouse will move to a suspended state.,New queries will be queued and executed when capacity is available.,The warehouse will scale out automatically,,,The keyword here maximized means MIN_CLUSTER_COUNT = MAX_CLUSTER_COUNT,https://docs.snowflake.com/en/user-guide/performance-query-warehouse-queue,,Performance Concepts
712,Which command should be used to look into the validity of an XML object in Snowflake?,A,CHECK_XML,PARSE_XML,XMLGET,TO_XML,,,"CHECK_XML: Checks the validity of an XML document. If the input string is NULL or a valid XML document, the output is NULL. In case of an XML parsing error, the output string contains the error message.",https://docs.snowflake.com/en/sql-reference/functions/check_xml,,Data Transformations
713,Which account usage view in Snowflake can be used to identify the most-frequently accessed tables?,A,Access_History,Tables,Object_Dependencies,Table_Storage_Metrics,,,"The Access_History view in Snowflake can be used to identify the most frequently accessed tables. This view contains information about the historical access patterns for tables and views in your Snowflake account, including details on queries, users, and access frequency. By querying this view, you can analyze which tables are being accessed most frequently in your Snowflake environment.",https://docs.snowflake.com/en/user-guide/access-history,,Account Access and Security
714,Which programming languages are supported for Snowflake User-Defined Functions (UDFs)? (Choose two.),"A,C",Python,TypeScript,JavaScript,C#,PHP,,,https://docs.snowflake.com/en/sql-reference/udf-overview#supported-languages,,Data Transformations
715,Which SQL command can be used to verify the privileges that are granted to a role?,A,SHOW GRANTS TO ROLE,SHOW GRANTS FOR ROLE,SHOW ROLES,SHOW GRANTS ON ROLE,,,,https://docs.snowflake.com/en/sql-reference/sql/show-grants,,Data Transformations
716,"Which command will fail if you have a table created with the following DDL query?

    CREATE TABLE MYTABLE 
	    (ID INTEGER, NAME VARCHAR)",C,SELECT * FROM “MYTABLE”,SELECT * FROM MYTABLE,SELECT * FROM “Mytable”,SELECT * FROM Mytable,,,"If you use the symbol "" "", you have to specify the exact name of the table.","https://docs.snowflake.com/en/sql-reference/sql/create-table#required-parameters, https://docs.snowflake.com/en/sql-reference/identifiers-syntax",,Data Transformations
717,"We want to generate a JSON object with the data from a table called users_table, composed of two columns (AGE and NAME), ordered by the name column. How can we do it?",B,"SELECT object_deconstruct(*) as users_object
FROM users_table
order by users_object[‘NAME’];","SELECT object_construct(*) as users_object
FROM users_table
order by users_object[‘NAME’];","SELECT to_json_object(*) as users_object
FROM users_table
order by users_object[‘NAME’];","SELECT to_object(*) as users_object
FROM users_table
order by users_object[‘NAME’];",,,The OBJECT_CONSTRUCT command returns an OBJECT constructed from the arguments.,https://docs.snowflake.com/en/sql-reference/data-types-semistructured#characteristics-of-an-object-value,,Data Transformations
718,What will happen to ALTER a column setting it to NOT NULL if it contains NULL values?,B,Snowflake deletes the rows with NULL values.,Snowflake returns an error.,"NULL values are changed to an empty string "" """,NULL values are changed to 0.,,,"When setting a column to NOT NULL, if the column contains NULL values, an error is returned and no changes are applied to the column. This restriction prevents inconsistency between values in rows inserted before the column was added and rows inserted after the column was added.",https://docs.snowflake.com/en/sql-reference/sql/alter-table-column#usage-notes,,Data Transformations
719,What is a responsibility of Snowflake’s virtual warehouses?,B,Infrastructure management,Query execution,Management of the storage layer,Query parsing and optimization,Metadata management,,"A warehouse provides the required resources, such as CPU, memory, and temporary storage, to perform the following operations in a Snowflake session:\n
-Executing SQL SELECT statements that require compute resources (e.g. retrieving rows from tables and views).\n
Performing DML operations, such as:\n
--Updating rows in tables\n
--Loading data into tables\n
--Unloading data from tables",https://docs.snowflake.com/en/user-guide/intro-key-concepts#query-processing,,Snowflake AI Data Cloud Features and Architecture
720,Which Snowflake tool is recommended for data batch processing?,D,The Snowflake API,Snowsight,SnowCD,SnowSQL,,,"SnowSQL is the command line client for connecting to Snowflake to execute SQL queries and perform all DDL and DML operations, including loading data into and unloading data out of database tables.\n

Snowsight is the snowflake web interface.\n

SnowCD (i.e. Snowflake Connectivity Diagnostic Tool) helps users to diagnose and troubleshoot their network connection to Snowflake.\n

The Snowflake SQL API is a REST API that you can use to access and update data in a Snowflake database.",https://docs.snowflake.com/en/user-guide/snowsql,,Snowflake AI Data Cloud Features and Architecture
721,Which privileges does a role need to clone a table? (Choose two.),"B,E",CREATE privilege on the source table.,USAGE privilege on the schema of the source table.,SELECT privilege on the database of the source table.,SHARE privilege on the database of the source table.,SELECT privilege on the source table.,,"Your current role must have SELECT privilege on the source table to create a clone. In addition, to clone a schema or an object within a schema, you’d need privileges on the container object(s) for both the source and the clone. You’d need the OWNERSHIP privilege for pipes, streams, and tasks.",https://docs.snowflake.com/en/sql-reference/sql/create-clone#general-usage-notes,,Data Transformations
722,What is the recommended file size for the best load performance and to avoid size limitations?,B,Files shouldn’t exceed 100-250 MB (or larger) in size uncompressed.,Files shouldn’t exceed 100-250 MB (or larger) in size compressed.,Files shouldn’t exceed 10-100 MB (or larger) in size compressed.,Files shouldn’t exceed 10-100 MB (or larger) in size uncompressed.,,,"This is the best size to get the best load performance. Suppose you still have to load a big file, for example, 100GB. In that case, you should carefully consider the ON_ERROR copy option value, as there is a maximum allowed duration of 24 hours, and the operation could be aborted without any portion of the file being committed.",https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare#general-file-sizing-recommendations,,Data Loading and Unloading
723,What role has the privileges to create and manage data shares by default?,D,SYSADMIN,SECURITYADMIN,USERADMIN,ACCOUNTADMIN,,,"By default, the privileges required to create and manage shares are granted only to the ACCOUNTADMIN role, ensuring that only account administrators can perform these tasks.",https://docs.snowflake.com/en/user-guide/security-access-privileges-shares,,"Data Protection and Data Sharing, Account Access and Security"
724,What is a characteristic of the maintenance of a materialized view?,B,A materialized view can be set up with the auto-refresh feature using the SQL SET command.,A materialized view is automatically refreshed by a Snowflake managed warehouse.,Materialized views cannot be refreshed automatically.,An additional set of scripts is needed to refresh data in materialized views.,,,Materialized views are automatically and transparently maintained by Snowflake. A background service updates the materialized view after changes are made to the base table. This is more efficient and less error-prone than manually maintaining the equivalent of a materialized view at the application level.,https://docs.snowflake.com/en/user-guide/views-materialized,,Performance Concepts
725,When can a newly configured virtual warehouse start running SQL queries?,B,After 50% of the warehouse provisioning has completed,When the warehouse provisioning is completed,During the time slots defined by the ACCOUNTADMIN,After the warehouse replication is completed,,,"Snowflake does not begin executing SQL statements submitted to a warehouse until all of the compute resources for the warehouse are successfully provisioned, unless any of the resources fail to provision.",https://docs.snowflake.com/en/user-guide/warehouses-tasks#,,Performance Concepts
726,Which type of charts are supported by Snowsight? (Choose two.),"A,B",Line charts,Scatterplots,Flowcharts,Pie charts S3,Gantt charts,,"Snowsight supports the following types of charts:\n
-Bar charts\n
-Line charts\n
-Scatterplots\n
-Heat grids\n
-Scorecards",https://docs.snowflake.com/en/user-guide/ui-snowsight-visualizations,,Snowflake AI Data Cloud Features and Architecture
727,What is the maximum size supported by the VARIANT column?,C,128 MB.,64 MB.,16 MB.,8 MB.,,,"The VARIANT data type imposes a 16 MB size limit on individual rows. If the data exceeds 16 MB, enable the STRIP_OUTER_ARRAY file format option for the COPY INTO <table> command to remove the outer array structure and load the records into separate table rows.",https://docs.snowflake.com/en/user-guide/semistructured-considerations#data-size-limitations,,Data Loading and Unloading
728,The Query Profile in the image is for a query executed in Snowsight. Four of the key nodes are highlighted in yellow. Which highlighted node will be the MOST expensive?,A,TableScan[3],TableScan[2],Aggregate[1],Join[5],,,"This image illustrates a que Operator Tree of a Query profile.\n

The tree provides a graphical representation of the operator nodes that comprise a query and the links that connect each operator. Operators are the functional building blocks of a query. They are responsible for different aspects of data management and processing, including data access, transformations and updates. Each operator node in the tree includes some basic attributes:\n

<Type> [#]\n
Operator type and ID number. ID can be used to uniquely identify an operator within a query profile (e.g. Aggregate [1] and Join [5] in the screenshot above).\n

Percentage\n
Fraction of time that this operator consumed within the query step (e.g. 53.4% for TableScan[3]). This information is also reflected in the bar at the bottom of the operator node, allowing for easy visual identification of performance-critical operators.\n

Label\n
Operator-specific additional information.\n
Links represent the data flowing between each operator node. Each link provides the number of records that were processed.\n

Therefore, we can conclude that it is the node TableScan[3] that has the highest percentage of time.",https://docs.snowflake.com/en/user-guide/ui-query-profile,https://i.imgur.com/vQhz5h4.png,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
729,"In addition to performing all the standard steps to share data, which privilege must be granted on each database referenced by a secure view in order to be shared?",A,REFERENCE_USAGE,USAGE,REFERENCES,READ,,,"You must grant the REFERENCE_USAGE privilege separately on each database referenced in a secure view, before granting the secure view to a share.",https://docs.snowflake.com/en/user-guide/data-sharing-multiple-db,,Data Protection and Data Sharing
730,Which command should be used to implement a masking policy that was already created in Snowflake?,A,SET MASKING POLICY,APPLY MASKING POLICY,CREATE MASKING POLICY,ALTER MASKING POLICY,,,"ALTER TABLE <name> { ALTER | MODIFY } COLUMN <col1_name> SET MASKING POLICY <policy_name> [ USING ( <col1_name> , cond_col_1 , .. ) ]",https://docs.snowflake.com/en/sql-reference/sql/alter-table-column#syntax,,Data Transformations
731,Which of the following SQL statements will list the version of the drivers currently being used?,A,Execute SELECT CURRENT_CLIENT(); from an application,Execute SELECT CURRENT_JDBC_VERSION(); from SnowSQL,Execute SELECT CURRENT_ODBC_CLIENT(); from the Web UI,Execute SELECT CURRENT_VERSION(); from the Python Connector,,,CURRENT_CLIENT() -- name and version of connected client CURRENT_VERSION() -- version of Snowflake,https://docs.snowflake.com/en/sql-reference/functions/current_client,,Data Transformations
732,Which of the following operations require the use of a running virtual warehouse? (Choose two.),"D,E",Altering a table,Listing files in a stage,Downloading data from an internal stage,Querying data from a materialized view,Executing a stored procedure,,,https://docs.snowflake.com/en/user-guide/warehouses,,Performance Concepts
733,"In a managed access schema, who can grant privileges on objects in the schema to other roles? (Choose two.)","B,C",The USERADMIN system role,The role with the MANAGE GRANTS privilege,The schema owner role,The role that owns the object in the schema,The ORGADMIN system role,,"In managed access schemas, object owners lose the ability to make grant decisions. Only the schema owner or a role with the MANAGE GRANTS privilege can grant privileges on objects in the schema, including future grants, centralizing privilege management.",https://docs.snowflake.com/en/user-guide/security-access-control-overview,,Account Access and Security
734,Which commands support a multiple-statement request to access and update Snowflake data? (Choose two.),"A,C",ROLLBACK,GET,COMMIT,CALL,PUT,,"A transaction is a sequence of SQL statements that are processed as an atomic unit. All statements in the transaction are either applied (i.e. committed) or undone (i.e. rolled back) together. Snowflake transactions guarantee ACID properties.\n

A transaction can be ended explicitly by executing COMMIT or ROLLBACK. Snowflake supports the synonym COMMIT WORK for COMMIT, and the synonym ROLLBACK WORK for ROLLBACK.",https://docs.snowflake.com/en/sql-reference/transactions,,Data Transformations
735,What privilege is needed for a Snowflake user to see the definition of a secure view?,B,MODIFY,OWNERSHIP,USAGE,CREATE,,,"The definition of a secure view is only exposed to authorized users (i.e. users who have been granted the role that owns the view). However, users that have been granted IMPORTED PRIVILEGES privilege on the SNOWFLAKE database or another shared database have access to secure view definitions via the VIEWS Account Usage view. Users granted the ACCOUNTADMIN role or the SNOWFLAKE.OBJECT_VIEWER database role can also see secure view definitions via this view. The preferred, least-privileged means of access is the SNOWFLAKE.OBJECT_VIEWER database role.",https://docs.snowflake.com/en/user-guide/views-secure,,"Data Protection and Data Sharing, Performance Concepts"
736,Which pipes are cloned when cloning a database or schema?,C,Both.,Pipes that reference internal stages.,Pipes that reference external stages.,Pipes cannot be cloned.,,,"Internal named stages are NEVER cloned, so pipes that reference internal stages are not cloned.",https://docs.snowflake.com/en/user-guide/object-clone#cloning-and-pipes,,Performance Concepts
737,Which data modeling concepts can be used in Snowflake (Choose two.),"A,B",Primary Key.,Foreign Key.,Unique Index.,Non-Unique Index.,Distribution Key.,,"Constraints define integrity and consistency rules for data stored in tables. You can specify a CONSTRAINT clause in a CREATE TABLE or ALTER TABLE statement. A table can have multiple unique keys and foreign keys, but only one primary key. Snowflake supports defining and maintaining constraints, but does not enforce them, except for NOT NULL constraints, which are always enforced. For example:\n
CREATE TABLE MY_TABLE (\n
    col1 INTEGER NOT NULL\n
);",https://docs.snowflake.com/en/sql-reference/constraints,,Data Transformations
738,Who can activate a network policy for users in a Snowflake account? (Choose two.),"C,E",USERADMIN,SYSADMIN,ACCOUNTADMIN,PUBLIC,Any role that has the global ATTACH POLICY privilege,,"Only security administrators (i.e. users with the SECURITYADMIN role) or higher or a role with the global ATTACH POLICY privilege can activate a network policy for an account. Once the policy is associated with your account, Snowflake restricts access to your account based on the allowed list and blocked list.",https://docs.snowflake.com/en/user-guide/network-policies,,Account Access and Security
739,What is the maximum number of clusters in a multi-cluster warehouse?,B,64,10,"Unlimited, there is not a maximum number of clusters.",100,,,"To define a multi-cluster warehouse, the maximum number of clusters has to be greater than 1 (up to 10). Also, the minimum number of clusters must equal to or less than the maximum.",https://docs.snowflake.com/en/user-guide/warehouses-multicluster#what-is-a-multi-cluster-warehouse,,Performance Concepts
740,Which statement accurately describes a characteristic of a materialized view?,A,A materialized view can query only a single table.,Materialized view refreshes need to be maintained by the user.,Data accessed through materialized views can be stale.,Querying a materialized view is slower than executing a query against the base table of the view.,,,"A materialized view can query only a single table.\n

It is recommended to be familiar with the limitations of the materialized views. This is often a common question.",https://docs.snowflake.com/en/user-guide/views-materialized#limitations-on-creating-materialized-views,,Performance Concepts
741,What are the benefits of the replication feature in Snowflake? (Choose two.),"B,E",Data security,Database failover and failback,Time Travel,Fail-safe,Disaster recovery,,,https://docs.snowflake.com/en/user-guide/replication-intro,,Data Protection and Data Sharing
742,What is the purpose of enabling Federated Authentication on a Snowflake account?,D,Allows dual Multi-Factor Authentication (MFA) when connecting to Snowflake,Forces users to connect through a secure network proxy,"Disables the ability to use key pair and basic authentication (e.g., username/password) when connecting",Allows users to connect using secure single sign-on (SSO) through an external identity provider,,,"In a federated environment, user authentication is separated from user access through the use of one or more external entities that provide independent authentication of user credentials. The authentication is then passed to one or more services, enabling users to access the services through SSO.",https://docs.snowflake.com/en/user-guide/admin-security-fed-auth,,Account Access and Security
743,What table functions in the Snowflake Information Schema can be queried to retrieve information about directory tables? (Choose two.),"D,E",EXTERNAL_TABLE_FILE_REGISTRATION_HISTORY,MATERIALIZED_VIEW_REFRESH_HISTORY,EXTERNAL_TABLE_FILES,STAGE_DIRECTORY_FILE_REGISTRATION_HISTORY,AUTO_REFRESH_REGISTRATION_HISTORY,,"AUTO_REFRESH_REGISTRATION_HISTORY: Retrieve the history of data files registered in the metadata of specified objects and the credits billed for these operations. STAGE_DIRECTORY_FILE_REGISTRATION_HISTORY: Retrieve information about the metadata history for a directory table, including any errors found when refreshing the metadata.",https://docs.snowflake.com/en/user-guide/data-load-dirtables,,Data Loading and Unloading
744,"According to Snowflake best practice recommendations, which role should be used to create databases?",C,SECURITYADMIN,ACCOUNTADMIN,SYSADMIN,USERADMIN,,,"The system administrator (SYSADMIN) role includes the privileges to create warehouses, databases, and all database objects (schemas, tables, etc.).",https://docs.snowflake.com/en/user-guide/security-access-control-considerations,,Account Access and Security
745,Any user with the appropriate privileges can view data storage for individual tables by using which queries? (Choose two.),"C,D",METERING_HISTORY view in the ACCOUNT_USAGE schema,METERING_DAILY_HISTORY view in the ORGANIZATION_USAGE schema,TABLE_STORAGE_METRICS view in the INFORMATION_SCHEMA schema,TABLE_STORAGE_METRICS view in the ACCOUNT_USAGE schema,STORAGE_USAGE view in the ACCOUNT_USAGE schema,,Any user with the appropriate privileges can view data storage for individual tables. Snowflake provides the following methods for viewing table data storage:,https://docs.snowflake.com/en/user-guide/tables-storage-considerations,,Performance Concepts
746,What is the maximum time that Snowflake can run a query?,C,1 day.,Unlimited.,7 days.,2 days.,,,"The default value for the command “STATEMENT_TIMEOUT_IN_SECONDS” is 172800 seconds, which is two days, but the maximum time we can configure is seven days.",https://docs.snowflake.com/en/sql-reference/parameters#statement-timeout-in-seconds,,Data Transformations
747,"There are two Snowflake accounts in the same cloud provider region: one is production and the other is non-production.

How can data be easily transferred from the production account to the non-production account?",B,Clone the data from the production account to the non-production account.,Create a data share from the production account to the non-production account.,Create a reader account using the production account and link the reader account to the non-production account.,Create a subscription in the production account and have it publish to the non-production account.,,,"Keyword is ""account"" which means a share is the appropriate answer. To share to another account, a share is required. A cloned object can be shared to another account but also via a share. Reader account isn't applicable because it's referring to 2 Snowflake accounts.",https://docs.snowflake.com/en/user-guide/data-sharing-intro,,Data Protection and Data Sharing
748,Which command is used to unload data from a Snowflake table to an external stage?,D,GET,COPY INTO followed by PUT,COPY INTO followed by GET,COPY INTO,,,Use the COPY INTO <location> command to copy the data from the Snowflake database table into one or more files in a Snowflake stage.,https://docs.snowflake.com/en/user-guide/data-unload-snowflake,,Data Loading and Unloading
749,Which of the following roles are recommended to create and manage users and roles? (Choose two.,"B,D",PUBLIC,USERADMIN,ACCOUNTADMIN,SECURITYADMIN,SYSADMIN,,,https://docs.snowflake.com/en/user-guide/security-access-control-overview#roles,,Account Access and Security
750,How many cluster keys can we create for a Snowflake table?,C,A maximum of three or four cluster keys.,Two.,One.,Unlimited.,,,"You can enable clustering on specific tables by specifying ONE clustering key for each table. We can only create one cluster key, but we can have several columns or expressions in that cluster key.",https://docs.snowflake.com/en/user-guide/tables-clustering-keys,,Performance Concepts
751,What is it called when a customer managed key is combined with a Snowflake managed key to create a composite key for encryption?,B,Client-side encryption,Tri-secret secure encryption,Key pair authentication,Hierarchical key model,,,Tri-Secret Secure is the combination of a Snowflake-maintained key and a customer-managed key in the cloud provider platform that hosts your Snowflake account to create a composite master key to protect your Snowflake data.,https://docs.snowflake.com/en/user-guide/security-encryption-manage,,Data Protection and Data Sharing
752,Which of these commands require a running warehouse?,A,"SELECT *
FROM USERS_TABLE
WHERE email=’test@test.com’;","EXPLAIN USING TABULAR
SELECT *
FROM USERS_TABLE
WHERE email=’test@test.com’;","SELECT MAX(AGE)
FROM USERS_TABLE;","SELECT COUNT(*)
FROM USERS_TABLE;",,,"SELECT MAX and SELECT COUNT are both metadata operations so they don't require a running warehouse. Additionally, this is an excellent example to see the use of the EXPLAIN command, which returns the logical execution plan for the specified SQL statement. An explained plan shows the operations (for example, table scans and joins) that Snowflake would perform to execute the query.\n

Although EXPLAIN does not consume any compute credits, the compilation of the query does consume Cloud Service credits, just as other metadata operations do. The output is the same as the output of the command EXPLAIN_JSON.",https://docs.snowflake.com/en/sql-reference/sql/explain#usage-notes,,Data Transformations
753,Which file function generates a Snowflake-hosted file URL to a staged file using the stage name and relative file path as inputs?,B,GET_ABSOLUTE_PATH,BUILD_STAGE_FILE_URL,GET_STAGE_LOCATION,GET_RELATIVE_PATH,,,"BUILD_STAGE_FILE_URL Generates a Snowflake-hosted file URL to a staged file using the stage name and relative file path as inputs. A file URL permits prolonged access to a specified file. That is, the file URL does not expire.",https://docs.snowflake.com/en/sql-reference/functions/build_stage_file_url,,Data Transformations
754,"Which roles can create, alter or drop network policies? (Choose two.)","B,C",ORGADMIN,SECURITYADMIN.,ACCOUNTADMIN.,SYSADMIN.,USERADMIN.,,"Network policies allow restricting access to your account based on user IP address. Snowflake applies the blocked IP address list when a network policy includes values in both the allowed and blocked IP address lists.\n

Only security administrators (i.e., users with the SECURITYADMIN role) or higher or a role with the global CREATE NETWORK POLICY privilege can create network policies.\n

Only the network policy owner (i.e., role with the OWNERSHIP privilege on the network policy) or higher can alter a network policy.",https://docs.snowflake.com/en/user-guide/network-policies#about-network-policies,,Account Access and Security
755,After how many hours does Snowflake cancel our running SQL statement by default?,D,24 hours.,10 hours.,1 hour.,48 hours.,,,"The DEFAULT value for the command “STATEMENT_TIMEOUT_IN_SECONDS” is 172800 seconds, which is 48 hours. A query constantly running can be dangerous, so Snowflake kills it in 48 hours. The maximum timeout is 604800 seconds or 7 days.",https://docs.snowflake.com/en/sql-reference/parameters#statement-timeout-in-seconds,,Data Transformations
756,What are the two models that Snowflake combines as an approach to access control?,B,DAC & ABAC.,DAC & RBAC.,MAC & RBAC.,MAC & ABAC.,,,"Snowflake combines Discretionary Access Control (DAC) and Role-Based Access Control (RBAC). Discretionary Access Control (DAC) remarks that ""each object has an owner, who can, in turn, grant access to that object"". In contrast, the Role-based Access Control (RBAC) remarks that ""access privileges are assigned to roles, which are in turn assigned to users"".",https://docs.snowflake.com/en/user-guide/security-access-control-overview,,Account Access and Security
757,What actions will prevent leveraging of the ResultSet cache?,B,If the result has not been reused within the last 12 hours,Removing a column from the query SELECT list,Stopping the virtual warehouse that the query is running against,Executing the RESULTS_SCAN() table function,,,,https://docs.snowflake.com/en/user-guide/querying-persisted-results#retrieval-optimization,,Performance Concepts
758,"A user created a database and set the DATA_RETENTION_TIME_IN_DAYS to 30, but did not set the DATA_RETENTION_TIME_IN_DAYS in table T1. After 5 days, the user accidentally drops table T1. What are the considerations for recovering table T1?",D,The table can only be recovered by contacting Snowflake Support to recover the table from Fail-safe.,The user can recover the table T1 after 30 days.,The table cannot be recovered because the DATA_RETENTION_TIME_IN_DAYS was not set for table T1.,The table can be recovered because the table retention period default is at the database level.,,,"By default, the maximum retention period is 1 day (i.e. one 24 hour period). With Snowflake Enterprise Edition (and higher), the default for your account can be set to any value up to 90 days:\n
-When creating a table, schema, or database, the account default can be overridden using the DATA_RETENTION_TIME_IN_DAYS parameter in the command.\n
-If a retention period is specified for a database or schema, the period is inherited by default for all objects created in the database/schema.",https://docs.snowflake.com/en/user-guide/data-time-travel,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
759,Which of the following query profiler variables will indicate that a virtual warehouse is not sized correctly for the query being executed?,A,Remote spillage,Initialization,Bytes sent over the network,Synchronization,,,"For some operations (e.g. duplicate elimination for a huge data set), the amount of memory available for the compute resources used to execute the operation might not be sufficient to hold intermediate results. As a result, the query processing engine will start spilling the data to local disk. If the local disk space is not sufficient, the spilled data is then saved to remote disks.",https://docs.snowflake.com/en/user-guide/ui-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
760,Which features make up Snowflake's column level security? (Choose two.),"A,D",Dynamic Data Masking,Row access policies,Key pair authentication,External Tokenization,Continuous Data Protection (CDP),,,https://docs.snowflake.com/en/user-guide/security-column,,Data Protection and Data Sharing
761,What technique does Snowflake use to limit the number of micro-partitions scanned by each query?,B,B-tree,Pruning,Indexing,Map reduce,,,,https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
762,Which service or feature in Snowflake is used to improve the performance of certain types of lookup and analytical queries that use an extensive set of WHERE conditions?,B,Data classification,Search optimization service,Query acceleration service,Tagging,,,The search optimization service can significantly improve the performance of certain types of lookup and analytical queries that use an extensive set of predicates for filtering.,"https://docs.snowflake.com/en/user-guide/search-optimization-service, https://www.snowflake.com/blog/now-generally-available-snowflakes-search-optimization-service-accelerates-queries-dramatically",,"Performance Concepts, Snowflake AI Data Cloud Features and Architecture"
763,"How can a Snowflake user access a JSON object, given the following table? (Choose two.)","B,D",SRC:salesPerson.Name,src:salesPerson.name,src:salesperson.name,SRC:salesPerson.name,src:salesPerson.Name,,"Regardless of which notation you use, the column name is case-insensitive but element names are case-sensitive.\n

For example, in the following list, the first two paths are equivalent, but the third is not:\n
src:salesperson.name\n
SRC:salesperson.name\n
SRC:Salesperson.Name\n",https://docs.snowflake.com/en/user-guide/querying-semistructured,https://i.imgur.com/GQsbLCU.png,Performance Concepts
764,What statements are true about the Snowflake Monitoring Page? (Choose two.),"B,C",You cannot see the queries of other users.,You cannot see the results of other users.,The History page allows you to view and drill into the details of all queries executed in the last 14 days.,The History page allows you to view and drill into the details of all queries executed in the last 24 days.,You can see the results of other users.,,"You can view results only for queries you have executed. You can also see other users’ queries but cannot see their results. If you have privileges to view queries executed by another user, the Query Detail page displays the details for the query, but it won't show the actual query result.\n

However, if you have the same role, perform the same query, and the data has not changed, you'll use the Query Result Cache and get the same result. In this example, you can see the execution of a query that uses the Query Results Cache, only spending 141ms to be executed.","https://docs.snowflake.com/en/user-guide/ui-snowsight-navigation#overview-of-the-new-navigation, https://docs.snowflake.com/user-guide/ui-snowsight-activity#review-query-history-by-using-snowsight",,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
765,Which Snowflake object stores DML change made to tables and metadata about each change?,C,Pipes.,Account Streams.,Table Streams.,Tables.,,,"Streams are Snowflake objects that record data manipulation language (DML) changes made to tables and views, including INSERTS, UPDATES, and DELETES, as well as metadata about each change. A stream can also be referred to as a “table stream”.",https://docs.snowflake.com/en/user-guide/streams-intro,,Data Loading and Unloading
766,Which role in Snowflake allows a user to enable replication for multiple accounts?,D,SYSADMIN,ACCOUNTADMIN,SECURITYADMIN,ORGADMIN,,,,https://docs.snowflake.com/en/user-guide/database-replication-config,,Data Protection and Data Sharing
767,Which command can we use to query the table <my_table> as it was 15 minutes ago?,C,"SELECT *
FROM my_table
AT(offset => 15);","SELECT *
FROM my_table
AT(offset => -3600*15);","SELECT *
FROM my_table
AT(offset => -60*15);","We should’ve created a backup of that table. Otherwise, we are not able to do it.",,,"Thanks to the Time Travel functionality, it’s possible to query a table as it was some time ago. We need to put the time in seconds as the offset parameter, in this case, 15 minutes * 60. We'll add the “-” symbol as we are querying in the past.","https://docs.snowflake.com/en/sql-reference/constructs/at-before#parameters, https://docs.snowflake.com/en/user-guide/data-time-travel",,"Data Transformations, Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
768,Which command will use warehouse credits?,C,"SELECT MIN(ID)
FROM MYTABLE","SELECT MAX(ID)
FROM MYTABLE","SELECT MAX(ID)
FROM MYTABLE
GROUP BY ID","SELECT COUNT(*)
FROM MYTABLE",,,"MIN, MAX, and COUNT queries use the metadata cache as they are metadata stored in each micro-partition, however using GROUP BY will require using warehouse credits as that is not a metadata operation.",https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#what-are-micro-partitions,,Performance Concepts
769,"When data is loaded into Snowflake, what formats does Snowflake use internally to store the data in cloud storage? (Choose two.)","A,E",Compressed,Key-value,Document,Graph,Columnar,,"When data is loaded into Snowflake, Snowflake reorganizes that data into its internal optimized, compressed, columnar format.\n

Typical question about how Snowflake stores information (key concept).",https://docs.snowflake.com/en/user-guide/intro-key-concepts,,Snowflake AI Data Cloud Features and Architecture
770,How many credits will consume a medium-size warehouse with 2 clusters running in maximized mode for 3 hours?,B,32,24,8,16,,,"A medium size warehouse with one cluster consumes four credits per hour. As we have two clusters, it will consume eight credits per hour. In three hours, it will consume 24 credits.",https://docs.snowflake.com/en/user-guide/warehouses-overview#warehouse-size,,Performance Concepts
771,A task is still being executed before the next scheduled task. What is going to happen with the new scheduled task?,D,Snowflake will abort it.,Snowflake will execute it.,Snowflake will wait for the previous task to complete.,Snowflake will skip it.,,,"Snowflake ensures that only one instance of a task with a schedule is executed at a given time. If a task is still running when the next scheduled execution time occurs, then that scheduled time is skipped.",https://docs.snowflake.com/en/user-guide/tasks-intro#task-scheduling,,Performance Concepts
772,Which privilege is required on a virtual warehouse to abort any existing executing queries?,B,MODIFY,OPERATE,MONITOR,USAGE,,,"OPERATE: Enables changing the state of a warehouse (stop, start, suspend, resume). In addition, enables viewing current and past queries executed on a warehouse and aborting any executing queries.",https://docs.snowflake.com/en/user-guide/security-access-control-privileges#virtual-warehouse-privileges,,Account Access and Security
773,What are potential impacts of storing non-native values like dates and timestamps in a VARIANT column in Snowflake?,B,Faster query performance and increased storage consumption,Slower query performance and increased storage consumption,Slower query performance and decreased storage consumption,Faster query performance and decreased storage consumption,,,"For non-native data (such as dates and timestamps), the values are stored as strings when loaded into a VARIANT column. Therefore, operations on these values could be slower and also consume more space than when stored in a relational column with the corresponding data type.",https://docs.snowflake.com/en/sql-reference/data-types-semistructured,,Data Transformations
774,Which command can we use to refresh a materialized view?,C,DROP VIEW <view>;,CREATE MATERIALIZED VIEW <view>;,Materialized views are automatically refreshed by Snowflake.,ALTER MATERIALIZED_VIEW <view> REFRESH=TRUE,RESTART MATERIALIZED_VIEW <view>,,"Snowflake automatically and transparently maintains materialized views. To see the last time that Snowflake refreshed a materialized view, check the REFRESHED_ON and BEHIND_BY columns in the output of the command SHOW MATERIALIZED VIEWS.",https://docs.snowflake.com/en/user-guide/views-materialized#understanding-how-materialized-views-are-maintained,,Performance Concepts
775,"For a multi-cluster virtual warehouse, which parameters are used to calculate the number of credits billed? (Choose two.)","A,C",Warehouse size,Volume of data processed,Number of clusters,Cache size,Number of queries executed,,,https://docs.snowflake.com/en/user-guide/warehouses-overview,,Performance Concepts
776,"To add or remove search optimization for a table, a user must have which of the following privileges or roles? (Choose two.)","C,D",The SELECT privilege on the table,A SECURITYADMIN role,The OWNERSHIP privilege on the table,The ADD SEARCH OPTIMIZATION privilege on the schema that contains the table,The MODIFY privilege on the table,,"To add, configure, or remove search optimization for a table, you must have the following privileges:\n
-You must have OWNERSHIP privilege on the table.\n
-You must have ADD SEARCH OPTIMIZATION privilege on the schema that contains the table.",https://docs.snowflake.com/en/user-guide/search-optimization-service#what-access-control-privileges-are-needed-for-the-search-optimization-service,,"Performance Concepts, Snowflake AI Data Cloud Features and Architecture"
777,Which parameter allows us to schedule the task_1 to run every day with a CRON expression?,A,SET SCHEDULE,SET INITIALIZATION,SET FIXED_TIME,SET CRON,,,"An example can be:\n
ALTER TASK TASK_1 SET SCHEDULE = 'USING CRON */3 * * * * UTC';",https://docs.snowflake.com/en/sql-reference/sql/alter-task,,Data Transformations
778,Which permission on a Snowflake virtual warehouse allows the role to resize the warehouse?,B,MONITOR,MODIFY,USAGE,ALTER,,,,https://docs.snowflake.com/en/sql-reference/sql/alter-warehouse#access-control-requirements,,Data Transformations
779,A JSON document is stored in the source_column of type VARIANT. The document has an array called elements. The array contains the name key that has a string value. How can a Snowflake user extract the name from the first element?,C,source_column.elements[1]:name,source_column.elements[0]:name,source_column:elements[0].name,source_column:elements[1].name,,,It is important to be familiar with the syntax for querying semi-structured data.,https://docs.snowflake.com/en/user-guide/querying-semistructured,,Performance Concepts
780,Which function should be used to insert JSON formatted string data into a VARIANT field?,D,TO_VARIANT,CHECK_JSON,FLATTEN,PARSE_JSON,,,"PARSE_JSON: Interprets an input string as a JSON document, producing a VARIANT value.",https://docs.snowflake.com/en/sql-reference/functions/parse_json,,Data Transformations
781,Which command can we use to access sequences in queries as expressions?,D,<seq_name>.CURRENTVAL,<seq_name>.THISVAL,<seq_name>.GETVAL,<seq_name>.NEXTVAL,,,"We use sequences to generate unique numbers across sessions and statements, including concurrent statements. You can use them to generate values for a primary key or any column that requires a unique value.",https://docs.snowflake.com/en/user-guide/querying-sequences#sequences-as-expressions,,Performance Concepts
782,"When unloading data to an external stage, what is the MAXIMUM file size supported?",D,16 GB,10 GB,1 GB,5 GB,,,"By default, COPY INTO location statements separate table data into a set of output files to take advantage of parallel operations. The maximum size for each file is set using the MAX_FILE_SIZE copy option. The default value is 16777216 (16 MB) but can be increased to accommodate larger files. The maximum file size supported is 5 GB for Amazon S3, Google Cloud Storage, or Microsoft Azure stages.",https://docs.snowflake.com/en/user-guide/data-unload-considerations#,,Data Loading and Unloading
783,What service is provided as an integrated Snowflake feature to enhance Multi-Factor Authentication (MFA) support?,C,Okta,Single Sign-On (SSO),Duo Security,OAuth,,,"MFA provides increased login security for users connecting to Snowflake. MFA support is provided as an integrated Snowflake feature, powered by the Duo Security service, which is managed completely by Snowflake.",https://docs.snowflake.com/en/user-guide/ui-snowsight-profile,,Snowflake AI Data Cloud Features and Architecture
784,What is the effect of configuring a virtual warehouse auto-suspend value to ‘0’?,C,All clusters in the multi-cluster warehouse will resume immediately.,The warehouse will suspend immediately upon work completion.,The warehouse will never suspend.,The warehouse will not resume automatically.,,,"Specifies the number of seconds of inactivity after which a warehouse is automatically suspended.\n
Any integer 0 or greater, or NULL:\n
Setting a value less than 60 is allowed, but may not result in the desired/expected behavior because the background process that suspends a warehouse runs approximately every 60 seconds and, therefore, is not intended for enabling exact control over warehouse suspension.\n
Setting a 0 or NULL value means the warehouse never suspends.",https://docs.snowflake.com/en/sql-reference/sql/alter-warehouse,,Data Transformations
785,What is the PRIMARY factor that determines the cost of using a virtual warehouse in Snowflake?,D,The amount of data stored in the warehouse,The number of tables or databases queried,The type of SQL statements executed,The length of time the compute resources in each cluster run,,,,https://docs.snowflake.com/en/user-guide/cost-understanding-compute,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
786,Which activities are included in the Cloud Services layer? (Choose two.),"B,E",Dynamic data masking,User authentication,Data storage,Partition scanning,Infrastructure management,,"The Cloud Services layer in Snowflake is responsible for critical data-related activities. Services managed in this layer include:\n
-Authentication\n
-Infrastructure management\n
-Metadata management\n
-Query parsing and optimization\n
-Access control",https://docs.snowflake.com/en/user-guide/intro-key-concepts,,Snowflake AI Data Cloud Features and Architecture
787,"When referring to User-Defined Function (UDF) names in Snowflake, what does the term overloading mean?",A,There are multiple SQL UDFs with the same names but with a different number of arguments or argument types.,There are multiple SQL UDFs with different names but the same number of arguments or argument types.,There are multiple SQL UDFs with the same names and the same number of arguments.,There are multiple SQL UDFs with the same names and the same number of argument types.,,,"Snowflake supports overloading procedures and functions. In a given schema, you can define multiple procedures or functions that have the same name but different signatures. The signatures must differ by the number of arguments, the types of the arguments, or both.",https://docs.snowflake.com/developer-guide/udf-stored-procedure-naming-conventions#overloading-procedures-and-functions,,Data Transformations
788,Which key governance feature in Snowflake allows users to identify automatically data objects that contain sensitive data and their related objects?,B,Column-level security,Data classification,Object tagging,Row access policy,,,"Data classification in Snowflake is a feature that allows users to automatically identify and classify columns in their tables containing personal or sensitive data.\n

Data classification is a multi-step process that associates Snowflake-defined tags (i.e. system tags) to columns by analyzing the cells and metadata for personal data.\n

Based on the tracking information and related audit processes, the data engineer can protect the column containing personal or sensitive data with a masking policy or the table containing this column with a row access policy.",https://docs.snowflake.com/en/user-guide/governance-classify-concepts,,"Snowflake AI Data Cloud Features and Architecture, Data Protection and Data Sharing"
789,"The following settings are configured:

THE MIN_DATA_RETENTION_TIME_IN_DAYS is set to 5 at the account level.

THE DATA_RETENTION_TIME_IN_DAYS is set to 2 at the object level.

For how many days will the data be retained at the object level?",B,2,5,7,3,,,"The MIN_DATA_RETENTION_TIME_IN_DAYS account parameter can be set by users with the ACCOUNTADMIN role to set a minimum retention period for the account. This parameter does not alter or replace the DATA_RETENTION_TIME_IN_DAYS parameter value. However it may change the effective data retention time. When this parameter is set at the account level, the effective minimum data retention period for an object is determined by MAX(DATA_RETENTION_TIME_IN_DAYS, MIN_DATA_RETENTION_TIME_IN_DAYS).",https://docs.snowflake.com/en/user-guide/data-time-travel,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
790,Which SQL command can be used to see the CREATE definition of a masking policy?,B,DESCRIBE MASKING POLICY,GET_DDL,SHOW MASKING POLICIES,LIST MASKING POLICIES,,,"GET_DDL returns the create statement to recreate the object.\n

DESCRIBE will show the sql behind the policy but not in the form of a create statement.",https://docs.snowflake.com/en/sql-reference/functions/get_ddl#examples,,Data Transformations
791,Which Snowflake data governance feature can support auditing when a user query reads column data?,B,Column-level security,Access History,Object dependencies,Data classification,,,"Access History in Snowflake refers to when the user query reads data and when the SQL statement performs a data write operation, such as INSERT, UPDATE, and DELETE along with variations of the COPY command, from the source data object to the target data object. The user access history can be found by querying the Account Usage ACCESS_HISTORY view.",https://docs.snowflake.com/en/user-guide/access-history,,Account Access and Security
792,How do secure views compare to non-secure views in Snowflake?,B,Secure views are similar to materialized views in that they are the most performant.,Secure views execute slowly compared to non-secure views.,Non-secure views are preferred over secure views when sharing data.,There are no performance differences between secure and non-secure views.,,,,https://docs.snowflake.com/en/user-guide/views-secure#when-should-i-use-a-secure-view,,"Data Protection and Data Sharing, Performance Concepts"
793,"While attempting to avoid data duplication, which COPY INTO option should be used to load files with expired load metadata?",A,LOAD_UNCERTAIN_FILES,VALIDATION_MODE,FORCE,LAST_MODIFIED,,,"To load files whose metadata has expired, set the LOAD_UNCERTAIN_FILES copy option to true. The copy option references load metadata, if available, to avoid data duplication, but also attempts to load files with expired load metadata.",https://docs.snowflake.com/en/user-guide/data-load-considerations-load,,Data Loading and Unloading
794,Which Snowflake object contains all the information required to share a database?,C,Secure view,Private listing,Share,Sequence,,,Shares are named Snowflake objects that encapsulate all of the information required to share a database.,https://docs.snowflake.com/en/user-guide/data-sharing-intro,,Data Protection and Data Sharing
795,How can a Snowflake user sample 10 rows from a table named SNOWPRO? (Choose two.),"A,C",SELECT * FROM SNOWPRO TABLESAMPLE (10 ROWS),SELECT * FROM SNOWPRO TABLESAMPLE BLOCK (10),SELECT * FROM SNOWPRO SAMPLE BERNOULLI (10 ROWS),SELECT * FROM SNOWPRO SAMPLE SYSTEM (10),SELECT * FROM SNOWPRO TABLESAMPLE BLOCK (10 ROWS),,,https://docs.snowflake.com/en/sql-reference/constructs/sample,,Data Transformations
796,When does a materialized view get suspended in Snowflake?,C,When a DML operation is run on the base table,When a column is added to the base table,When a column is dropped from the base table,When the base table is reclustered,,,"If a base table is altered so that existing columns are changed or dropped, then all materialized views on that base table are suspended.",https://docs.snowflake.com/en/user-guide/views-materialized#dropping-the-base-table,,Performance Concepts
797,Which views are included in the DATA_SHARING_USAGE schema? (Choose two.),"D,E",ACCESS_HISTORY,DATA_TRANSFER_HISTORY,WAREHOUSE_METERING_HISTORY,LISTING_TELEMETRY_DAILY,MONETIZED_USAGE_DAILY,,"You can expect in the exams some strange questions about parameters that are not the most typical ones to use. It is not necessary to know all the parameters available in Snowflake, but it is important that you are at least familiar with the most important ones. In the case of this question, you can approach it by elimination.",https://docs.snowflake.com/en/sql-reference/data-sharing-usage,,Data Protection and Data Sharing
798,On which of the following cloud platforms can a Snowflake account be hosted? (Choose three.),"A,B,D",Microsoft Azure Cloud,Google Cloud Platform,Oracle Cloud,Amazon Web Services,Private Virtual Cloud,Alibaba Cloud,,https://docs.snowflake.com/en/user-guide/intro-cloud-platforms,,Snowflake AI Data Cloud Features and Architecture
799,What information is found within the Statistic output in the Query Profile Overview?,A,Table pruning,Operator tree,Nodes by execution time,Most expensive nodes,,,,https://docs.snowflake.com/en/user-guide/ui-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
800,What are the least privileges needed to view and modify resource monitors? (Choose two.),"A,D",MODIFY,USAGE,SELECT,MONITOR,OWNERSHIP,,"By default, resource monitors can only be created by account administrators and, therefore, can only be viewed and maintained by them.\n

However, roles that have been granted the MONITOR or MODIFY privileges on specific resource monitors can view and modify the resource monitor as needed using SQL",https://docs.snowflake.com/en/user-guide/resource-monitors,,Performance Concepts
801,Which categories are included in the execution time summary in a Query Profile? (Choose two.),"A,E",Local Disk I/O,Spilling,Pruning,Percentage of data read from cache,Initialization,,"Execution time provides information about “where the time was spent” during the processing of a query. Time spent can be broken down into the following categories, displayed in the following order:\n

Processing — time spent on data processing by the CPU.\n
Local Disk IO — time when the processing was blocked by local disk access.\n
Remote Disk IO — time when the processing was blocked by remote disk access.\n
Network Communication — time when the processing was waiting for the network data transfer.\n
Synchronization — various synchronization activities between participating processes.\n
Initialization — time spent setting up the query processing.",https://docs.snowflake.com/en/user-guide/ui-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
802,A Snowflake user wants to share unstructured data through the use of secure views. Which URL types can be used? (Choose two.),"B,D",File URL,Pre-signed URL,HTTPS URL,Scoped URL,Cloud storage URL,,,https://docs.snowflake.com/en/user-guide/unstructured-data-sharing,,"Data Protection and Data Sharing, Data Loading and Unloading"
803,How does the search optimization service help Snowflake users improve query performance?,D,It scans the micro-partitions based on the joins used in the queries and scans only join columns.,It keeps track of running queries and their results and saves those extra scans on the table.,It scans the local disk cache to avoid scans on the tables used in the query.,It maintains a persistent data structure that keeps track of the values of the table’s columns in each of its micro-partitions.,,,"To improve performance of search queries, the search optimization service creates and maintains a persistent data structure called a search access path. The search access path keeps track of which values of the table’s columns might be found in each of its micro-partitions, allowing some micro-partitions to be skipped when scanning the table.",https://docs.snowflake.com/en/user-guide/search-optimization-service#how-does-the-search-optimization-service-work,,"Performance Concepts, Snowflake AI Data Cloud Features and Architecture"
804,A Snowflake user executed a query and received the results. Another user executed the same query 4 hours later. The data had not changed. What will occur?,D,"No virtual warehouse will be used, data will be read from the local disk cache.",The default virtual warehouse will be used to read all data.,The virtual warehouse that is defined at the session level will be used to read all data.,"No virtual warehouse will be used, data will be read from the result cache.",,,,https://docs.snowflake.com/en/user-guide/querying-persisted-results,,Performance Concepts
805,Which feature allows a user the ability to control the organization of data in a micro-partition?,A,Automatic Clustering,Range Partitioning,Horizontal Partitioning,Search Optimization Service,,,Search Optimization Service has nothing to do with the organization of data in micro-partitions. Its clustering only which organizes data in micro-partitions,https://docs.snowflake.com/en/user-guide/tables-auto-reclustering,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
806,What should be used when creating a CSV file format where the columns are wrapped by single quotes or double quotes?,C,SKIP_BYTE_ORDER_MARK,ESCAPE_UNENCLOSED_FIELD,FIELD_OPTIONALLY_ENCLOSED_BY,BINARY_FORMAT,,,"Character used to enclose strings. Value can be NONE, single quote character ('), or double quote character (""). To use the single quote character, use the octal or hex representation (0x27) or the double single-quoted escape ('').",https://docs.snowflake.com/en/sql-reference/sql/create-file-format,,Data Transformations
807,How are serverless features billed?,B,"Per second multiplied by the size, as determined by the SERVERLESS_FEATURES_SIZE account parameter",Per second multiplied by an automatic sizing for the job,"Per minute multiplied by an automatic sizing for the job, with a minimum of one minute","Serverless features are not billed, unless the total cost for the month exceeds 10% of the warehouse credits, on the account",,,"Charges for serverless features are calculated based on total usage of snowflake-managed compute resources measured in compute-hours. Compute-Hours are calculated on a per second basis, rounded up to the nearest whole second. The number of credits consumed per compute hour varies depending on the serverless feature. To learn how many credits are consumed by a serverless feature, refer to the “Serverless Feature Credit Table” in the Snowflake service consumption table.",https://docs.snowflake.com/en/user-guide/cost-understanding-compute#serverless-credit-usage,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
808,What operation can be performed using Time Travel?,A,Creating a clone of an entire table at a specific point in the past from a permanent table,Restoring tables that have been dropped from a data share,Extending a permanent table’s retention duration from 90 to 100 days,Disabling Time Travel for a specific object by setting DATA_RETENTION_TIME_IN_DAYS to NULL,,,"Using Time Travel, you can perform the following actions within a defined period of time:\n
-Query data in the past that has since been updated or deleted.\n
-Create clones of entire tables, schemas, and databases at or before specific points in the past.\n
-Restore tables, schemas, and databases that have been dropped.",https://docs.snowflake.com/en/user-guide/data-time-travel,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
809,Which function generates a Snowflake hosted file URL to a staged file using the stage name and relative file path as inputs?,B,BUILD_SCOPED_FILE_URL,BUILD_STAGE_FILE_URL,GET_STAGE_LOCATION,GET_PRESIGNED_URL,,,"BUILD_STAGE_FILE_URL: Generates a Snowflake-hosted file URL to a staged file using the stage name and relative file path as inputs. A file URL permits prolonged access to a specified file. That is, the file URL does not expire.\n

This question can be tricky because there are very similar functions with small details that differentiate them.",https://docs.snowflake.com/en/sql-reference/functions/build_stage_file_url,,Data Transformations
810,"Which SQL command, when committed, will consume a stream and advance the stream offset?",C,ALTER TABLE AS SELECT FROM STREAM,SELECT FROM STREAM,INSERT INTO TABLE SELECT FROM STREAM,BEGIN COMMIT,,,The stream position (i.e. offset) is advanced when the stream is used in a DML statement. The position is updated at the end of the transaction to the beginning timestamp of the transaction. The stream describes change records starting from the current position of the stream and ending at the current transactional timestamp.,https://docs.snowflake.com/en/user-guide/streams-intro,,Data Loading and Unloading
811,What is the minimum Snowflake edition needed for database failover and fail-back between Snowflake accounts for business continuity and disaster recovery?,B,Standard,Business Critical,Virtual Private Snowflake,Enterprise,,,Requires Business Critical (or higher).,https://docs.snowflake.com/en/user-guide/database-failover-config#failing-over-databases-across-multiple-accounts,,Data Loading and Unloading
812,What metadata does Snowflake store for rows in micro-partitions? (Choose two.),"C,E",Sorted values,Index values,Distinct values,Null values,Range of values,,,https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
813,Which of the following are valid methods for authenticating users for access into Snowflake? (Choose three.),"C,D,E",TLS 1.2,OCSP authentication,Key-pair authentication,Federated authentication,OAuth,SCIM,,https://docs.snowflake.com/en/user-guide/authentication,,Account Access and Security
814,Which privileges apply to stored procedures? (Choose two.),"D,E",MODIFY,MONITOR,OPERATE,USAGE,OWNERSHIP,,"Similar to other database objects (tables, views, UDFs, etc.), stored procedures are owned by a role and have one or more privileges that can be granted to other roles.\n

Currently, USAGE AND OWNERSHIP privileges apply to stored procedures.",https://docs.snowflake.com/en/developer-guide/stored-procedure/stored-procedures-usage,,Data Transformations
815,What happens when a Data Provider revokes privileges to a share on an object in their source database?,D,Any additional data arriving after this point in time will not be visible to Data Consumers.,The Data Consumers stop seeing data updates and become responsible for storage charges for the object.,A static copy of the object at the time the privilege was revoked is created in the Data Consumers account.,The object immediately becomes unavailable for all Data Consumers.,,,"Revokes access privileges for databases and other supported database objects (schemas, tables, and views) from a share. Revoking privileges on these objects effectively removes the objects from the share, disabling access to the objects granted via the database role in all consumer accounts that have created a database from the share.",https://docs.snowflake.com/en/sql-reference/sql/revoke-privilege-share,,"Data Transformations, Data Protection and Data Sharing"
816,What happens when a Snowflake user changes the data retention period at the schema level?,A,All child objects that do not have an explicit retention period will automatically inherit the new retention period.,All child objects with an explicit retention period will be overridden with the new retention period.,All explicit child object retention periods will remain unchanged.,All child objects will retain data for the new retention period.,,,"If you change the data retention period for a database or schema, the change only affects active objects contained within the database or schema. Any objects that have been dropped (for example, tables) remain unaffected.\n

For example, if you have a schema s1 with a 90-day retention period and table t1 is in schema s1, table t1 inherits the 90-day retention period. If you drop table s1.t1, t1 is retained in Time Travel for 90 days. Later, if you change the schema’s data retention period to 1 day, the retention period for the dropped table t1 is unchanged. Table t1 will still be retained in Time Travel for 90 days.",https://docs.snowflake.com/en/user-guide/data-time-trave,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
817,What does the “percentage scanned from cache” represent in the Query Profile?,B,The percentage of data scanned from the remote disk cache,The percentage of data scanned from the local disk cache,The percentage of data scanned from the result cache,The percentage of data scanned from the query cache,,,,https://docs.snowflake.com/en/user-guide/ui-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
818,Which statements are true of micro-partitions? (Choose two.),"A,C","They are approximately 50-500MB, before compression",They are stored compressed only if COMPRESS=TRUE on Table,They are immutable,They are only encrypted in the Enterprise edition and above,"They are approximately 50-500MB, after compression",,,https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#what-are-micro-partitions,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
819,Which function determines the kind of value stored in a VARIANT column?,B,IS_JSON,TYPEOF,IS_ARRAY,CHECK_JSON,,,TYPEOF: Reports the type of a value stored in a VARIANT column. The type is returned as a string.,https://docs.snowflake.com/en/sql-reference/functions/typeof,,Data Transformations
820,What can be done to reduce queueing on a virtual warehouse?,C,Lower the MAX_CONCURRENCY_LEVEL setting for the warehouse.,Increase the AUTO_SUSPEND setting for the warehouse.,Change the warehouse to a multi-cluster warehouse.,Increase the warehouse size.,,,Multi-cluster warehouses are best utilized for scaling resources to improve concurrency for users/queries.,https://docs.snowflake.com/en/user-guide/performance-query-warehouse-queue,,Performance Concepts
821,Which commands can a Snowflake user execute to specify a cluster key for a table? (Choose two.),"C,D",SET,SHOW,CREATE,ALTER,UPDATE,,A clustering key can be defined at table creation (using the CREATE TABLE command) or afterward (using the ALTER TABLE command)..,https://docs.snowflake.com/en/user-guide/tables-clustering-keys,,Performance Concepts
822,Which of the following statements about data sharing are true? (Choose two.),"B,D",Reader Accounts are charged for warehouse usage.,Reader Accounts are created by Data Providers.,New objects created by a Data Provider are automatically shared with existing Data Consumers and Reader Accounts.,Shared databases are read-only.,All database objects can be included in a shared database.,,,https://docs.snowflake.com/en/user-guide/ui-snowsight-private-sharing-reader-accounts,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
823,In which use case does Snowflake apply egress charges?,C,Query result retrieval,Data sharing within a specific region,Database replication,Loading data into Snowflake,,,Snowflake charges a per-byte fee for data egress when users transfer data from a Snowflake account into a different region on the same cloud platform or into a completely different cloud platform. Data transfers within the same region are free.,https://docs.snowflake.com/en/user-guide/cost-understanding-data-transfer,,Performance Concepts
824,Which SQL command will list the files in a named stage?,B,get @%mytable;,list @my_stage;,get @my_stage;,list @~;,,,"LIST: Returns a list of files that have been staged (i.e. uploaded from a local file system or unloaded from a table) in one of the following Snowflake stages:\n
-Named internal stage.\n
-Named external stage.\n
-Stage for a specified table.\n
-Stage for the current user.",https://docs.snowflake.com/en/sql-reference/sql/list,,Data Transformations
825,Which Snowflake privilege is required on a pipe object to pause or resume pipes?,B,SELECT,OPERATE,READ,USAGE,,,"ALTER PIPE: Modifies a limited set of properties for an existing pipe object. Also supports the following operations:\n
-Pausing the pipe.\n
-Refreshing a pipe (i.e. copying the specified staged data files to the Snowpipe ingest queue for loading into the target table).\n
-Adding/overwriting/removing a comment for a pipe.\n
-Setting/unsetting a tag on a pipe.\n

A non-owner role with the OPERATE privilege on the pipe can pause or resume a pipe (using ALTER PIPE … SET PIPE_EXECUTION_PAUSED = TRUE | FALSE).\n

SQL operations on schema objects also require the USAGE privilege on the database and schema that contain the object.",https://docs.snowflake.com/en/sql-reference/sql/alter-pipe,,Data Transformations
826,Which use case does the search optimization service support?,B,LIKE/ILIKE/RLIKE join predicates,Conjunctions (AND) of multiple equality predicates,Disjuncts (OR) in join predicates,Join predicates on VARIANT columns,,,"Search optimization can improve the performance of queries using these kinds of predicates:\n
-Point lookup queries using equality and IN.\n
-Substring queries using wildcards and regular expressions.\n
-Searches in semi-structured data.\n
-Geospatial queries.\n
-Queries using conjunctions (AND) and disjunctions (OR).\n

The search optimization service does not directly improve the performance of joins. However, it can improve the performance of filtering rows from either table prior to the join.",https://docs.snowflake.com/en/user-guide/search-optimization/queries-that-benefit,,"Performance Concepts, Snowflake AI Data Cloud Features and Architecture"
827,What is the recommended way to change the existing file format type in my_format from CSV to JSON?,B,ALTER FILE FORMAT my_format SET TYPE=JSON;,CREATE OR REPLACE FILE FORMAT my_format TYPE=JSON;,ALTER FILE FORMAT my_format SWAP TYPE WITH JSON;,REPLACE FILE FORMAT my_format TYPE=JSON;,,,"ALTER FILE FORMAT does not support changing the type (CSV, JSON, etc.) for the file format.\n

To make any of these changes, you must recreate the file format.",https://docs.snowflake.com/en/sql-reference/sql/create-file-format,,Data Transformations
828,"While clustering a table, columns with which data types can be used as clustering keys? (Choose two.)","A,E",BINARY,GEOGRAPHY,OBJECT,VARIANT,GEOMETRY,,"It can be any data type except GEOGRAPHY, VARIANT, OBJECT, or ARRAY",https://docs.snowflake.com/en/user-guide/tables-clustering-keys#defining-a-clustering-key-for-a-table,,Performance Concepts
829,What is a feature of a stored procedure in Snowflake?,B,They can only contain a single SQL statement.,They can be created to run with a caller's rights or an owner's rights.,They can be created as secure and hide the underlying metadata from all users.,They can access tables from a single database.,,,,https://docs.snowflake.com/en/sql-reference/stored-procedures-rights,,Data Transformations
830,Query parsing and compilation occurs in which architecture layer of the Snowflake Cloud Data Platform?,B,Storage layer,Cloud services layer,Compute layer,Cloud agnostic layer,,,,https://docs.snowflake.com/en/user-guide/intro-key-concepts#cloud-services,,Snowflake AI Data Cloud Features and Architecture
831,"By default, which role has access to the SYSTEM$GLOBAL_ACCOUNT_SET_PARAMETER function?",B,SYSADMIN,ORGADMIN,ACCOUNTADMIN,SECURITYADMIN,,,Usage notes: Only organization administrators (i.e. users with the ORGADMIN role) can call this SQL function.,https://docs.snowflake.com/en/sql-reference/functions/system_global_account_set_parameter,,Data Transformations
832,"Which semi-structured file format is a compressed, efficient, columnar data representation?",C,Avro,TSV,Parquet,JSON,,,"Parquet is a compressed, efficient columnar data representation designed for projects in the Hadoop ecosystem.",https://docs.snowflake.com/en/user-guide/semistructured-data-formats,,Data Loading and Unloading
833,How does Snowflake handle the data retention period for a table if a stream has not been consumed?,B,The data retention period is not affected by the stream consumption.,The data retention period is temporarily extended to the stream’s offset.,The data retention period s reduced to a minimum of 14 days.,The data retention period is permanently extended for the table.,,,"If the data retention period for a table is less than 14 days, and a stream has not been consumed, Snowflake temporarily extends this period to prevent it from going stale. The period is extended to the stream’s offset, up to a maximum of 14 days by default, regardless of the Snowflake edition for your account. The maximum number of days for which Snowflake can extend the data retention period is determined by the MAX_DATA_EXTENSION_TIME_IN_DAYS parameter value. When the stream is consumed, the extended data retention period is reduced to the default period for the table.",https://docs.snowflake.com/en/user-guide/streams-intro#data-retention-period-and-staleness,,Data Loading and Unloading
834,What does the Activity area of Snowsight allow users to do? (Choose two.),"A,C",Monitor queries executed by users in an account.,Create and manage user roles and permissions.,Explore each step of an executed query.,Access Snowflake Marketplace to find and integrate datasets.,Schedule automated data backups.,,,https://docs.snowflake.com/en/user-guide/ui-snowsight-activity,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
835,What type of query will benefit from the query acceleration service?,B,Queries of tables that have search optimization service enabled,Queries with large scans and selective filters,Queries where the GROUP BY has high cardinality,Queries without filters or aggregation,,,"Examples of the types of workloads that might benefit from the query acceleration service include:\n
-Ad hoc analytics.\n
-Workloads with unpredictable data volume per query.\n
-Queries with large scans and selective filters.",https://docs.snowflake.com/en/user-guide/query-acceleration-service,,Performance Concepts
836,Which Snowflake object uses credits for maintenance?,B,Regular table,Materialized view,Cached query result,Regular view,,,The automatic maintenance of materialized views consumes credits.,https://docs.snowflake.com/en/user-guide/views-materialized,,Performance Concepts
837,What does a table with a clustering depth of 1 mean in Snowflake?,B,The table has 1 overlapping micro-partition.,The table has no overlapping micro-partitions.,The table has no micro-partitions.,The table has only 1 micro-partition.,,,"Higher the overlap micro partition, higher is the overlap depth. Overlap depth=1 means there is no overlap",https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions,,Performance Concepts
838,"When a Snowflake user loads CSV data from a stage, which COPY INTO [table] command guideline should they follow?",A,The number of columns in each row should be consistent.,The data file must have the same number of columns as the target table.,The data file in the stage must be in a compressed format.,"The CSV field delimiter must be a comma character (',').",,,,https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare#preparing-delimited-text-files,,Data Loading and Unloading
839,"When loading data into Snowflake, the COPY command supports which of the following?",D,Joins,Filters,Aggregates,Column reordering,,,,https://docs.snowflake.com/en/user-guide/data-load-transform#reorder-csv-columns-during-a-load,,"Data Transformations, Data Loading and Unloading"
840,"Which type of join will list all rows in the specified table, even if those rows have no match in the other table?",D,Cross join,Inner join,Natural join,Outer join,,,,https://docs.snowflake.com/en/sql-reference/constructs/join#syntax,,Data Transformations
841,"In which Snowsight section can a user switch roles, modify their profile, and access documentation?",B,The content pane,The user menu,The worksheets page,The activity page,,,You can expect some questions about the operation of Snowsight in the exam. It is advisable to navigate through the various sections to familiarize yourself with the interface.,https://docs.snowflake.com/en/user-guide/ui-snowsight-quick-tour#user-menu,,Snowflake AI Data Cloud Features and Architecture
842,What is the purpose of a Query Profile?,C,To profile how many times a particular query was executed and analyze its usage statistics over time.,To profile which queries are running in each warehouse and identify proper warehouse utilization and sizing for better performance and cost balancing.,"To profile a particular query to understand the mechanics of the query, its behavior, and performance.",To profile the user and/or executing role of a query and all privileges and policies applied on the objects within the query.,,,Query Profile is a powerful tool for understanding the mechanics of queries. It can be used whenever you want or need to know more about the performance or behavior of a particular query.,https://docs.snowflake.com/en/user-guide/ui-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
843,Which encryption type will enable client-side encryption for a directory table?,C,SNOWFLAKE_SSE,AWS_CSE,SNOWFLAKE_FULL,AES,,,SNOWFLAKE_FULL: Client-side and server-side encryption. The files are encrypted by a client when it uploads them to the internal stage using PUT.,https://docs.snowflake.com/en/sql-reference/sql/create-stage,,Data Transformations
844,How long does Snowflake retain information in the ACCESS_HISTORY view?,B,28 days,365 days,14 days,7 days,,,,https://docs.snowflake.com/en/sql-reference/account-usage,,Data Transformations
845,"If a Snowflake user decides a table should be clustered, what should be used as the cluster key?",C,The columns with many different values.,The columns that are queried in the select clause.,The columns most actively used in the select filters.,The columns with very high cardinality.,,,"Snowflake recommends prioritizing keys in the order below:\n

Cluster columns that are most actively used in selective filters. For many fact tables involved in date-based queries (for example “WHERE invoice_date > x AND invoice date <= y”), choosing the date column is a good idea. For event tables, event type might be a good choice, if there are a large number of different event types. (If your table has only a small number of different event types, then see the comments on cardinality below before choosing an event column as a clustering key.)\n

If there is room for additional cluster keys, then consider columns frequently used in join predicates, for example “FROM table1 JOIN table2 ON table2.column_A = table1.column_B”.",https://docs.snowflake.com/en/user-guide/tables-clustering-keys#strategies-for-selecting-clustering-keys,,Performance Concepts
846,What does the TableScan operator represent in the Query Profile?,A,The access to a single table,The list of values provided with the VALUES clause,The records generated using the TABLE(GENERATOR(...)) construct,The access to data stored in stage objects,,,TableScan: Represents access to a single table.,https://docs.snowflake.com/en/user-guide/ui-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
847,Why should a Snowflake user implement a secure view? (Choose two.),"A,E",To limit access to sensitive data,To increase query performance,To optimize query concurrency and queuing,To store unstructured data,To hide view definition and details from unauthorized users,,,https://docs.snowflake.com/en/user-guide/views-secure,,"Data Protection and Data Sharing, Performance Concepts"
848,Snowpark provides libraries for which programming languages? (Choose two.),"A,B",Scala,Python,C++,R,JavaScript,,"Snowpark provide libs for:\n
-Java\n
-Python\n
-Scala",https://docs.snowflake.com/en/developer-guide/snowpark/index#developer-guides,,"Snowflake AI Data Cloud Features and Architecture, Data Transformations"
849,Which Snowflake layer is always used when accessing a query from the result cache?,D,Data Storage,Metadata,Compute,Cloud Services,,,Cloud Services layer is responsible for query parsing and optimization,https://docs.snowflake.com/en/user-guide/intro-key-concepts#cloud-services,,Snowflake AI Data Cloud Features and Architecture
850,Which ACCOUNT_USAGE views are used to evaluate the details of dynamic data masking? (Choose two.),"B,C",QUERY_HISTORY,MASKING_POLICIES,POLICY_REFERENCES,ACCESS_HISTORY,ROLES,RESOURCE_MONITORS,"Snowflake provides two Account Usage views to obtain information about masking policies:\n
1. The MASKING POLICIES view provides a list of all masking policies in your Snowflake account.\n
2. The POLICY_REFERENCES view provides a list of all objects in which a masking policy is set.",https://docs.snowflake.com/en/user-guide/security-column-ddm-intro,,Data Protection and Data Sharing
851,The Snowflake VARIANT data type imposes a 16 MB size limit on what?,A,An individual row,An individual column,A file in a stage,A view,,,The VARIANT data type imposes a 16 MB size limit on individual rows.,https://docs.snowflake.com/en/user-guide/semistructured-considerations,,Data Loading and Unloading
852,How does Snowflake describe its unique architecture?,D,A multi-cluster shared nothing architecture using a siloed data repository and symmetric multiprocessing (SMP),A single-cluster shared data architecture using a central data repository and massively parallel processing (MPP),A single-cluster shared nothing architecture using a siloed data repository and symmetric multiprocessing (SMP),A multi-cluster shared data architecture using a central data repository and massively parallel processing (MPP),,,"A simple and straightforward question, but one that always appears in the exam.",https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture,,Snowflake AI Data Cloud Features and Architecture
853,Which type of loop requires a BREAK statement to stop executing?,C,WHILE,FOR,LOOP,REPEAT,,,"BREAK is required in a LOOP but is not necessary in WHILE, FOR, and REPEAT.",https://docs.snowflake.com/en/developer-guide/snowflake-scripting/loops,,Data Transformations
854,Which of the following can be used when unloading data from Snowflake? (Choose two.),"B,E",Use the ENCODING file format option to change the encoding from the default UTF-8.,"By using the SINGLE = TRUE parameter, a single file up to 5 GB in size can be exported to the storage layer.",Use the PARSE_JSON function to ensure structured data will be unloaded into the VARIANT data type.,"When unloading semi-structured data, it is recommended that the STRIP_OUTER_ARRAY option be used.",The OBJECT_CONSTRUCT function can be used to convert relational data to semi-structured data.,,,https://docs.snowflake.com/en/user-guide/data-unload-considerations,,Data Loading and Unloading
855,What will happen if a Snowflake user increases the size of a suspended virtual warehouse?,C,The warehouse will resume immediately and start to share the compute load with other running virtual warehouses.,The warehouse will remain suspended but new resources will be added to the query acceleration service.,The provisioning of additional compute resources will be in effect when the warehouse is next resumed.,The provisioning of new compute resources for the warehouse will begin immediately.,,,"Resizing a suspended warehouse does not provision any new compute resources for the warehouse. It simply instructs Snowflake to provision the additional compute resources when the warehouse is next resumed, at which time all the usage and credit rules associated with starting a warehouse apply.",https://docs.snowflake.com/en/user-guide/warehouses-tasks,,Performance Concepts
856,What are advantages clones have over tables created with CREATE TABLE AS SELECT statement? (Choose two.),"D,E",The clone has better query performance.,The clone always stays in sync with the original table.,The clone will have time travel history from the original table.,The clone saves space by not duplicating storage.,The clone is created almost instantly.,,"Cloning is fast, but not instantaneous, particularly for large objects (e.g. tables). - so ALMOST is correct.\n

Clone is not a Physical copy of the actual data instead it is a pointer to the original micro-partitions and only when we modify the cloned data.",https://docs.snowflake.com/en/sql-reference/sql/create-clone,,Data Transformations
857,A size 3X-Large multi-cluster warehouse runs one cluster for one full hour and then runs two clusters for the next full hour. What would be the total number of credits billed?,C,64,128,192,149,,,"First hour, 1 cluster: 64\n

Second hour, 2 clusters: 64x2",https://docs.snowflake.com/en/user-guide/warehouses-overview,,Performance Concepts
858,What are the recommended steps to address poor SQL query performance due to data spilling? (Choose two.),"D,E",Clone the base table.,Run a multi-cluster warehouse with maximized mode.,Add another cluster in the virtual warehouse.,Fetch required attributes only.,Use a larger virtual warehouse.,,"The spilling can't always be avoided, especially for large batches of data, but it can be decreased by:\n
-Reviewing the query for query optimization especially if it is a new query\n
-Reducing the amount of data processed. For example, by trying to improve partition pruning, or projecting only the columns that are needed in the output.\n
-Decreasing the number of parallel queries running in the warehouse.\n
-Trying to split the processing into several steps (for example by replacing the CTEs with temporary tables).\n
-Using a larger warehouse - this effectively means more memory and more local disk space.\n","https://community.snowflake.com/s/article/Performance-impact-from-local-and-remote-disk-spilling, https://docs.snowflake.com/en/user-guide/performance-query-warehouse-memory",,Performance Concepts
859,Which constraint type is enforced in Snowflake from the ANSI SQL standard?,C,PRIMARY KEY,UNIQUE,NOT NULL,FOREIGN KEY,,,"Snowflake supports defining and maintaining constraints, but does not enforce them, except for NOT NULL constraints, which are always enforced.",https://docs.snowflake.com/en/sql-reference/constraints-overview,,Data Transformations
860,What is the MINIMUM permission needed to access a file URL from an external stage?,D,READ,MODIFY,SELECT,USAGE,,,"Permissions Required:\n
-Query\n
-USAGE (external stage) or READ (internal stage)",https://docs.snowflake.com/en/sql-reference/functions/build_stage_file_url,,Data Transformations
861,"To use the OVERWRITE option on INSERT, which privilege must be granted to the role?",C,SELECT,UPDATE,DELETE,TRUNCATE,,,"To use the OVERWRITE option on INSERT, you must use a role that has DELETE privilege on the table because OVERWRITE will delete the existing records in the table.",https://docs.snowflake.com/en/sql-reference/sql/insert,,Data Transformations
862,Which role has the ability to create a share from a shared database by default?,A,ACCOUNTADMIN,SYSADMIN,SECURITYADMIN,ORGADMIN,,,"By default, the privileges required to create and manage shares are granted only to the ACCOUNTADMIN role, ensuring that only account administrators can perform these tasks.",https://docs.snowflake.com/en/user-guide/security-access-privileges-shares,,"Data Protection and Data Sharing, Account Access and Security"
863,What are valid sub-clauses to the OVER clause for a window function? (Choose two.),"A,B",PARTITION BY,ORDER BY,LIMIT,GROUP BY,UNION ALL,,"Window Syntax\n
<function> ([ <arguments> ]) OVER ([ PARTITION BY <expr1> ] [ ORDER BY <expr2> ])\n",https://docs.snowflake.com/en/sql-reference/functions-analytic#window-syntax-and-usage,,Data Transformations
864,What does a masking policy consist of in Snowflake?,D,"A single data type, with only one condition, and only one masking function","Multiple data types, with only one condition, and one or more masking functions","Multiple data types, with one or more conditions, and one or more masking functions","A single data type, with one or more conditions, and one or more masking functions",,,"A masking policy consists of a single data type, one or more conditions, and one or more masking functions.",https://docs.snowflake.com/en/user-guide/security-column-intro,,Data Protection and Data Sharing
865,Which features are included in Snowsight? (Choose two.),"B,C",Changing the Snowflake account cloud provider,Worksheet sharing,Exploring the Snowflake Marketplace,Downloading query result data larger than 100 MB,Referencing SnowSQL,,,https://docs.snowflake.com/en/user-guide/ui-snowsight-quick-tour,,Snowflake AI Data Cloud Features and Architecture
866,"When executing a COPY INTO command, performance can be negatively affected by using which optional parameter on a large number of files?",C,VALIDATION_MODE,FILE_FORMAT,PATTERN,FILES,,,,https://docs.snowflake.com/en/sql-reference/sql/copy-into-table,,Data Transformations
867,What is the difference between a stored procedure and a User-Defined Function (UDF)?,B,Multiple stored procedures can be called as part of a single executable statement while a single SQL statement can only call one UDF at a time.,Stored procedures can execute database operations while UDFs cannot.,Values returned by a stored procedure can be used directly in a SQL statement while the values returned by a UDF cannot.,Returning a value is required in a stored procedure while returning values in a UDF is optional.,,,,https://docs.snowflake.com/en/sql-reference/stored-procedures-overview#differences-between-stored-procedures-and-udfs,,Data Transformations
868,Which command should be used when loading many flat files into a single table?,A,COPY INTO,PUT,MERGE,INSERT,,,,https://docs.snowflake.com/en/sql-reference/sql/copy-into-table,,Data Transformations
869,Which common query problems are identified by the Query Profile? (Choose two.),"B,C",Syntax error,Queries too large to fit in memory,Inefficient pruning,Ambiguous column names,Object does not exist or not authorized,,"Pruning - information on the effects of table pruning.\n

Spilling — information about disk usage for operations where intermediate results do not fit in memory.",https://docs.snowflake.com/en/user-guide/ui-query-profile#statistics,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
870,"Which Snowflake function is maintained separately from the data and helps to support features such as Time Travel, Secure Data Sharing, and pruning?",A,Metadata management,Column compression,Micro-partitioning,Data clustering,,,"Metadata management in Snowflake is maintained separately from the actual data in Cloud Service Layer.\n

Metadata management in Snowflake plays a crucial role in supporting advanced features such as Time Travel, Secure Data Sharing, and pruning.",https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture,,Snowflake AI Data Cloud Features and Architecture
871,Which function should be used to find the query ID of the second query executed in a current session?,C,Select LAST_QUERY_ID(-1),Select LAST_QUERY_ID(1),Select LAST_QUERY_ID(2),Select LAST_QUERY_ID(-2),,,"Positive numbers start with the first query executed in the session. For example:\n

LAST_QUERY_ID(1) returns the first query.\n

LAST_QUERY_ID(2) returns the second query.\n

LAST_QUERY_ID(6) returns the sixth query.\n

Etc.\n

Negative numbers start with the most recently-executed query in the session. For example:\n

LAST_QUERY_ID(-1) returns the most recently-executed query (equivalent to LAST_QUERY_ID()).\n

LAST_QUERY_ID(-2) returns the second most recently-executed query.\n",https://docs.snowflake.com/en/sql-reference/functions/last_query_id,,Data Transformations
872,Which view can be used to determine if a table has frequent row updates or deletes?,C,STORAGE_USAGE,TABLES,TABLE_STORAGE_METRICS,STORAGE_DAILY_HISTORY,,,,https://docs.snowflake.com/en/sql-reference/info-schema/table_storage_metrics,,Data Transformations
873,"If a multi-cluster warehouse is using an economy scaling policy, how long will queries wait in the queue before another cluster is started?",A,6 minutes,2 minutes,8 minutes,1 minute,,,,https://docs.snowflake.com/en/user-guide/warehouses-multicluster#setting-the-scaling-policy-for-a-multi-cluster-warehouse,,Performance Concepts
874,What are characteristics of Snowflake directory fables? (Choose two.),"C,D",Directory tables are separate database objects.,Directory tables contain copies of staged files in binary format.,Directory tables store file-level metadata about the data files in a stage.,"A directory table can be added to a stage when the stage is created, or later.",Directory tables can only be used with an external stage.,,"A directory table is an implicit object layered on a stage and it stores file-level metadata about the data files in the stage.\n

You can add a directory table to a stage when you create a stage (using CREATE STAGE) or later (using ALTER STAGE).",https://docs.snowflake.com/en/user-guide/data-load-dirtables,,Data Loading and Unloading
875,What are characteristics of transient tables in Snowflake? (Choose two.),"B,D",Transient tables have a Fail-safe period of 7 days.,Transient tables have Time Travel retention periods of 0 or 1 day.,Transient tables can be cloned to permanent tables.,Transient tables persist until they are explicitly dropped.,Transient tables can be altered to make them permanent tables.,,"Transient tables are a type of table in Snowflake that persist until they are explicitly dropped. They do not have a Fail-safe period, and they can only have a Time Travel retention period of 0 or 1 day. Transient tables cannot be cloned to permanent tables, and they cannot be altered to make them permanent tables.",https://docs.snowflake.com/en/user-guide/tables-temp-transient#transient-tables,,Performance Concepts
876,"When initially creating an account in Snowflake, which settings can be specified? (Choose two.)","B,C",Organization name,Account name,Snowflake edition,Account locator,Region,,"Be cautious with this question, it asks you to choose 2 options but actually there are 3 correct options: Account name, Region, Snowflake edition. In the real exam choosing 2 of the 3 valid options will be counted as a correct question.",https://docs.snowflake.com/en/sql-reference/sql/create-account#required-parameters,,Data Transformations
877,Which data types are valid in Snowflake? (Choose two.),"A,C",Geography,BLOB,Variant,CLOB,JSON,,,https://docs.snowflake.com/en/sql-reference/intro-summary-data-types,,Data Transformations
878,"How can an administrator check for updates (for example, SCIM API requests) sent to Snowflake by the identity provider?",A,REST_EVENT_HISTORY,QUERY_HISTORY,ACCESS_HISTORY,LOAD_HISTORY,,,Administrators can query the rest_event_history table to determine whether the identity provider is sending updates (i.e. SCIM API requests) to Snowflake.,https://docs.snowflake.com/en/user-guide/scim-intro,,Account Access and Security
879,"Which function will return a row for each for each object in a VARIANT, OBJECT, or ARRAY column?",D,CAST,GET,PARSE_JSON,FLATTEN,,,"The FLATTEN function is a table function that takes a VARIANT, OBJECT, or ARRAY column and returns a row for each element or attribute within the column.",https://docs.snowflake.com/en/sql-reference/functions/flatten,,Data Transformations
880,A complex SQL query involving eight tables with joins is taking a while to execute. The Query Profile shows that all partitions are being scanned. What is causing the query performance issue?,A,Pruning is not being performed efficiently.,The columns in the micro-partitions need granular ordering based on the dataset.,"Incorrect joins are being used, leading to scanning and pulling too many records.","A huge volume of data is being fetched, with many joins applied.",,,"Key is: Query Profile shows that all partitions are being scanned.\n

The efficiency of pruning can be observed by comparing Partitions scanned and Partitions total statistics in the TableScan operators. If the former is a small fraction of the latter, pruning is efficient. If not, the pruning did not have an effect.",https://docs.snowflake.com/en/user-guide/ui-query-profile#inefficient-pruning,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
881,"If file format options are specified in multiple locations, the load operation selects which option FIRST to apply in order of precedence?",A,COPY INTO TABLE statement,Stage definition,Session level,Table definition,,,"If file format options are specified in multiple locations, the load operation applies the options in the following order of precedence:\n
COPY INTO TABLE statement.\n
Stage definition.\n
Table definition.",https://docs.snowflake.com/en/user-guide/data-load-prepare#overriding-default-file-format-options,,Data Loading and Unloading
882,Other than ownership what privileges does a user need to view and modify resource monitors in Snowflake? (Choose two.),"B,D",ALTER,MODIFY,CREATE,MONITOR,DROP,,,https://docs.snowflake.com/en/user-guide/security-access-control-privileges#resource-monitor-privileges,,Account Access and Security
883,What unit of storage supports efficient query processing in Snowflake?,D,Block storage,JSON,Blobs,Micro-partitions,,,,https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions,,Performance Concepts
884,Which Data Definition Language (DDL) commands are supported by Snowflake to manage tags? (Choose two.),"C,E",GRANT ... TO TAG,GRANT TAG,ALTER TAG,DESCRIBE TAG,DROP TAG,,"Snowflake supports the following DDL to create and manage tags:\n
CREATE TAG\n
ALTER TAG ALTER <object> (to set a tag on a Snowflake object)\n
SHOW TAGS\n
DROP TAG\n
UNDROP TAG",https://docs.snowflake.com/en/user-guide/object-tagging#label-object-tags-ddl,,Performance Concepts
885,How is the hierarchy of database objects organized in Snowflake?,B,A schema consists of one or more databases. A database contains tables and views.,A database consists of one or more schemas. A schema contains tables and views.,"A schema consists of one or more databases. A database contains tables, views, and warehouses.",A database consists of one of more schemas and warehouses. A schema contains tables and views.,,,,https://docs.snowflake.com/en/sql-reference/ddl-database,,Data Transformations
886,What common query issues can be identified using the Query Profile? (Choose two.),"A,B",Exploding joins,Inefficient pruning,Unions,Data masking,Data classification,,,https://docs.snowflake.com/en/user-guide/ui-query-profile#common-query-problems-identified-by-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
887,"When unloading data, which file format preserves the data values for floating-point number columns?",A,Parquet,Avro,JSON,CSV,,,"When floating-point number columns are unloaded to CSV or JSON files, Snowflake truncates the values to approximately (15,9).\n

The values are not truncated when unloading floating-point number columns to Parquet files.",https://docs.snowflake.com/en/user-guide/data-unload-considerations#floating-point-numbers-truncated,,Data Loading and Unloading
888,What is the recommended way to obtain a cloned table with the same grants as the source table?,D,Clone the schema then drop the unwanted tables.,Use an ALTER TABLE command to copy the grants.,Create a script to extract grants and apply them to the cloned table.,Clone the table with the COPY GRANTS command.,,,,https://docs.snowflake.com/en/user-guide/object-clone,,Performance Concepts
889,A Query Profile shows a UnionAll operator with an extra Aggregate operator on top. What does this signify?,A,UNION without ALL,Exploding joins,Inefficient pruning,Queries that are too large to fit in memory,,,"In SQL, it is possible to combine two sets of data with either UNION or UNION ALL constructs. The difference between them is that UNION ALL simply concatenates inputs, while UNION does the same, but also performs duplicate elimination.\n

A common mistake is to use UNION when the UNION ALL semantics are sufficient. These queries show in Query Profile as a UnionAll operator with an extra Aggregate operator on top (which performs duplicate elimination).",https://docs.snowflake.com/en/user-guide/ui-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
890,How can a Snowflake user share data with another user who does not have a Snowflake account?,A,Create a reader account and create a share of the data,Grant the READER privilege to the database that is going to be shared,Move the Snowflake account to a region where data sharing is enabled,Share the data by implementing User-Defined Functions (UDFs),,,,https://docs.snowflake.com/en/user-guide/data-sharing-intro#reader-accounts-for-third-party-access,,Data Protection and Data Sharing
891,What JavaScript delimiters are available in Snowflake stored procedures? (Choose two.),"A,C",Double dollar sign ($$),Double forward slash (//),Single quote (’),Double quotes (“),Double backslash (\\),,The JavaScript portion of the stored procedure code must be enclosed within either single quotes ' or double dollar signs $$.,https://docs.snowflake.com/en/sql-reference/stored-procedures-javascript,,Data Transformations
892,What type of NULL values are supported in semi-structured data? (Choose two.),"A,E",JSON,Avro,Parquet,ORC,SQL,,"Snowflake supports two types of NULL values in semi-structured data: SQL NULL:\n
SQL NULL means the same thing for semi-structured data types as it means for structured data types: the value is missing or unknown.\n
JSON null (sometimes called “VARIANT NULL”): In a VARIANT column, JSON null values are stored as a string containing the word “null” to distinguish them from SQL NULL values.",https://docs.snowflake.com/en/user-guide/semistructured-considerations,,Data Loading and Unloading
893,"A Snowflake user has a query that is running for a long time. When the user opens the query profiler, it indicates that a lot of data is spilling to disk. What is causing this to happen?",D,The cloud storage staging area is not sufficient to hold the data results.,The result cache is almost full and is unable to hold the results.,Clustering has not been applied to the table so the table is not optimized.,The warehouse memory is not sufficient to hold the intermediate query results.,,,,https://community.snowflake.com/s/article/Performance-impact-from-local-and-remote-disk-spilling,,Performance Concepts
894,Which command would return an empty sample?,A,select * from testtable sample (0);,select * from testtable sample (null);,select * from testtable sample ();,select * from testtable sample (none);,,,"Return an empty sample: \n
SELECT * FROM testtable SAMPLE ROW (0);",https://docs.snowflake.com/en/sql-reference/constructs/sample#examples,,Data Transformations
895,A user wants to add additional privileges to the system-defined roles for their virtual warehouse. How does Snowflake recommend they accomplish this?,D,Grant the additional privileges to the ORGADMIN role.,Grant the additional privileges to the ACCOUNTADMIN role.,Grant the additional privileges to the SYSADMIN role.,Grant the additional privileges to a custom role.,,,"Although additional privileges can be granted to the system-defined roles, it is not recommended.\n

If additional privileges are needed, Snowflake recommends granting the additional privileges to a custom role and assigning the custom role to the system-defined role.",https://docs.snowflake.com/en/user-guide/security-access-control-overview#roles,,Account Access and Security
896,What does the VARIANT data type impose a 16 MB size limit on?,B,Individual columns,Individual rows,All columns,All rows,,,The VARIANT data type imposes a 16 MB size limit on individual rows.,https://docs.snowflake.com/en/user-guide/semistructured-considerations,,Data Loading and Unloading
897,How does a Snowflake user execute an anonymous block of code?,A,The statements that define the block must also execute the block.,The user must run the CALL command to execute the block.,The block must be saved to a worksheet and executed using a connector.,The SUBMIT command must run immediately after the block is defined,,,The BEGIN … END statement that defines the block also executes the block. (You don’t run a separate CALL command to execute the block.),https://docs.snowflake.com/en/developer-guide/snowflake-scripting/blocks#using-an-anonymous-block,,Data Transformations
898,What are the main differences between the account usage views and the information schema views? (Choose two.),"B,E",Information schema views are read-only but account usage views are not.,"Data retention for account usage views is 1 year but is 7 days to 6 months for information schema views, depending on the view.",Account usage views do not contain data about tables but information schema views do.,No active warehouse is needed to query account usage views but one is needed to query information schema views.,Account usage views contain dropped objects but information schema views do not.,,Other difference between ACCOUNT USAGE and INFORMATION SCHEMA is latency.,https://docs.snowflake.com/en/sql-reference/account-usage,,Data Transformations
899,Which object-level parameters can be set to help control query processing and concurrency? (Choose two).,"C,D",MIN_DATA_RETENTION_TIME_IN_DAYS,MAX_CONCURRENCY_LEVEL,STATEMENT_QUEUED_TIMEOUT_IN_SECONDS,STATEMENT_TIMEOUT_IN_SECONDS,DATA_RETENTION_TIME_IN_DAYS,,"The number of queries that a warehouse can concurrently process is determined by the size and complexity of each query. As queries are submitted, the warehouse calculates and reserves the compute resources needed to process each query. If the warehouse does not have enough remaining resources to process a query, the query is queued, pending resources that become available as other running queries complete.\n

Snowflake provides some object-level parameters that can be set to help control query processing and concurrency:\n

STATEMENT_QUEUED_TIMEOUT_IN_SECONDS\n

STATEMENT_TIMEOUT_IN_SECONDS",https://docs.snowflake.com/en/user-guide/warehouses-overview,,Performance Concepts
900,"Several users are using the same virtual warehouse. The users report that the queries are running slowly, and that many queries are being queued. What is the recommended way to resolve this issue?",C,Reduce the warehouse STATEMENT_QUEUED_TIMEOUT_IN SECONDS parameter.,Increase the warehouse MAX_CONCURRENCY_LIMIT parameter.,Increase the warehouse MAX_CLUSTER_COUNT parameter.,Reduce the warehouse AUTO_SUSPEND parameter.,,,We have to solve concurrency issues here and scale out is the solution so most suitable option is increase the cluster count.,https://docs.snowflake.com/en/user-guide/warehouses-considerations#scaling-up-vs-scaling-out,,Performance Concepts
901,Which parameter prevents streams on tables from becoming stale?,B,LOCK_TIMEOUT,MAX_DATA_EXTENSION_TIME_IN_DAYS,STALE_AFTER,MIN_DATA_RETENSION_TIME_IN_DAYS,,,,https://docs.snowflake.com/en/user-guide/streams-intro#label-streams-staleness,,Data Loading and Unloading
902,What actions can be performed by a consumer account on a shared database? (Choose two.),"B,C",Cloning a shared table,Joining the data from a shared table with another table,Executing the SELECT statement on a shared table,Using Time Travel on a shared table,Modifying the data in a shared table,,,https://docs.snowflake.com/en/user-guide/data-share-consumers,,Data Protection and Data Sharing
903,What type of function can be used to estimate the approximate number of distinct values from a table that has trillions of rows?,A,HyperLogLog (HLL),MD5,Window,External,,,"Snowflake uses HyperLogLog to estimate the approximate number of distinct values in a data set. HyperLogLog is a state-of-the-art cardinality estimation algorithm, capable of estimating distinct cardinalities of trillions of rows with an average relative error of a few percent.\n

HyperLogLog can be used in place of COUNT(DISTINCT …) in situations where estimating cardinality is acceptable.",https://docs.snowflake.com/en/sql-reference/functions/hll,,Data Transformations
904,Which roles can make grant decisions to objects within a managed access schema? (Choose two.),"B,C",SYSADMIN,ACCOUNTADMIN,SECURITYADMIN,ORGADMIN,USERADMIN,,,https://docs.snowflake.com/en/user-guide/security-access-control-configure#label-managed-access-schemas,,Account Access and Security
905,What actions does the use of the PUT command do automatically? (Choose two.),"B,E",It creates an empty target table.,It compresses all files using GZIP.,It creates a file format object.,It uses the last stage created.,It encrypts the file data in transit.,,,https://docs.snowflake.com/en/sql-reference/sql/put,,Data Transformations
906,Why should a user select the economy scaling policy for a multi-cluster warehouse?,D,To increase performance of the clusters,To prevent/minimize query queuing,To reduce queuing concurrent user queries,To conserve credits by keeping running clusters fully loaded,,,"The Economy scaling policy conserves credits by favoring keeping running clusters fully-loaded rather than starting additional clusters, which may result in queries being queued and taking longer to complete.",https://docs.snowflake.com/en/user-guide/warehouses-multicluster#setting-the-scaling-policy-for-a-multi-cluster-warehouse,,Performance Concepts
907,What are reasons for using the VALIDATE function in Snowflake after a COPY INTO command execution? (Choose two.),"A,E",To validate the files that have been loaded earlier using the COPY INTO command,To fix errors that were made during the execution of the COPY INTO command,To count the number of errors encountered during the execution of the COPY INTO command,To identify potential issues in the COPY INTO command before it is executed,To return errors encountered during the execution of the COPY INTO command,,"VALIDATE function validates the files loaded in a past execution of the COPY INTO <table> command and returns all the errors encountered during the load, rather than just the first error.",https://docs.snowflake.com/en/sql-reference/functions/validate,,Data Transformations
908,"If a virtual warehouse runs for 30 seconds after it is provisioned, how many seconds will the customer be billed for?",D,121 seconds,30 seconds,1 hour,60 seconds,,,,https://docs.snowflake.com/en/user-guide/warehouses-considerations#how-are-credits-charged-for-warehouses,,Performance Concepts
909,How does Snowflake recommend handling the bulk loading of data batches from files already available in cloud storage?,D,Use an external table.,Use Snowpipe.,Use the INSERT command.,Use the COPY command.,,,Key concept is Bulk.,https://docs.snowflake.com/en/user-guide/data-load-overview#bulk-vs-continuous-loading,,Data Loading and Unloading
910,How many network policies can be assigned to an account or specific user at a time?,D,Two,Unlimited,Three,One,,,Only a single network policy can be assigned to the account or a specific user at a time.,https://docs.snowflake.com/en/user-guide/network-policies,,Account Access and Security
911,A Snowflake user has been granted the CREATE DATA EXCHANGE LISTING privilege with their role. Which tasks can this user now perform on the Data Exchange? (Choose two.),"A,C",Modify listings properties,Rename listings,Submit listings for approval/publishing,Delete provider profiles,Modify incoming listing access requests,,,https://docs.snowflake.com/en/user-guide/data-exchange-marketplace-privileges#label-create-data-exchange-listing-on-account,,Data Protection and Data Sharing
912,A JSON object is loaded into a column named data using a Snowflake variant datatype. The root node of the object is BIKE. The child attribute for this root node is BIKEID. Which statement will allow the user to access BIKEID?,B,select data.BIKE.BIKEID,select data:BIKE.BIKEID,select data:BIKE:BIKEID,select data:BIKEID,,,SYNTAX --> COLUMN:FirstElement.SubsequentElement,https://docs.snowflake.com/en/user-guide/querying-semistructured,,Performance Concepts
913,Which result shows efficient pruning?,C,Partitions scanned is equal to the partitions total.,Partitions scanned is greater than or equal to the partitions total.,Partitions scanned is less than partitions total.,Partitions scanned is greater than partitions total.,,,,https://docs.snowflake.com/en/user-guide/ui-query-profile#inefficient-pruning,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
914,"When using the ALLOW_CLIENT_MFA_CACHING parameter, how long is a cached Multi-Factor Authentication (MFA) token valid for?",B,8 hours,4 hours,2 hours,1 hour,,,"MFA token caching can help to reduce the number of prompts that must be acknowledged while connecting and authenticating to Snowflake, especially when multiple connection attempts are made within a relatively short time interval. A cached MFA token is valid for up to four hours.",https://docs.snowflake.com/en/user-guide/security-mfa#label-mfa-token-caching,,Account Access and Security
915,Which activities are managed by Snowflake’s Cloud Services layer? (Choose two.),"C,D",Data pruning,Data compression,Query parsing and optimization,Authentication,Access delegation,,"Services managed in this layer include:\n
-Authentication\n
-Infrastructure management\n
-Metadata management\n
-Query parsing and optimization\n
-Access control",https://docs.snowflake.com/en/user-guide/intro-key-concepts,,Snowflake AI Data Cloud Features and Architecture
916,The INFORMATION_SCHEMA included in each database contains which objects? (Choose two.),"A,D",Table functions for historical and usage data across the Snowflake account,Views for historical and usage data across the Snowflake account,"Table functions for account-level objects, such as roles, virtual warehouses, and databases",Views for all the objects contained in the database,Views for all the objects contained in the Snowflake account,,"Each database created in your account automatically includes a built-in, read-only schema named INFORMATION_SCHEMA.\n

The schema contains the following objects:\n
-Views for all the objects contained in the database, as well as views for account-level objects (i.e. non-database objects such as roles, warehouses, and databases)\n
-Table functions for historical and usage data across your account.",https://docs.snowflake.com/en/sql-reference/info-schema,,Data Transformations
917,How many resource monitors can be applied to a single virtual warehouse?,D,Unlimited,Zero,Eight,One,,,A resource monitor can be set to monitor multiple warehouses but a warehouse can be assigned only to a single resource monitor.,https://docs.snowflake.com/en/user-guide/resource-monitors,,Performance Concepts
918,Which virtual warehouse privilege is required to view a load-monitoring chart?,B,USAGE,MONITOR,OPERATE,MODIFY,,,,https://docs.snowflake.com/en/user-guide/warehouses-load-monitoring,,Performance Concepts
919,What mechanisms can be used to inform Snowpipe that there are staged files available to load into a Snowflake table? (Choose two.),"B,D",Error notifications,Cloud messaging,Email integrations,REST endpoints,Snowsight interactions,,,https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro,,"Data Loading and Unloading, Snowflake AI Data Cloud Features and Architecture"
920,Which task is supported by the use of Access History in Snowflake?,B,Data backups,Compliance auditing,Performance optimization,Cost monitoring,,,"Access History in Snowflake refers to when the user query reads data and when the SQL statement performs a data write operation, such as INSERT, UPDATE, and DELETE along with variations of the COPY command, from the source data object to the target data object. The user access history can be found by querying the Account Usage ACCESS_HISTORY view. The records in this view facilitate regulatory compliance auditing and provide insights on popular and frequently accessed tables and columns because there is a direct link between the user (i.e. query operator), the query, the table or view, the column, and the data.","https://docs.snowflake.com/en/sql-reference/account-usage/access_history, https://docs.snowflake.com/en/user-guide/access-history",,"Data Transformations, Account Access and Security"
921,Which user object property requires contacting Snowflake Support in order to set a value for it?,D,MINS_TO_BYPASS_MFA,MINS_TO_UNLOCK,DISABLED,MINS_TO_BYPASS_NETWORK_POLICY,,,"It is possible to temporarily bypass a network policy for a set number of minutes by configuring the user object property MINS_TO_BYPASS_NETWORK_POLICY, which can be viewed by executing DESCRIBE USER. Only Snowflake can set the value for this object property. Please contact Snowflake Support to set a value for this property.",https://docs.snowflake.com/en/user-guide/network-policies,,Account Access and Security
922,What is a characteristic of the Snowflake query profiler?,C,It can be used by third-party software using the query profiler API.,It can provide statistics on a maximum number of 100 queries per week.,It provides a graphic representation of the main components of the query processing.,It provides detailed statistics about which queries are using the greatest number of compute resources.,,,"Query Profile, available through the classic web interface, provides execution details for a query. For the selected query, it provides a graphical representation of the main components of the processing plan for the query, with statistics for each component, along with details and statistics for the overall query.",https://docs.snowflake.com/en/user-guide/ui-query-profile,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
923,What MINIMUM privilege is required on the external stage for any role in the GET REST API to access unstructured data files using a file URL?,D,OWNERSHIP,READ,WRITE,USAGE,,,"External: USAGE\n

Internal: READ",https://docs.snowflake.com/en/user-guide/data-load-unstructured-rest-api,,"Data Transformations, Data Loading and Unloading"
924,"Two users share a virtual warehouse named WH_DEV_01. When one of the users loads data, the other one experiences performance issues while querying data. How does Snowflake recommend resolving this issue?",A,Create separate warehouses for each workload,Stop loading and querying data at the same time,Scale up the existing warehouse,Create separate warehouses for each user,,,"It is always good practice to separate the loading and transformation/analysis warehouses to adjust the size that best suits each case.\n

If the running query load is high or there’s queuing, consider starting a separate warehouse and moving queued queries to that warehouse.",https://docs.snowflake.com/en/user-guide/warehouses-load-monitoring#slow-query-performance,,Performance Concepts
925,What is the default compression type when unloading data from Snowflake?,B,bzip2,gzip,Zstandard,Brotli,,,"By default, all unloaded data files are compressed using gzip, unless compression is explicitly disabled or one of the other supported compression methods is explicitly specified.",https://docs.snowflake.com/en/user-guide/intro-summary-unloading,,Data Loading and Unloading
926,A Snowflake user is writing a User-Defined Function (UDF) with some unqualified object names. How will those object names be resolved during execution?,B,Snowflake will resolve them according to the SEARCH_PATH parameter.,Snowflake will only check the schema the UDF belongs to.,"Snowflake will first check the current schema, and then the schema the previous query used.","Snowflake will first check the current schema, and then the PUBLIC schema of the current database.",,,"In queries, unqualified object names are resolved through a search path. The SEARCH_PATH is not used inside views or Writing User-Defined Functions (UDFs). All unqualifed objects in a view or UDF definition will be resolved in the view’s or UDF’s schema only.",https://docs.snowflake.com/en/sql-reference/name-resolution,,Data Transformations
927,"A user creates a stage using the following command:

CREATE STAGE mystage
DIRECTORY = (ENABLE = TRUE)
FILE_FORMAT = myformat;

What will be the outcome?",A,A stage with a directory table that has metadata that must be manually refreshed will be created.,The command will fail to run because the name of the directory table is not specified.,An error will be received stating that the storage location for the stage must be identified when creating a stage with a directory table.,A stage with a directory table set to automatically refresh will be created.,,,"Check the statement, it is creating an internal stage.\n

ENABLE = TRUE | FALSE: Specifies whether to add a directory table to the stage. When the value is TRUE, a directory table is created with the stage.\n

Directory tables on internal stages require manual metadata refreshes. You could also choose to include a directory table on external stages and refresh the metadata manually. For information about automated metadata refreshes, see automated metadata refreshes.",https://docs.snowflake.com/en/user-guide/data-load-dirtables-manage,,Data Loading and Unloading
928,What is used to extract the content of PDF files stored in Snowflake stages?,B,HyperLogLog (HLL) function,Java User-Defined Function (UDF),FLATTEN function,Window function,,,,https://docs.snowflake.com/en/user-guide/unstructured-data-java#process-a-pdf-with-a-udf-and-procedure,,Data Loading and Unloading
929,What does Snowflake's search optimization service support?,C,External tables,Casts on table columns (except for fixed-point numbers cast to strings),Tables that use masking policies and row access policies.,Materialized views,,,"The search optimization service does not support the following:\n
-External tables.\n
-Materialized views.\n
-Columns defined with a COLLATE clause.\n
-Column concatenation.\n
-Analytical expressions.\n
-Casts on table columns (except for fixed-point numbers cast to strings).","https://docs.snowflake.com/en/user-guide/search-optimization-service#label-search-optimization-service-supported-data-types, https://docs.snowflake.com/en/user-guide/search-optimization-service#tables-with-masking-policies-and-row-access-policies",,"Performance Concepts, Snowflake AI Data Cloud Features and Architecture"
930,Snowflake Partner Connect is limited to users with a verified email address and which role?,D,USERADMIN,SECURITYADMIN,SYSADMIN,ACCOUNTADMIN,,,,https://docs.snowflake.com/en/user-guide/ecosystem-partner-connect#security-requirements,,"Snowflake AI Data Cloud Features and Architecture, Account Access and Security"
931,How does Snowflake handle the bulk unloading of data into single or multiple files?,D,It uses COPY INTO to copy the data from a table into one or more files in an external stage only.,It uses the PUT command to download the data by default.,It uses COPY INTO for bulk unloading where the default option is SINGLE = TRUE.,It assigns each unloaded data file a unique name.,,,"Bulk Unloading into Single or Multiple Files The COPY INTO <location> command provides a copy option (SINGLE) for unloading data into a single file or multiple files. The default is SINGLE = FALSE (i.e. unload into multiple files).\n

Snowflake assigns each file a unique name. The location path specified for the command can contain a filename prefix that is assigned to all the data files generated. If a prefix is not specified, Snowflake prefixes the generated filenames with data_.",https://docs.snowflake.com/en/user-guide/data-unload-overview,,Data Loading and Unloading
932,A user wants to upload a file to an internal Snowflake stage using a PUT command. Which tools and/or connectors could be used to execute this command? (Choose two.),"D,E",SQL API,SnowCD,Snowsight worksheets,Python connector,SnowSQL,,"PUT command is not supported by SQL API.\n

PUT command the command cannot be executed from the Worksheets page in either Snowflake web interface; instead, use the SnowSQL client or Drivers to upload data files, or check the documentation for a specific Snowflake client to verify support for this command.\n

SnowCD is a tool for solving connectivity issues.","https://docs.snowflake.com/en/developer-guide/sql-api/intro#limitations-of-the-sql-api, https://docs.snowflake.com/en/sql-reference/sql/put",,Data Transformations
933,Which type of role can be granted to a share?,C,Account role,Custom role,Database role,Secondary role,,,"Grant the database role to a share and grant future privileges on an object to the database role:\n
-GRANT DATABASE ROLE dbr1 TO SHARE myshare;\n
-GRANT SELECT ON FUTURE TABLES IN SCHEMA sh TO DATABASE ROLE dbr1;",https://docs.snowflake.com/en/sql-reference/sql/grant-database-role-share,,"Data Transformations, Data Protection and Data Sharing"
934,How can a Snowflake user post-process the result of SHOW FILE FORMATS?,B,Create a CURSOR for the command.,Use the RESULT_SCAN function.,Put it in the FROM clause in brackets.,Assign the command to RESULTSET.,,,"RESULT_SCAN function returns the result set of a previous command (within 24 hours of when you executed the query) as if the result was a table.\n
SHOW FILE FORMATS;\n
SELECT * FROM TABLE(RESULT_SCAN(LAST_QUERY_ID(-1))) ;",https://docs.snowflake.com/en/sql-reference/functions/result_scan#usage-notes,,Data Transformations
935,Which features could be used to improve the performance of queries that return a small subset of rows from a large table? (Choose two.),"B,E",Multi-cluster virtual warehouses,Search optimization service,Row access policies,Secure views,Automatic clustering,,"The search optimization service aims to significantly improve the performance of certain types of queries on tables, including:\n
-Selective point lookup queries on tables.\n
-A point lookup query returns only one or a small number of distinct rows...(see linked documentation for more)\n
Typically, queries benefit from clustering when the queries filter or sort on the clustering key for the table. Sorting is commonly done for ORDER BY operations, for GROUP BY operations, and for some joins.","https://docs.snowflake.com/en/user-guide/search-optimization-service, https://docs.snowflake.com/en/user-guide/tables-clustering-keys",,"Performance Concepts, Snowflake AI Data Cloud Features and Architecture"
936,What are characteristics of reader accounts in Snowflake? (Choose two.),"A,E",Reader account users cannot add new data to the account.,A single reader account can consume data from multiple provider accounts.,Reader account users can share data to other reader accounts.,Data consumers are responsible for reader account setup and data usage costs.,Reader accounts enable data consumers to access and query data shared by the provider.,,,https://docs.snowflake.com/en/user-guide/data-sharing-reader-create,,Data Protection and Data Sharing
937,What is the compressed size limit for semi-structured data loaded into a VARIANT data type using the COPY command?,C,8 MB,64 MB,16 MB,32 MB,,,,https://docs.snowflake.com/en/sql-reference/data-types-semistructured,,Data Transformations
938,A Snowflake user wants to unload data from a relational table sized 5 GB using CSV. The extract needs to be as performant as possible. What should the user do?,A,Leave the default MAX_FILE_SIZE to 16 MB to take advantage of parallel operations.,Increase the default MAX_FILE_SIZE to 5 GB and set SINGLE = true to produce a single file.,"Use Parquet as the unload file format, using Parquet's default compression feature.",Use a regular expression in the stage specification of the COPY command to restrict parsing time.,,,"By default, COPY INTO location statements separate table data into a set of output files to take advantage of parallel operations. The maximum size for each file is set using the MAX_FILE_SIZE copy option. The default value is 16777216 (16 MB) but can be increased to accommodate larger files. The maximum file size supported is 5 GB for Amazon S3, Google Cloud Storage, or Microsoft Azure stages.",https://docs.snowflake.com/en/user-guide/data-unload-considerations#unloading-to-a-single-file,,Data Loading and Unloading
939,What is the default period of time the Warehouse Activity section provides a graph of Snowsight activity?,D,1 month,1 week,2 hours,2 weeks,,,"The Warehouse Activity section provides a graph of activity over a period of time:\n
-Hour\n
-Day\n
-Week\n
-2 Weeks (default)\n",https://docs.snowflake.com/en/user-guide/ui-snowsight-admin#warehouse-activity,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
940,Which types of URLs are provided by Snowflake to access unstructured data files? (Choose two).,"A,D",Scoped URL,Dynamic URL,Absolute URL,File URL,Relative URL,,,https://docs.snowflake.com/en/user-guide/unstructured-intro,,Data Loading and Unloading
941,What ensures that a user with the role SECURITYADMIN can activate a network policy for an individual user?,C,A role that has been granted the global ATTACH POLICY privilege,A role that has been granted the EXECUTE TASK privilege,Ownership privilege on both the user and the network policy,Ownership privilege on only the role that created the network policy,,,"Only the role with the OWNERSHIP privilege on both the user and the network policy, or a higher role, can activate a network policy for an individual user.",https://docs.snowflake.com/en/user-guide/network-policies#activating-network-policies-for-individual-users,,Account Access and Security
942,Which use case will always cause an exploding join in Snowflake?,B,A query that has more than 10 left outer joins.,A query that has not specified join criteria for tables.,A query that is using a UNION without an ALL.,A query that has requested too many columns of data.,,,It's also called cartesian product.,https://docs.snowflake.com/en/user-guide/ui-snowsight-activity#label-exploding-join,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
943,Which statement describes when a virtual warehouse can be resized?,B,A resize can only be completed when the warehouse is in an auto-resume status.,A resize can be completed at any time.,A resize must be completed when the warehouse is suspended.,"A resize will affect running, queued, and new queries.",,,"A warehouse can be resized up or down at any time, including while it is running and processing statements.",https://docs.snowflake.com/en/user-guide/warehouses-tasks#resizing-a-warehouse,,Performance Concepts
944,"Which Snowflake object can be accessed in the FROM clause of a query, returning a set of rows having one or more columns?",A,A User-Defined Table Function (UDTF),A stored procedure,A Scalar User Defined Function (UDF),A task,,,,https://docs.snowflake.com/en/developer-guide/udf/udf-calling-sql#calling-a-udtf,,Data Transformations
945,What statistical information in a Query Profile indicates that the query is too large to fit in memory? (Choose two.),"C,D",Bytes spilled to remote metastore.,Bytes spilled to remote cache.,Bytes spilled to remote storage.,Bytes spilled to local storage.,Bytes spilled to local cache.,,"Bytes spilled to local storage — volume of data spilled to local disk.\n

Bytes spilled to remote storage — volume of data spilled to remote disk.",https://docs.snowflake.com/en/user-guide/ui-query-profile#statistics,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
946,Which system function can be used to manage access to the data in a share and display certain data only to paying customers?,C,SYSTEM$ALLOWLIST_PRIVATELINK,SYSTEM$ALLOWLIST,SYSTEM$IS_LISTING_PURCHASED,SYSTEM$AUTHORIZE_PRIVATELINK,,,"If you choose to limit trial consumers to specific data and functionality, create a single share for your paid listing and use secure views and a system function provided by Snowflake, SYSTEM$IS_LISTING_PURCHASED, to control which data is visible to trial consumers and which data is available only to paying consumers.",https://other-docs.snowflake.com/en/collaboration/provider-listings-preparing,,Data Protection and Data Sharing
947,Which view will return users who have queried a table?,D,SNOWFLAKE.ACCOUNT_USAGE.COLUMNS,SNOWFLAKE.ACCOUNT_USAGE.OBJECT_DEPENDENCIES,SNOWFLAKE.ACCOUNT_USAGE.WAREHOUSE_EVENT_HISTORY,SNOWFLAKE.ACCOUNT_USAGE.ACCESS_HISTORY,,,,https://docs.snowflake.com/en/user-guide/access-history,,Account Access and Security
948,How long is a query visible in the Query History page in the Snowflake Web Interface (UI)?,A,14 days,30 days,60 minutes,24 hours,,,,https://docs.snowflake.com/en/user-guide/ui-history,,Snowflake AI Data Cloud Features and Architecture
949,What are characteristics of Snowsight worksheets? (Choose two.),"A,E",Users can import worksheets and share them with other users.,Users are limited to running only one query on a worksheet.,The Snowflake session ends when a user switches worksheets.,"Worksheets can be grouped under folders, and a folder of folders.",Each worksheet is a unique Snowflake session.,,You can share worksheets and folders of worksheets with other Snowflake users in your account. Each worksheet is a unique session and can use roles different from the role you select. Folders can't be nested.,https://docs.snowflake.com/en/user-guide/ui-snowsight-worksheets#label-snowsight-worksheet-session-context,,Snowflake AI Data Cloud Features and Architecture
950,What does it mean when the sample function uses the Bernoulli sampling method?,C,The data is based on sampling 1000 rows of the source data.,The data is based on sampling blocks of the source data.,The data is based on sampling every row.,The data is based on sampling 10% of the source data.,,,BERNOULLI (or ROW): Includes each row with a probability of p/100. Similar to flipping a weighted coin for each row.,https://docs.snowflake.com/en/sql-reference/constructs/sample#syntax,,Data Transformations
951,Which statements reflect valid commands when using secondary roles? (Choose two.),"B,C",USE SECONDARY ROLES SUSPEND,USE SECONDARY ROLES NONE,USE SECONDARY ROLES ALL,USE SECONDARY ROLES RESUME,USE SECONDARY ROLES ADD,,,https://docs.snowflake.com/en/sql-reference/sql/use-secondary-roles#syntax,,Data Transformations
952,What technique does Snowflake recommend for determining which virtual warehouse size to select?,B,Use the default size Snowflake chooses,Experiment by running the same queries against warehouses of different sizes,Always start with an X-Small and increase the size if the query does not complete in 2 minutes,Use X-Large or above for tables larger than 1 GB,,,"The keys to using warehouses effectively and efficiently are:\n
-Experiment with different types of queries and different warehouse sizes to determine the combinations that best meet your specific query needs and workload.\n
-Don’t focus on warehouse size. Snowflake utilizes per-second billing, so you can run larger warehouses (Large, X-Large, 2X-Large, etc.) and simply suspend them when not in use.",https://docs.snowflake.com/en/user-guide/warehouses-considerations,,Performance Concepts
953,Which object type is granted permissions for reading a table?,B,User,Role,Schema,Attribute,,,,https://docs.snowflake.com/en/sql-reference/sql/grant-privilege,,Data Transformations
954,Which function returns the URL of a stage using the stage name as the input?,B,BUILD_SCOPED_FILE_URL,GET_STAGE_LOCATION,BUILD_STAGE_FILE_URL,GET_PRESIGNED_URL,,,,https://docs.snowflake.com/en/sql-reference/functions/get_stage_location,,Data Transformations
955,How do managed access schemas help with data governance?,B,They log all operations and enable fine-grained auditing.,They provide centralized privilege management with the schema owner.,They require the use of masking and row access policies across every table and view in the schema.,They enforce identical privileges across all tables and views in a schema.,,,"With managed access schemas, object owners lose the ability to make grant decisions. Only the schema owner (i.e. the role with the OWNERSHIP privilege on the schema) or a role with the MANAGE GRANTS privilege can grant privileges on objects in the schema, including future grants, centralizing privilege management.",https://docs.snowflake.com/en/user-guide/security-access-control-configure#creating-managed-access-schemas,,Account Access and Security
956,Where can a Snowflake user find the query history in Snowsight?,D,Data,Admin,Dashboards,Activity,,,,https://docs.snowflake.com/en/user-guide/ui-snowsight-activity,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
957,Which operation will produce an error in Snowflake?,B,Inserting duplicate values into a PRIMARY KEY column,Inserting a NULL into a column with a NOT NULL constraint,Inserting a value to FOREIGN KEY column that does not match a value in the column referenced,Inserting duplicate values into a column with a UNIQUE constraint,,,"Snowflake supports defining and maintaining constraints, but does not enforce them, except for NOT NULL constraints, which are always enforced.",https://docs.snowflake.com/en/sql-reference/constraints,,Data Transformations
958,"A user needs to MINIMIZE the cost of large tables that are used to store transitory data. The data does not need to be protected against failures, because the data can be reconstructed outside of Snowflake. What table type should be used?",D,Permanent,External,Directory,Transient,,,"Transient tables are best suited in scenarios where the data in your table is not critical and can be recovered from external means if required. Also, they have no fail-safe period, and Time travel is also only 1 day (which can be set to 0 also).",https://docs.snowflake.com/en/user-guide/tables-temp-transient#transient-tables,,Performance Concepts
959,"Which query will return a sample of a table with 1000 rows named testtable, in which each row has a 10% probability of being included in the sample?",D,select * from testtable sample (10 rows);,select * from testtable sample (0.1 rows);,select * from testtable sample (0.1);,select * from testtable sample (10);,,,,https://docs.snowflake.com/en/sql-reference/constructs/sample,,Data Transformations
960,What is the MINIMUM size of a table for which Snowflake recommends considering adding a clustering key?,B,1 Kilobyte (KB),1 Terabyte (TB),1 Gigabyte (GB),1 Megabyte (MB),,,,https://docs.snowflake.com/en/user-guide/tables-clustering-keys,,Performance Concepts
961,What is a characteristic of a role in Snowflake?,B,System-defined roles can be dropped.,Privileges on securable objects can be granted and revoked to a role.,Roles cannot be granted to other roles.,Privileges granted to system roles by Snowflake can be revoked.,,,,https://docs.snowflake.com/en/user-guide/security-access-control-overview,,Account Access and Security
962,Which function is used to profile warehouse credit usage?,A,WAREHOUSE_METERING_HISTORY,MATERIALIZED_VIEW_REFRESH_HISTORY,WAREHOUSE_LOAD_HISTORY,AUTOMATIC_CLUSTERING_HISTORY,,,,https://docs.snowflake.com/en/sql-reference/functions/warehouse_metering_history,,Data Transformations
963,"By default, which role has privileges to create tables and views in an account?",D,SECURITYADMIN,USERADMIN,PUBLIC,SYSADMIN,,,"The SYSADMIN role is a system-defined role that has privileges to create warehouses, databases, and database objects in an account and grant those privileges to other roles.",https://docs.snowflake.com/en/user-guide/security-access-control-configure#creating-a-role-hierarchy,,Account Access and Security
964,Which table type is no longer available after the close of the session and therefore has no Fail-safe or Time Travel recovery option?,B,External,Temporary,Transient,Permanent,,,,https://docs.snowflake.com/en/user-guide/tables-temp-transient#temporary-tables,,Performance Concepts
965,How are micro-partitions typically generated in Snowflake?,A,Automatically,ORDER BY <>;,PARTITION BY <>;,GROUP BY <>;,,,,https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
966,Snowflake strongly recommends that all users with what type of role be required to use Multi-Factor Authentication (MFA)?,B,USERADMIN,ACCOUNTADMIN,SYSADMIN,SECURITYADMIN,,,All users assigned the ACCOUNTADMIN role should also be required to use multi-factor authentication (MFA) for login.,https://docs.snowflake.com/en/user-guide/security-access-control-considerations#control-the-assignment-of-the-accountadmin-role-to-users,,Account Access and Security
967,"Given the statement template below, which database objects can be added to a share? (Choose two.)

GRANT ON TO SHARE;","C,E",Streams,Stored procedures,Tables,Tasks,Secure functions,,,https://docs.snowflake.com/en/user-guide/data-sharing-intro,,Data Protection and Data Sharing
968,How can a Snowflake user validate data that is unloaded using the COPY INTO command?,A,Use the VALIDATION_MODE = RETURN_ROWS statement.,Load the data into a CSV file.,Load the data into a relational table.,Use the VALIDATION_MODE = SQL statement.,,,"String (constant) that instructs the COPY command to return the results of the query in the SQL statement instead of unloading the results to the specified cloud storage location. The only supported validation option is RETURN_ROWS. This option returns all rows produced by the query.\n

When you have validated the query, you can remove the VALIDATION_MODE to perform the unload operation.",https://docs.snowflake.com/en/sql-reference/sql/copy-into-location#optional-parameters,,Data Transformations
969,How are URLs that access unstructured data in external stages retrieved?,C,From the Snowsight navigation menu,By creating an external function,By querying a directory table,By using the INFORMATION_USAGE schema,,,,https://docs.snowflake.com/en/user-guide/unstructured-intro#directory-tables,,Data Loading and Unloading
970,Which clustering indicator will show if a large table in Snowflake will benefit from explicitly defining a clustering key?,B,Total partition count,Depth,Ratio,Percentage,,,,https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#label-clustering-depth,,Performance Concepts
971,Why would a Snowflake user choose to use a transient table?,C,To create a permanent table for ongoing use in ELT,To store data for long-term analysis,To store transitory data that needs to be maintained beyond the session,To store large data files that are used frequently,,,Transient tables are specifically designed for transitory data that needs to be maintained beyond each session,https://docs.snowflake.com/en/user-guide/tables-temp-transient#transient-tables,,Performance Concepts
972,When should a stored procedure be created with caller's rights?,D,When the stored procedure needs to operate on objects that the caller does not have privileges on,When the caller needs to run a statement that could not execute outside of the stored procedure,When the caller needs to be prevented from viewing the source code of the stored procedure,When the stored procedure needs to run with the privileges of the role that called the stored procedure,,,,https://docs.snowflake.com/en/sql-reference/stored-procedures-rights,,Data Transformations
973,How long can a data consumer who has a pre-signed URL access data files using Snowflake?,A,Until the expiration_time is exceeded,Until the result_cache expires,Indefinitely,Until the retention_time is met,,,,https://docs.snowflake.com/en/sql-reference/functions/get_presigned_url,,Data Transformations
974,Which kind of Snowflake table stores file-level metadata for each file in a stage?,C,External,Temporary,Directory,Transient,,,A directory table is an implicit object layered on a stage (not a separate database object) and is conceptually similar to an external table because it stores file-level metadata about the data files in the stage. A directory table has no grantable privileges of its own.,https://docs.snowflake.com/en/user-guide/data-load-dirtables,,Data Loading and Unloading
975,A tag object has been assigned to a table (TABLE_A) in a schema within a Snowflake database. Which CREATE object statement will automatically assign the TABLE_A tag to a target object?,C,CREATE TABLE AS SELECT * FROM TABLE_A;,CREATE VIEW AS SELECT * FROM TABLE_A;,CREATE TABLE LIKE TABLE_A;,CREATE MATERIALIZED VIEW AS SELECT * FROM TABLE_A;,,,"With CREATE TABLE … LIKE, tags assigned to the source table are assigned to the target table",https://docs.snowflake.com/en/user-guide/object-tagging#create-table-statements,,Performance Concepts
976,"User A cloned a schema and overwrote a schema that User B was working on. User B no longer has access to their version of the tables. However, this all occurred within the Time Travel retention period defined at the database level. How should the missing tables be restored?",B,Use a CREATE TABLE AS SELECT statement,Rename the cloned schema and use an UNDROP SCHEMA statement.,Contact Snowflake Support to retrieve the data from Fail-safe,Use an UNDROP TABLE statement.,,,"If an object with the same name already exists, UNDROP fails. You must rename the existing object, which then enables you to restore the previous version of the object.",https://docs.snowflake.com/en/user-guide/data-time-travel#restoring-objects,,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
977,"A custom role owns multiple tables. If this role is dropped from the system, who becomes the owner of these tables?",C,SYSADMIN,ACCOUNTADMIN,The role that dropped the custom role.,Tables will be standalone or orphaned.,,,,https://docs.snowflake.com/en/sql-reference/sql/drop-role,,Data Transformations
978,What column type does a Kafka connector store formatted information in a single column?,C,VARCHAR,ARRAY,VARIANT,OBJECT,,,"Each Kafka message is passed to Snowflake in JSON format or Avro format. The Kafka connector stores that formatted information in a single column of type VARIANT. The data is not parsed, and the data is not split into multiple columns in the Snowflake table.",https://docs.snowflake.com/en/user-guide/kafka-connector-overview,,"Data Transformations, Performance Concepts"
979,Why do Snowflake’s virtual warehouses have scaling policies?,C,To help control the credits consumed by a multi-cluster warehouse running in maximized mode,To help increase the performance of serverless computing features,To help control the credits consumed by a multi-cluster warehouse running in auto-scale mode,To help save extra storage costs,,,"To help control the credits consumed by a multi-cluster warehouse running in Auto-scale mode, Snowflake provides scaling policies, which are used to determine when to start or shut down a cluster.",https://docs.snowflake.com/en/user-guide/warehouses-multicluster#label-mcw-scaling-policies,,Performance Concepts
980,Which function produces a lateral view of a VARIANT column?,D,PARSE_JSON,GET,GET_PATH,FLATTEN,,,,https://docs.snowflake.com/en/sql-reference/functions/flatten,,Data Transformations
981,"A Snowflake account administrator has set the resource monitors as shown in the diagram, with actions defined for each resource monitor as “Notify & Suspend Immediately”.",C,What is the MAXIMUM limit of credits that Warehouse 2 can consume?,1500,5000,0,3500,,"Warehouse 2 is controlled by policy on the account level and all five warehouses usage count toward this limit. Having limit on another warehouses (in this example: 3, 4, 5) just means that warehouse 3, 4, 5 can be suspended earlier when reaching their limits.\n

The question ask for the MAXIMUM, so the best case scenario for warehouse 2 is that other warehouses doesn't consume ANY resources and in such case warehouse 2 can burn whole 5000 limit.",https://docs.snowflake.com/en/user-guide/resource-monitors,https://i.imgur.com/tziPWUt.png,Performance Concepts
982,What is the MINIMUM size requirement when creating a Snowpark-optimized virtual warehouse?,C,X-Small,Small,Medium,Large,,,,https://docs.snowflake.com/en/user-guide/warehouses-snowpark-optimized,,"Performance Concepts, Snowflake AI Data Cloud Features and Architecture"
983,"In the Data Exchange, who can get or request data from the listings? (Choose two.)","C,D",Users with MANAGE GRANTS privilege,Users with ORGADMIN role,Users with ACCOUNTADMIN role,Users with IMPORT SHARE privilege,Users with SYSADMIN role,,"All users can browse listings in the Data Exchange, but only users with the ACCOUNTADMIN role or the IMPORT SHARE privilege can get or request data.",https://docs.snowflake.com/en/user-guide/data-exchange-using,,Data Protection and Data Sharing
984,Which table function is used to view all errors encountered during a previous data load?,B,QUERY_HISTORY,VALIDATE,GENERATOR,INFER_SCHEMA,,,"VALIDATE: Validates the files loaded in a past execution of the COPY INTO <table> command and returns all the errors encountered during the load, rather than just the first error.",https://docs.snowflake.com/en/sql-reference/functions/validate,,Data Transformations
985,What does Snowflake recommend regarding database object ownership? (Choose two.),"C,D",Create objects with SECURITYADMIN to ease granting of privileges later.,Create objects with ACCOUNTADMIN and do not reassign ownership.,Create objects with SYSADMIN.,Create objects with a custom role and grant this role to SYSADMIN.,Use only managed access schemas for objects owned by ACCOUNTADMIN.,,"SYSADMIN - Role that has privileges to create warehouses and databases (and other objects) in an account.\n

If, as recommended, you create a role hierarchy that ultimately assigns all custom roles to the SYSADMIN role, this role also has the ability to grant privileges on warehouses, databases, and other objects to other roles.",https://docs.snowflake.com/en/user-guide/security-access-control-overview,,Account Access and Security
986,Which semi-structured data formats can be loaded into Snowflake with a COPY command? (Choose two.),"C,E",CSV,HTML,XML,EDI,ORC,,,https://docs.snowflake.com/en/user-guide/semistructured-concepts,,Data Loading and Unloading
987,A Snowflake user wants to share data with someone who does not have a Snowflake account. How can the Snowflake user share the data?,B,Use a Snowflake share.,Create a reader account.,Create a consumer account.,Use the Snowflake Marketplace.,,,,https://docs.snowflake.com/en/user-guide/data-sharing-intro#reader-accounts-for-third-party-access,,Data Protection and Data Sharing
988,hat is the MAXIMUM number of clusters that can be provisioned with a multi-cluster virtual warehouse?,B,5,10,100,1,,,,https://docs.snowflake.com/en/user-guide/warehouses-multicluster,,Performance Concepts
989,Which role can execute the SHOW ORGANIZATION ACCOUNTS command successfully?,B,SECURITYADMIN,ORGADMIN,ACCOUNTADMIN,USERADMIN,,,,https://docs.snowflake.com/en/sql-reference/sql/show-organization-accounts,,Data Transformations
990,A user wants to access files stored in a stage without authenticating into Snowflake. Which type of URL should be used?,B,Scoped URL,Pre-signed URL,Staged URL,File URL,,,"You can allow data consumers to retrieve either scoped or pre-signed URLs from the secure view. Scoped URLs provide better security, while pre-signed URLs can be accessed without authorization or authentication.",https://docs.snowflake.com/en/user-guide/unstructured-data-sharing,,"Data Protection and Data Sharing, Data Loading and Unloading"
991,"As a best practice, all custom roles should be granted to which system-defined role?",A,SYSADMIN,SECURITYADMIN,ORGADMIN,ACCOUNTADMIN,,,,https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles,,Account Access and Security
992,"For the ALLOWED_VALUES tag property, what is the MAXIMUM number of possible string values for a single tag?",A,300,64,10,256,,,The ALLOWED_VALUES tag property enables specifying the possible string values that can be assigned to the tag when the tag is set on an object. The maximum number of possible string values for a single tag is 300.,https://docs.snowflake.com/en/user-guide/object-tagging#specify-tag-values,,Performance Concepts
993,What does Snowflake attempt to do if any of the compute resources for a virtual warehouse fail to provision during start-up?,C,Restart the failed resources.,Provision the failed resources.,Repair the failed resources.,Queue the failed resources.,,,"If any of the compute resources for the warehouse fail to provision during start-up, Snowflake attempts to repair the failed resources.",https://docs.snowflake.com/en/user-guide/warehouses-tasks,,Performance Concepts
994,Which operation can be performed on Snowflake external tables?,D,INSERT,RENAME,DELETE,ALTER,,,"External tables are read-only. You cannot perform data manipulation language (DML) operations on them. However, you can use external tables for query and join operations. You can also create views against external tables.\n

ALTER EXTERNAL TABLE\n

Modifies the properties, columns, or constraints for an existing external table.",https://docs.snowflake.com/en/sql-reference/sql/alter-external-table,,Data Transformations
995,What are Snowflake best practices when assigning the ACCOUNTADMIN role to users? (Choose two.),"C,E",The ACCOUNTADMIN role should be given to any user who needs a high level of authority.,The ACCOUNTADMIN role should be used for running automated scripts.,All users assigned the ACCOUNTADMIN role should use Multi-Factor Authentication (MFA).,The ACCOUNTADMIN role should be used to create Snowflake objects.,The ACCOUNTADMIN role should be assigned to at least two users.,,"Snowflake strongly recommends the following precautions when assigning the ACCOUNTADMIN role to users:\n
-Assign this role only to a select/limited number of people in your organization.\n
-All users assigned the ACCOUNTADMIN role should also be required to use multi-factor authentication (MFA) for login (for details, see Configuring Access Control).\n
-Assign this role to at least two users. We follow strict security procedures for resetting a forgotten or lost password for users with the ACCOUNTADMIN role. These procedures can take up to two business days. Assigning the ACCOUNTADMIN role to more than one user avoids having to go through these procedures because the users can reset each other’s passwords.",https://docs.snowflake.com/en/user-guide/security-access-control-considerations,,Account Access and Security
996,What Snowflake function should be used to unload relational data to JSON?,A,OBJECT_CONSTRUCT(),TO_VARIANT(),PARSE_JSON(),BUILD_STAGE_FILE_URL(),,,OBJECT_CONSTRUCT Returns an OBJECT constructed from the arguments.,https://docs.snowflake.com/en/sql-reference/functions/object_construct,,Data Transformations
997,Which security feature is used to connect or log in to a Snowflake account?,C,Role-Based Access Control (RBAC),Network policy,Key pair authentication,SCIM,,,"To authenticate to Snowflake, you can use one of the following options:\n
-Password-based authentication. To use this, set the password option when establishing the connection.\n
-Single sign-on (SSO) through a web browser.\n
-Native SSO through Okta.\n
-Key pair authentication.\n
-OAuth.\n
\n
Network Policy in Snowflake are used to control the network traffic allowed to access a Snowflake account. They can restrict access based on IP address ranges or other network-related properties.\n

SCIM is used for managing user identities across different systems, including provisioning and deprovisioning users in a centralized manner.\n

RBAC in Snowflake is a method for controlling access to resources based on the roles assigned to users. It defines what actions users can take and what data they can access within Snowflake.",https://docs.snowflake.com/en/developer-guide/node-js/nodejs-driver-authenticate,,Account Access and Security
998,What happens when the size of a virtual warehouse is changed?,B,Queries that are running on the current warehouse configuration are moved to the new configuration and finished there.,Queries that are running on the current warehouse configuration are not impacted.,Queries that are running on the current warehouse configuration are aborted and have to be resubmitted by the user.,Queries that are running on the current warehouse configuration are aborted and are automatically resubmitted.,,,"Resizing a running warehouse does not impact queries that are already being processed by the warehouse; the additional compute resources, once fully provisioned, are only used for queued and new queries.",https://docs.snowflake.com/en/user-guide/warehouses-tasks#effects-of-resizing-a-running-warehouse,,Performance Concepts
999,Which chart type does Snowsight support to visualize worksheet data?,A,Scatterplot,Pie chart,Bubble chart,Box plot,,,"Snowsight supports the following types of charts:\n
-Bar charts\n
-Line charts\n
-Scatterplots\n
-Heat grids\n
-Scorecards",https://docs.snowflake.com/en/user-guide/ui-snowsight-visualizations,,Snowflake AI Data Cloud Features and Architecture
1000,Which command should a Snowflake user execute to load data into a table?,D,copy into mytable validation = ‘RETURN_ERRORS’;,copy into mytable purge_mode = TRUE;,copy into mytable file_format = (format_name);,copy into mytable from @my_int_stage;,,,,https://docs.snowflake.com/en/sql-reference/sql/copy-into-table,,Data Transformations
1001,What metadata does Snowflake store concerning all rows stored in a micro-partition? (Choose two.),"B,E",The range of values for each of the rows in the micro-partition,The number of distinct values for each column in the micro-partition,The range of values for each partition in the micro-partition,A count of the number of total values in the micro-partition,The range of values for each of the columns in the micro-partition,,"Snowflake stores metadata about all rows stored in a micro-partition, including:\n
-The range of values for each of the columns in the micro-partition.\n
-The number of distinct values.\n
-Additional properties used for both optimization and efficient query processing.",https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions,,"Snowflake AI Data Cloud Features and Architecture, Performance Concepts"
1002,Which file function provides a URL with access to a file on a stage without the need for authentication and authorization?,D,BUILD_STAGE_FILE_URL,GET_RELATIVE_PATH,BUILD_SCOPED_FILE_URL,GET_PRESIGNED_URL,,,Generates the pre-signed URL to a staged file using the stage name and relative file path as inputs. Access files in an external stage using the function.,https://docs.snowflake.com/en/sql-reference/functions/get_presigned_url,,Data Transformations
1003,What will be the output of the last select statement once the following SQL statements have been executed:,C,8,3,7,4,,,,https://docs.snowflake.com/en/sql-reference/sql/create-sequence,https://i.imgur.com/ceOkj4Z.png,Data Transformations
1004,The use of which technique or tool will improve Snowflake query performance on very large tables?,C,Materialized views,Indexing,Clustering keys,Multi-clustering,,,A clustering key is a subset of columns in a table (or expressions on a table) that are explicitly designated to co-locate the data in the table in the same micro-partitions. This is useful for very large tables where the ordering was not ideal (at the time the data was inserted/loaded) or extensive DML has caused the table’s natural clustering to degrade.,https://docs.snowflake.com/en/user-guide/tables-clustering-keys,,Performance Concepts
1005,What happens when a database is cloned?,A,It replicates all granted privileges on the corresponding child objects.,It does not retain any privileges granted on the source object.,It replicates all granted privileges on the corresponding source objects.,It replicates all granted privileges on the corresponding child schema objects.,,,"If the source object is a database or schema, the clone inherits all granted privileges on the clones of all child objects contained in the source object:\n
-For databases, contained objects include schemas, tables, views, etc.\n
-For schemas, contained objects include tables, views, etc.\n
Note that the clone of the container itself (database or schema) does not inherit the privileges granted on the source container.",https://docs.snowflake.com/en/user-guide/object-clone,,Performance Concepts
1006,"A Snowflake user wants to share transactional data with retail suppliers. However, some of the suppliers do not use Snowflake. According to best practice, what should the Snowflake user do? (Choose two.)","B,C",Create an ETL pipeline that uses select and inserts statements from the source to the target supplier accounts.,Provide each non-Snowflake supplier with their own reader account.,Use a data share for suppliers in the same cloud region and a replicated proxy share for other cloud deployments.,Extract the shared transactional data to an external stage and use cloud storage utilities to reload the suppliers' regions.,Deploy a single reader account to be shared by all of the non-Snowflake suppliers.,,,https://docs.snowflake.com/en/user-guide/data-share-replication,,Data Protection and Data Sharing
1007,How does the Snowflake search optimization service improve query performance?,C,It improves the performance of range searches.,It defines different clustering keys on the same source table.,It improves the performance of equality searches.,It improves the performance of all queries running against a given table.,,,"Keywords are ""equality searches"".",https://docs.snowflake.com/en/user-guide/search-optimization-service,,"Performance Concepts, Snowflake AI Data Cloud Features and Architecture"
1008,What is to be expected when sharing worksheets in Snowsight?,A,"To run a shared worksheet, a user must be granted the role used for the worksheet session context.",Worksheets can be shared with users that are internal or external to any organization.,"Snowsight offers different sharing permissions at the worksheet, folder, and dashboard level.",Snowsight allows users to view and refresh results but not to edit shared worksheets.,,,"When you share a worksheet with someone, you can manage access to the worksheet and its contents by choosing which permissions to grant to the other user. These permissions are also used for sharing dashboards. Worksheet owners have the same permissions as worksheet editors.\n

Each worksheet in Snowsight uses a unique session with a specific role and warehouse assigned in the context of the worksheet. The worksheet role is the primary role last used to run the worksheet and is required to run the worksheet. The worksheet role can change if the worksheet owner or editor runs the worksheet using a different role.","https://docs.snowflake.com/en/user-guide/ui-snowsight-dashboards#label-snowsight-dashboards-sharing, https://docs.snowflake.com/en/user-guide/ui-snowsight-worksheets#permissions-for-shared-worksheets",,"Data Protection and Data Sharing, Snowflake AI Data Cloud Features and Architecture"
1009,How does Snowflake define its approach to Discretionary Access Control (DAC)?,D,"Access privileges are assigned to roles, which are in turn assigned to users.",An entity to which access can be granted.,A defined level of access to an object.,"Each object has an owner, who can in turn grant access to that object.",,,"Discretionary Access Control (DAC): Each object has an owner, who can in turn grant access to that object.",https://docs.snowflake.com/en/user-guide/security-access-control-overview,,Account Access and Security
1010,Which of the following languages can be used to implement Snowflake User Defined Functions (UDFs)? (Choose two.),"D,E",C#,PERL,Ruby,SQL,Javascript,,,https://docs.snowflake.com/en/sql-reference/user-defined-functions,,Data Transformations
1011,What is SnowSQL?,A,Snowflake's command line client built on the Python connector which is used to connect to Snowflake and execute SQL.,"Snowflake's proprietary extension of the ANSI SQL standard, including built-in keywords and system functions.",Snowflake's new user interface where users can visualize data into charts and dashboards.,Snowflake's library that provides a programming interface for processing data on Snowflake without moving it to the system where the application code runs.,,,"SnowSQL is the command line client for connecting to Snowflake to execute SQL queries and perform all DDL and DML operations, including loading data into and unloading data out of database tables.\n

SnowSQL (snowsql executable) can be run as an interactive shell or in batch mode through stdin or using the -f option.\n

SnowSQL is an example of an application developed using the Snowflake Connector for Python; however, the connector is not a prerequisite for installing SnowSQL. All required software for installing SnowSQL is bundled in the installers.",https://docs.snowflake.com/en/user-guide/snowsql,,Snowflake AI Data Cloud Features and Architecture